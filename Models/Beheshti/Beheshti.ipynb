{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled162(5).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "528454febcb54c01ada8f4a3bb8e6b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_579d803cb4a246e987f5d7456a3c862e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef7bf0bcedae40f698e72a9aac0e64c8",
              "IPY_MODEL_967e7cd68920478e86f1e84b8641bee9"
            ]
          }
        },
        "579d803cb4a246e987f5d7456a3c862e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef7bf0bcedae40f698e72a9aac0e64c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36803e5ea19240bb933a2bf513c32719",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5575df8bf10c4fd2a638953f7775b9ee"
          }
        },
        "967e7cd68920478e86f1e84b8641bee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0becee7515f4d4abfa9393f539261da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00,  7.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_931828a5afe848d6bb86be4a66d9712b"
          }
        },
        "36803e5ea19240bb933a2bf513c32719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5575df8bf10c4fd2a638953f7775b9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0becee7515f4d4abfa9393f539261da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "931828a5afe848d6bb86be4a66d9712b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17b041e2e51844bb8c958432723d2462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74664b3e2250444881dbfc3c9578e501",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c581d046a1a944b5a2c47474741dc08f",
              "IPY_MODEL_7bf9bab4be5940eba262c4738be8ae2b"
            ]
          }
        },
        "74664b3e2250444881dbfc3c9578e501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c581d046a1a944b5a2c47474741dc08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21bfa5545c734d059d88c8916cc849ad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d3747668fd14124b5543532e5178127"
          }
        },
        "7bf9bab4be5940eba262c4738be8ae2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53d933f3b9b7451ead62565731c3e98a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [06:09&lt;00:00, 27.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2340ff10c361423f9cafa070046b4226"
          }
        },
        "21bfa5545c734d059d88c8916cc849ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d3747668fd14124b5543532e5178127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53d933f3b9b7451ead62565731c3e98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2340ff10c361423f9cafa070046b4226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e34e1cfad534ca7a0326aaa5c787760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b16c827eecbe4c52b954c36d07e048e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62bb58fed5634627a86ba3d1dc695573",
              "IPY_MODEL_251fce78babc4284993c03cabf260797"
            ]
          }
        },
        "b16c827eecbe4c52b954c36d07e048e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62bb58fed5634627a86ba3d1dc695573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89fe89f54e9c40479152417e1a740283",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 41489,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 41489,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bcc7e51ad27452581a74609951c14fd"
          }
        },
        "251fce78babc4284993c03cabf260797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4bef1b3e1cff417e85a5467c8626dd59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 41489/41489 [00:51&lt;00:00, 812.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_539170a0b79848d1b9898bde7dfded23"
          }
        },
        "89fe89f54e9c40479152417e1a740283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bcc7e51ad27452581a74609951c14fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bef1b3e1cff417e85a5467c8626dd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "539170a0b79848d1b9898bde7dfded23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "963363ccc3084e5bb6df0b8fcb031615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7457ab6be51842c39208f1b3c157614e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93dd4f9ebf584cd1a0d83cc0ffcac777",
              "IPY_MODEL_af9c562adf924f6e976da9b17e8f5cc7"
            ]
          }
        },
        "7457ab6be51842c39208f1b3c157614e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93dd4f9ebf584cd1a0d83cc0ffcac777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db5d5cd997114ed99ae723d399e3613a",
            "_dom_classes": [],
            "description": " 60%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2594,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d627eb6f737f468f8e72c49c04b1fd6d"
          }
        },
        "af9c562adf924f6e976da9b17e8f5cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cbdf2e250e541f3806f8da993fcfe4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1560/2594 [12:18&lt;06:54,  2.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b263410588ed4ad5aa6c54bcd7c60c4a"
          }
        },
        "db5d5cd997114ed99ae723d399e3613a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d627eb6f737f468f8e72c49c04b1fd6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cbdf2e250e541f3806f8da993fcfe4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b263410588ed4ad5aa6c54bcd7c60c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97d4860b53cb4c4aafe3a1e7c5defd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e90299d6de784923a02f763c9b1af9e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41788be385cf4f94bd88c20d6830ad57",
              "IPY_MODEL_5add95792bf2474db0e27bd90c626ce9"
            ]
          }
        },
        "e90299d6de784923a02f763c9b1af9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41788be385cf4f94bd88c20d6830ad57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c9d22e349c3143b4a48eb9eb3cc3e1dd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 279,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 279,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d377ab2fa62646efb586112f195cc0c6"
          }
        },
        "5add95792bf2474db0e27bd90c626ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee83a30e65bf4557af14a7b1ace86ca3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 279/279 [00:33&lt;00:00,  8.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84d189ed5ea5472fa7504893a32632a4"
          }
        },
        "c9d22e349c3143b4a48eb9eb3cc3e1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d377ab2fa62646efb586112f195cc0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee83a30e65bf4557af14a7b1ace86ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84d189ed5ea5472fa7504893a32632a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13e4fde7043b488ea2b4faae4c94fe40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d83422b17824bfabe8041da2632722c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_923d2e7368f041359eb47a7151b54d39",
              "IPY_MODEL_8758fb70bf0e4a379330fe244c01d2f2"
            ]
          }
        },
        "5d83422b17824bfabe8041da2632722c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "923d2e7368f041359eb47a7151b54d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_48900de02b144813b144e191112cae89",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 279,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 279,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7da7aea34fc744dd9c8f011e9d0b14c1"
          }
        },
        "8758fb70bf0e4a379330fe244c01d2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38b0d5d6aff54b2db2e1f67de1fb7690",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 279/279 [00:33&lt;00:00,  8.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4efdc0686dc4b17bc0f1517f08ccdd7"
          }
        },
        "48900de02b144813b144e191112cae89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7da7aea34fc744dd9c8f011e9d0b14c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38b0d5d6aff54b2db2e1f67de1fb7690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4efdc0686dc4b17bc0f1517f08ccdd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8652bf65bf248e0bc404f760ac35cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1036f2a23af84d5fa4a327606a65afff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a0023f6c8cf444eafa67ea14ff78ed0",
              "IPY_MODEL_48b4b925f3a44bbf8ccd7f9ce6f32feb"
            ]
          }
        },
        "1036f2a23af84d5fa4a327606a65afff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a0023f6c8cf444eafa67ea14ff78ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a11ecd68740740cd8491a9b3d3a2a078",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 279,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 279,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fafa734cb6664231b4464df7b143a2a9"
          }
        },
        "48b4b925f3a44bbf8ccd7f9ce6f32feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef48aa1aaf5d43d3b67594b1bb4f2750",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 279/279 [00:33&lt;00:00,  8.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c2d6219a9a84e359a45a65c53030510"
          }
        },
        "a11ecd68740740cd8491a9b3d3a2a078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fafa734cb6664231b4464df7b143a2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef48aa1aaf5d43d3b67594b1bb4f2750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c2d6219a9a84e359a45a65c53030510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc0802b27fc24f73b3a9f503ea4f2a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98290768498e41ba9cc358d49de85377",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_275cb38742904662868ae1619b9a5089",
              "IPY_MODEL_fed9295e85f7417390f23380ea5e419e"
            ]
          }
        },
        "98290768498e41ba9cc358d49de85377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "275cb38742904662868ae1619b9a5089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_643ff90197a2445caf4fa6dacc9d7b46",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2224,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0cf37cacdd14944b4efb5e40934da15"
          }
        },
        "fed9295e85f7417390f23380ea5e419e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f27694adee7745729e2d9615c6dbd08f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13/2224 [00:07&lt;21:44,  1.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e1fbb3621894fb1bbf84bd4311f0cfa"
          }
        },
        "643ff90197a2445caf4fa6dacc9d7b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0cf37cacdd14944b4efb5e40934da15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f27694adee7745729e2d9615c6dbd08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e1fbb3621894fb1bbf84bd4311f0cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/MS-Thesis-Phase3/blob/master/Models/Beheshti/Beheshti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkQPQqY6s8-v",
        "colab_type": "text"
      },
      "source": [
        "#In the name of God"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SudnGM-6qcaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8161161e-af7c-4ef6-f725-728bb7dee2bc"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        "  function ClickConnect(){\n",
        "    console.log(\"Working\"); \n",
        "    document.querySelector(\"colab-connect-button\").click() \n",
        "  }\n",
        "  var connect_timer = setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  function ClickConnect(){\n",
              "    console.log(\"Working\"); \n",
              "    document.querySelector(\"colab-connect-button\").click() \n",
              "  }\n",
              "  var connect_timer = setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTGb1dOrs48Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "2ac7fa29-4674-4620-9639-b0f125155ff7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 12 10:23:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyf240b5tD82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "025bea60-8986-4efa-84ac-c25e163a6219"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcbfW-tZtpLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eweO40_dtxZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from transformers import AutoTokenizer\n",
        "import random\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModel"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X2E9kZ5tJRA",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eddoohNmtKug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = '/content/drive/My Drive/Thesis/phase-3/hkr_train.csv'\n",
        "valid_file =  '/content/drive/My Drive/Thesis/phase-3/hkr_valid.csv'\n",
        "test_seen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_seen.csv'\n",
        "test_unseen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_unseen.csv'\n",
        "last_sentence_file = '/content/drive/My Drive/Thesis/phase-3/last_sentence.csv'\n",
        "squad_file = '/content/drive/My Drive/Thesis/phase-3/squad.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCX3Tv8tqPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n",
        "dec_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu21rVUPuIvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"My dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, frac=1, split_rate=1, max_len=512, sort=True, bound=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "        \"\"\"\n",
        "        self.dialogues = pd.read_csv(csv_file)\n",
        "        #self.dialogues.dropna(inplace=True)\n",
        "        \n",
        "        self.dialogues.fillna(\"\", inplace=True)\n",
        "        self.dialogues = self.dialogues[self.dialogues.index % split_rate == 0]\n",
        "\n",
        "        self.dialogues = self.dialogues.sample(frac=frac)\n",
        "\n",
        "        self.dialogues.history = self.dialogues.history.str.replace(\n",
        "            \"[SEP]\", \"</s>\", n=-1, regex=False) ### SPECIAL CHARACHTER FOR TURN\n",
        "        \n",
        "        if bound:\n",
        "          len_prt = int(len(self.dialogues) / 5)\n",
        "          self.dialogues = self.dialogues[ : len_prt]\n",
        "\n",
        "        # s = self.dialogues['response'].apply(dec_tokenizer.encode).apply(len).sort_values().index\n",
        "        # self.dialogues = self.dialogues.reindex(s)\n",
        "\n",
        "        \n",
        "\n",
        "        #self.dialogues.dropna(inplace=True)\n",
        "\n",
        "        self.max_len = max_len\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    @staticmethod\n",
        "    def truncuate_join_pair_sentence(sentence1, sentence2, max_len=510):\n",
        "\n",
        "        \"\"\"\n",
        "        truncuate sentence one from head and sentence two from tail\n",
        "        Args:\n",
        "            sentence1 (string): first sentence\n",
        "            sentence2 (string): seconde sentence\n",
        "        \"\"\"\n",
        "        temp1 = enc_tokenizer.encode(sentence1,add_special_tokens=False)\n",
        "        temp2 = enc_tokenizer.encode(sentence2,add_special_tokens=False)\n",
        "        ### two above line may cause warning but no problem because we've handle them below\n",
        "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "        seq_1 = temp1\n",
        "        seq_2 = temp2\n",
        "        num_tokens_to_remove = len(temp1) + len(temp2) + 3 - max_len\n",
        "        if num_tokens_to_remove > 0 :\n",
        "            seq_1, seq_2, _ = enc_tokenizer.truncate_sequences(temp1[::-1],temp2, num_tokens_to_remove=num_tokens_to_remove,\n",
        "                                                               truncation_strategy='longest_first')\n",
        "            seq_1.reverse()\n",
        "        result_list = [enc_tokenizer.cls_token_id]+seq_1+[enc_tokenizer.sep_token_id]+seq_2+[enc_tokenizer.sep_token_id]\n",
        "        token_type_ids = [0] * (len(seq_1) + 2) + [1] * (len(seq_2) + 1)\n",
        "\n",
        "        if(len(result_list)>1000):\n",
        "          print(len(result_list))\n",
        "\n",
        "        return result_list, token_type_ids\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        \n",
        "        history = self.dialogues.iloc[idx].history\n",
        "        knowledge = self.dialogues.iloc[idx].knowledge\n",
        "        response = self.dialogues.iloc[idx].response\n",
        "\n",
        "\n",
        "        input_pair, input_pair_segments = MyDataset.truncuate_join_pair_sentence(history, knowledge, self.max_len)\n",
        "                \n",
        "\n",
        "        input_pair = torch.LongTensor(input_pair)\n",
        "\n",
        "        input_pair_segments = torch.LongTensor(input_pair_segments)\n",
        "\n",
        "        response_tensor = torch.LongTensor(dec_tokenizer.encode(response, truncation=True, max_length=128))\n",
        "\n",
        "        sample = {'input_pair': input_pair,\n",
        "                  'input_pair_segments': input_pair_segments,\n",
        "                  'response': response_tensor}\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0jkglqFwFQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a44b76ff-3f86-4fa7-d8cb-17f2f0ca5819"
      },
      "source": [
        "train_dataset = MyDataset(train_file, max_len=128, bound=False)\n",
        "valid_dataset = MyDataset(valid_file, max_len=128)\n",
        "test_unseen_dataset = MyDataset(test_unseen_file, max_len=128)\n",
        "test_seen_dataset = MyDataset(test_seen_file, max_len=128)\n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))\n",
        "print(len(test_unseen_dataset))\n",
        "print(len(test_seen_dataset))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41489\n",
            "4458\n",
            "2075\n",
            "2224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VasXIkuLwHnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cd8be571-77d8-4073-ce7a-169be9c9a0fa"
      },
      "source": [
        "print(enc_tokenizer.decode(train_dataset[600]['input_pair']))\n",
        "print(dec_tokenizer.decode(train_dataset[600]['response']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s>Kobe beef </s> Have you heard of Kobe beef? It is special beef from Japan. </s> No, i have never heard of Kobe beef could you tell me more about it?</s>These were the four wagyÅ« breeds, the Japanese Black, the Japanese Brown, the Japanese Polled and the Japanese Shorthorn.</s>\n",
            "<s>Yeah they kept the Kobe beef cow separate from cross breeding. There are 4 breeds for the purpose.</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Z5ZeAT2oii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "528454febcb54c01ada8f4a3bb8e6b65",
            "579d803cb4a246e987f5d7456a3c862e",
            "ef7bf0bcedae40f698e72a9aac0e64c8",
            "967e7cd68920478e86f1e84b8641bee9",
            "36803e5ea19240bb933a2bf513c32719",
            "5575df8bf10c4fd2a638953f7775b9ee",
            "a0becee7515f4d4abfa9393f539261da",
            "931828a5afe848d6bb86be4a66d9712b"
          ]
        },
        "outputId": "9baea9ee-6109-4576-cfd6-b69191467178"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "\n",
        "  len_batch = len(batch)\n",
        "\n",
        "  \n",
        "  max_len_input_pair = max([len(data['input_pair']) for data in batch])\n",
        "\n",
        "  max_len_response = max([len(data['response']) for data in batch])\n",
        "  \n",
        "  padding_ind = 0 ## for bert is 0 DON'T THINK BAD IT IS NOT REFACTORING !!!!!!\n",
        "  result_input_pair = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_input_pair_segments = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_response = torch.zeros(len_batch, max_len_response)\n",
        "\n",
        "  for i, data in enumerate(batch):\n",
        "    p1 = len(data['input_pair'])\n",
        "    result_input_pair[i, :p1] = data['input_pair']\n",
        "\n",
        "    p3 = len(data['input_pair_segments'])\n",
        "    result_input_pair_segments[i, :p3] = data['input_pair_segments']\n",
        "\n",
        "    p4 = len(data['response'])\n",
        "    result_response[i, :p4] = data['response']\n",
        "\n",
        "  return result_input_pair.long(), result_input_pair_segments.long(), result_response.long()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16,\n",
        "                                             shuffle=True, collate_fn=my_collate_fn,\n",
        "                                           num_workers=1)\n",
        "\n",
        "#valid_sampler = torch.utils.data.SequentialSampler(valid_dataset)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn, num_workers=1)\n",
        "\n",
        "i = 0 \n",
        "for batch_idx, batch  in tqdm(enumerate(train_loader)):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  print(pair_batch.shape)\n",
        "  print(segment_batch.shape)\n",
        "  print(response_batch.shape)\n",
        "  print(\"****\")\n",
        "  i += 1 \n",
        "  if(i==2):\n",
        "    break\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(valid_loader))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "528454febcb54c01ada8f4a3bb8e6b65",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 45])\n",
            "****\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 37])\n",
            "****\n",
            "2594\n",
            "279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoQlszJw_hFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "c5ef1ed1-4202-4916-d65d-d7cab8869c62"
      },
      "source": [
        "o = torch.rand(8,5)\n",
        "o"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7971, 0.5570, 0.6176, 0.8620, 0.0346],\n",
              "        [0.2617, 0.9808, 0.7682, 0.6243, 0.2782],\n",
              "        [0.4833, 0.6336, 0.0463, 0.0938, 0.4098],\n",
              "        [0.9999, 0.7067, 0.1404, 0.7106, 0.1492],\n",
              "        [0.0357, 0.5070, 0.1811, 0.8164, 0.6623],\n",
              "        [0.6191, 0.1194, 0.4503, 0.9537, 0.8837],\n",
              "        [0.2407, 0.3513, 0.4584, 0.2995, 0.2904],\n",
              "        [0.1673, 0.0891, 0.2090, 0.0751, 0.6567]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzwNQ5HwD5hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0aec0d8-18f3-43e7-f137-27cc4551bceb"
      },
      "source": [
        "y = torch.LongTensor(8).random_(0,5)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0, 0, 0, 4, 1, 4, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0fr2mAvGYA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "749be628-2f4b-4379-c354-d490ccde15dd"
      },
      "source": [
        "o[y!=2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2617, 0.9808, 0.7682, 0.6243, 0.2782],\n",
              "        [0.4833, 0.6336, 0.0463, 0.0938, 0.4098],\n",
              "        [0.9999, 0.7067, 0.1404, 0.7106, 0.1492],\n",
              "        [0.0357, 0.5070, 0.1811, 0.8164, 0.6623],\n",
              "        [0.6191, 0.1194, 0.4503, 0.9537, 0.8837],\n",
              "        [0.2407, 0.3513, 0.4584, 0.2995, 0.2904]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxXzuZtMINMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cafb2b27-0aaf-4bb8-8d21-a759de573555"
      },
      "source": [
        "z = torch.LongTensor(o[y!=2].shape[0]).fill_(2)\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J49VS8z3Ilz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfWWb-ayBCsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7132afe9-8373-49be-9a7b-225c4c8afa97"
      },
      "source": [
        "-1*F.nll_loss(nn.functional.log_softmax(o[y!=2]), z, reduction='mean')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7754)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXB7YVVgDyPU",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfGvoJMiEicR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizer\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    # self.seq2seq = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    #     'google/bert_uncased_L-2_H-128_A-2', 'google/bert_uncased_L-6_H-128_A-2')\n",
        "    \n",
        "    # for p in self.seq2seq.encoder.embeddings.parameters():\n",
        "    #    p.requires_grad = False\n",
        "    \n",
        "    # for p in self.seq2seq.decoder.bert.embeddings.parameters():\n",
        "    #    p.requires_grad = False\n",
        "\n",
        "    self.seq2seq = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "\n",
        "  def forward(self, encoder_input, segments_tensors, decoder_input):\n",
        "    '''\n",
        "    encoder_input = [batch_size, enc_len]\n",
        "    segments_tensors = [batch_size, enc_len]\n",
        "    decoder_input = [batch_size, dec_len]\n",
        "    '''\n",
        "    kwargs = {'token_type_ids':segments_tensors}\n",
        "    kwargs = {}\n",
        "    outputs = self.seq2seq(input_ids=encoder_input,\n",
        "                           decoder_input_ids=decoder_input,\n",
        "                           use_cache=False, **kwargs)[0]\n",
        "    return outputs\n",
        "  \n",
        "  def generate(self, encoder_input, segments_tensors, **kwargs):\n",
        "    ### encoder_input = [len] in int format\n",
        "    ### segment_tensors = [len]\n",
        "    encoder_input = encoder_input.unsqueeze(0)\n",
        "    segments_tensors = segments_tensors.unsqueeze(0)\n",
        "    \n",
        "    model_specific_kwargs = {}\n",
        "    #model_specific_kwargs['token_type_ids'] = {'token_type_ids':segments_tensors}\n",
        "\n",
        "    generated = model.seq2seq.generate(encoder_input, decoder_start_token_id=0,\n",
        "                                       eos_token_id=2, ## <s> = 0 </s> = 2\n",
        "                                       **kwargs, **model_specific_kwargs)\n",
        "\n",
        "    #### generated = [1, len]\n",
        "    return generated"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxsRPOHFGrBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d82d745c-e1dd-4484-91c5-1a1490a7f41f"
      },
      "source": [
        "dev = torch.device('cuda')\n",
        "model = Model().to(dev)\n",
        "\n",
        "x = torch.LongTensor(8, 40).random_(1,1000).to(dev)\n",
        "y = torch.LongTensor(8, 10).random_(1,1000).to(dev)\n",
        "print(model(x,x,y).shape)\n",
        "\n",
        "\n",
        "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(count_parameters(model))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 10, 50265])\n",
            "139420416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb5uvuCKL0cj",
        "colab_type": "text"
      },
      "source": [
        "#Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxB7zLBDZQXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJplUNA2A-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_cosine_schedule_with_warmup, get_constant_schedule\n",
        "scheduler = get_constant_schedule(optimizer)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ofqAPp12OnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "17b041e2e51844bb8c958432723d2462",
            "74664b3e2250444881dbfc3c9578e501",
            "c581d046a1a944b5a2c47474741dc08f",
            "7bf9bab4be5940eba262c4738be8ae2b",
            "21bfa5545c734d059d88c8916cc849ad",
            "5d3747668fd14124b5543532e5178127",
            "53d933f3b9b7451ead62565731c3e98a",
            "2340ff10c361423f9cafa070046b4226"
          ]
        },
        "outputId": "fcaa773d-b5d5-45ea-997b-b54a1ee95292"
      },
      "source": [
        "lrs = []\n",
        "for i in tqdm(range(10000)):\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "  lrs.append(scheduler.get_last_lr()[0])\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lrs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17b041e2e51844bb8c958432723d2462",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3ea2eb6400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufFe-Q62ZaFW",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfNUyJV1DfaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "0e34e1cfad534ca7a0326aaa5c787760",
            "b16c827eecbe4c52b954c36d07e048e8",
            "62bb58fed5634627a86ba3d1dc695573",
            "251fce78babc4284993c03cabf260797",
            "89fe89f54e9c40479152417e1a740283",
            "8bcc7e51ad27452581a74609951c14fd",
            "4bef1b3e1cff417e85a5467c8626dd59",
            "539170a0b79848d1b9898bde7dfded23"
          ]
        },
        "outputId": "4aacf47b-af81-476c-ef62-65c5a488e6a1"
      },
      "source": [
        "df = pd.read_csv(train_file)\n",
        "freqs = [1] * dec_tokenizer.vocab_size\n",
        "for response in tqdm(df['response']):\n",
        "  tknzd = dec_tokenizer.encode(response)\n",
        "  for tkn in tknzd:\n",
        "    freqs[tkn] += 1"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e34e1cfad534ca7a0326aaa5c787760",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=41489.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_YgBP3AFXF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weights(_lambda = 0):\n",
        "  weights = torch.ones(dec_tokenizer.vocab_size)\n",
        "  for idx, freq in enumerate(freqs):\n",
        "    weight = 1 / (freq**_lambda)\n",
        "    weights[idx] = weight\n",
        "  return weights"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-t7PADEZcZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn\n",
        "\n",
        "weight = get_weights().to(dev)\n",
        "\n",
        "def mahdi_loss(model_output, true_trg, **kwargs):\n",
        "  '''\n",
        "  model_output: [batch, len, hidden]\n",
        "  true_trg: [batch, len]\n",
        "  '''\n",
        "  model_output = model_output[:,:-1,:]\n",
        "  true_trg = true_trg[:,1:]\n",
        "\n",
        "  # cold\n",
        "  #T = 1\n",
        "  #model_output = model_output / T\n",
        "\n",
        "  if 'easy_training' in kwargs:\n",
        "    print(\"Easy training\")\n",
        "    limit_last_tokens = kwargs['easy_training']\n",
        "    model_output = model_output[:,-limit_last_tokens:,:]\n",
        "    true_trg = true_trg[:,-limit_last_tokens:]\n",
        "\n",
        "  batch_len = model_output.shape[0]\n",
        "  snt_len = model_output.shape[1]\n",
        "  hidden_size = model_output.shape[2]\n",
        "\n",
        "  model_output = model_output.reshape(-1, hidden_size)\n",
        "  true_trg = true_trg.reshape(-1)\n",
        "\n",
        "  loss_mod = nn.CrossEntropyLoss(weight=weight, ignore_index=0)## PAD = 0\n",
        "  loss = loss_mod(model_output, true_trg)\n",
        "\n",
        "\n",
        "\n",
        "  #z = torch.LongTensor(model_output[true_trg!=1045].shape[0]).fill_(1045).to(dev)\n",
        "  #neg_loss = -0.5*F.nll_loss(nn.functional.log_softmax(model_output[true_trg!=1045]), z, reduction='mean')\n",
        "\n",
        "  return loss "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmuTGJMJbR9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(batch_idx, batch):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  pair_batch = pair_batch.to(dev)\n",
        "  segment_batch = segment_batch.to(dev)\n",
        "  response_batch = response_batch.to(dev)\n",
        "  model_output = model(pair_batch, segment_batch, response_batch)\n",
        "  #kwargs = {'easy_training':4}\n",
        "  loss = mahdi_loss(model_output, response_batch)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "  del pair_batch\n",
        "  del segment_batch\n",
        "  del response_batch\n",
        "  return loss.item()\n",
        "\n",
        "def valid_step(batch_idx, batch):\n",
        "  with torch.no_grad():\n",
        "    pair_batch, segment_batch, response_batch = batch\n",
        "    pair_batch = pair_batch.to(dev)\n",
        "    segment_batch = segment_batch.to(dev)\n",
        "    response_batch = response_batch.to(dev)\n",
        "    model_output = model(pair_batch, segment_batch, response_batch)\n",
        "    loss = mahdi_loss(model_output, response_batch)\n",
        "    del pair_batch\n",
        "    del segment_batch\n",
        "    del response_batch\n",
        "    return loss.item()\n",
        "\n",
        "def valid_loop(valid_loader):\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "  for batch_idx, batch in tqdm(enumerate(valid_loader),  total=len(valid_loader), leave=False):\n",
        "    total_loss += valid_step(batch_idx, batch)\n",
        "  \n",
        "  print(\"temperature is 1:\")\n",
        "  kwargs = {'num_beams':8,'num_return_sequences':8,'temperature':1,\n",
        "            'no_repeat_ngram_size':3}\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  print(\"most greedy sentence:\")\n",
        "  kwargs = {\n",
        "          'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3,\n",
        "          'top-k':1\n",
        "          }\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  # print(\"temperature is 2:\")\n",
        "  # kwargs = {'num_beams':16,'num_return_sequences':16,'temperature':2}\n",
        "  # valid_inference(**kwargs)\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  return total_loss / len(valid_loader)\n",
        "\n",
        "def valid_inference(idx=600, **kwargs):\n",
        "  hk_pair =  train_dataset[idx]['input_pair'].to(dev)\n",
        "  hk_segment = train_dataset[idx]['input_pair_segments'].to(dev)\n",
        "  response = train_dataset[idx]['response'].to(dev)\n",
        "  generateds = model.generate(hk_pair, hk_segment, **kwargs)\n",
        "  print(\"pair is: \",enc_tokenizer.decode(hk_pair))\n",
        "  print(\"response is: \",dec_tokenizer.decode(response))\n",
        "  for generated in generateds:\n",
        "    print(\"model says: \",dec_tokenizer.decode(generated))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pxjS0PQfKU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_learning = True\n",
        "if new_learning:\n",
        "  # optimizer = NoamOpt(128, 1, 2000,\n",
        "  #           torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "  model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Beheshti/\"\n",
        "  step = 0\n",
        "  log_list = []"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZD1hD7rfNFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b619ef5b-b500-4a2a-e393-fb7c19e4531c"
      },
      "source": [
        "## if continue learning:\n",
        "#!wget -q https://github.com/mmsamiei/MS-Thesis-Phase2/raw/master/Models/hashemi_16000steps.model\n",
        "model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Montazeri\"\n",
        "checkpoint = torch.load(model_dir+'/montazeri_15000steps.model')\n",
        "step = checkpoint['log_list'][-1]['step']\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "optimizer._step = step\n",
        "log_list = checkpoint['log_list']\n",
        "new_learning = False\n",
        "print(step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHv6tC4YfZI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "963363ccc3084e5bb6df0b8fcb031615",
            "7457ab6be51842c39208f1b3c157614e",
            "93dd4f9ebf584cd1a0d83cc0ffcac777",
            "af9c562adf924f6e976da9b17e8f5cc7",
            "db5d5cd997114ed99ae723d399e3613a",
            "d627eb6f737f468f8e72c49c04b1fd6d",
            "3cbdf2e250e541f3806f8da993fcfe4a",
            "b263410588ed4ad5aa6c54bcd7c60c4a",
            "97d4860b53cb4c4aafe3a1e7c5defd3c",
            "e90299d6de784923a02f763c9b1af9e8",
            "41788be385cf4f94bd88c20d6830ad57",
            "5add95792bf2474db0e27bd90c626ce9",
            "c9d22e349c3143b4a48eb9eb3cc3e1dd",
            "d377ab2fa62646efb586112f195cc0c6",
            "ee83a30e65bf4557af14a7b1ace86ca3",
            "84d189ed5ea5472fa7504893a32632a4",
            "13e4fde7043b488ea2b4faae4c94fe40",
            "5d83422b17824bfabe8041da2632722c",
            "923d2e7368f041359eb47a7151b54d39",
            "8758fb70bf0e4a379330fe244c01d2f2",
            "48900de02b144813b144e191112cae89",
            "7da7aea34fc744dd9c8f011e9d0b14c1",
            "38b0d5d6aff54b2db2e1f67de1fb7690",
            "a4efdc0686dc4b17bc0f1517f08ccdd7",
            "a8652bf65bf248e0bc404f760ac35cbc",
            "1036f2a23af84d5fa4a327606a65afff",
            "2a0023f6c8cf444eafa67ea14ff78ed0",
            "48b4b925f3a44bbf8ccd7f9ce6f32feb",
            "a11ecd68740740cd8491a9b3d3a2a078",
            "fafa734cb6664231b4464df7b143a2a9",
            "ef48aa1aaf5d43d3b67594b1bb4f2750",
            "2c2d6219a9a84e359a45a65c53030510"
          ]
        },
        "outputId": "096ce10d-6196-49e8-e5d4-5f509697e925"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "MAX_STEP = 10000\n",
        "STEP_SAVE = 500\n",
        "STEP_CHECK = 500\n",
        "step_num = step + 1\n",
        "log_list = log_list ### Check if new learning or not\n",
        "print(step_num)\n",
        "while step_num <= MAX_STEP:\n",
        "  model.train()\n",
        "  for batch_idx, batch in tqdm(enumerate(iter(train_loader)), total=len(train_loader), leave=False):\n",
        "    step_loss = train_step(batch_idx, batch)\n",
        "    log = {'step':step_num, 'train_loss':step_loss}\n",
        "\n",
        "    if(step_num % STEP_CHECK == 0):\n",
        "      valid_error = valid_loop(valid_loader)\n",
        "      train_losses = [step['train_loss'] for step in log_list[-100:]]\n",
        "      avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "      print(\"train Loss rate: {} at step {}\".format(avg_train_loss, step_num))  \n",
        "      print(\"valid Loss rate: {} at step {}\".format(valid_error, step_num))  \n",
        "      log['valid_loss'] = valid_error\n",
        "\n",
        "    log_list.append(log)\n",
        "\n",
        "    if(step_num % STEP_SAVE == 0):\n",
        "      torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'log_list': log_list,\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, model_dir+'beheshti_{}steps.model'.format(step_num))\n",
        "    step_num += 1"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "963363ccc3084e5bb6df0b8fcb031615",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2594.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97d4860b53cb4c4aafe3a1e7c5defd3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=279.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "temperature is 1:\n",
            "pair is:  <s>Kobe beef </s> Have you heard of Kobe beef? It is special beef from Japan. </s> No, i have never heard of Kobe beef could you tell me more about it?</s>These were the four wagyÅ« breeds, the Japanese Black, the Japanese Brown, the Japanese Polled and the Japanese Shorthorn.</s>\n",
            "response is:  <s>Yeah they kept the Kobe beef cow separate from cross breeding. There are 4 breeds for the purpose.</s>\n",
            "model says:  <s><s>, there were four wagyÅ« breeds, the Japanese Black, Japanese Brown, the\n",
            "model says:  <s><s>, there are four wagyÅ« breeds, the Japanese Black, Japanese Brown, the\n",
            "model says:  <s><s>, there were four wagyÅ« breeds, the Japanese Black, Japanese Brown, Japanese\n",
            "model says:  <s><s>, there are four wagyÅ« breeds, the Japanese Black, Japanese Brown, Japanese\n",
            "model says:  <s><s>, there were four wagyÅ« breeds, the Japanese Black, Japanese Brown, and\n",
            "model says:  <s><s>, there are four wagyÅ« breeds, the Japanese Black, Japanese Brown, and\n",
            "model says:  <s><s>, there were four wagyÅ« breeds, the Japanese Black, Japanese Brown and the\n",
            "model says:  <s><s>, there are four wagyÅ« breeds, the Japanese Black, Japanese Brown and the\n",
            "most greedy sentence:\n",
            "pair is:  <s>Kobe beef </s> Have you heard of Kobe beef? It is special beef from Japan. </s> No, i have never heard of Kobe beef could you tell me more about it?</s>These were the four wagyÅ« breeds, the Japanese Black, the Japanese Brown, the Japanese Polled and the Japanese Shorthorn.</s>\n",
            "response is:  <s>Yeah they kept the Kobe beef cow separate from cross breeding. There are 4 breeds for the purpose.</s>\n",
            "model says:  <s>I, I know, but I have heard of the Japanese Black, the Japanese Brown, the Japan Polled and the Japanese Shorthorn.</s>\n",
            "train Loss rate: 2.882180914878845 at step 500\n",
            "valid Loss rate: 2.794859383695869 at step 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13e4fde7043b488ea2b4faae4c94fe40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=279.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "temperature is 1:\n",
            "pair is:  <s>Kobe beef </s> Have you heard of Kobe beef? It is special beef from Japan. </s> No, i have never heard of Kobe beef could you tell me more about it?</s>These were the four wagyÅ« breeds, the Japanese Black, the Japanese Brown, the Japanese Polled and the Japanese Shorthorn.</s>\n",
            "response is:  <s>Yeah they kept the Kobe beef cow separate from cross breeding. There are 4 breeds for the purpose.</s>\n",
            "model says:  <s><s> there are four wagyÅ« breeds, the Japanese Black, the Brown, the Poll</s>\n",
            "model says:  <s><s> there were four wagyÅ« breeds, the Japanese Black, the Brown, the Poll</s>\n",
            "model says:  <s><s>'s are the Japanese Black, the Japanese Brown, and the Japanese Polled and the</s>\n",
            "model says:  <s><s> there are four wagyÅ« breeds, the Japanese Black, the Brown Brown, the</s>\n",
            "model says:  <s><s>, there are four wagyÅ« breeds, the Japanese Black, the Brown, the</s>\n",
            "model says:  <s><s>, there were four wagyÅ« breeds, the Japanese Black, the Brown, the</s>\n",
            "model says:  <s><s> is the Japanese Black, the Japanese Brown, and the Japanese Polled.</s><pad><pad>\n",
            "model says:  <s><s>'s are the Japanese Black, the Japanese Brown, and the Japanese Polled.</s><pad>\n",
            "most greedy sentence:\n",
            "pair is:  <s>Kobe beef </s> Have you heard of Kobe beef? It is special beef from Japan. </s> No, i have never heard of Kobe beef could you tell me more about it?</s>These were the four wagyÅ« breeds, the Japanese Black, the Japanese Brown, the Japanese Polled and the Japanese Shorthorn.</s>\n",
            "response is:  <s>Yeah they kept the Kobe beef cow separate from cross breeding. There are 4 breeds for the purpose.</s>\n",
            "model says:  <s>Yes, there are four wagyÅ« breeds, the Japanese Black, the Brown, the Polled and the Japanese Shorthorn.</s>\n",
            "train Loss rate: 2.821344466209412 at step 1000\n",
            "valid Loss rate: 2.6996240692753948 at step 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8652bf65bf248e0bc404f760ac35cbc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=279.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "temperature is 1:\n",
            "pair is:  <s>Kobe beef </s> Have you heard of Kobe beef? It is special beef from Japan. </s> No, i have never heard of Kobe beef could you tell me more about it?</s>These were the four wagyÅ« breeds, the Japanese Black, the Japanese Brown, the Japanese Polled and the Japanese Shorthorn.</s>\n",
            "response is:  <s>Yeah they kept the Kobe beef cow separate from cross breeding. There are 4 breeds for the purpose.</s>\n",
            "model says:  <s><s> of the four wagyÅ« breeds, the Japanese Black, the Brown, the Poll\n",
            "model says:  <s><s> of the four wagyÅ« breeds, the Black, the Japanese Brown, the Poll\n",
            "model says:  <s><s> are the four wagyÅ« breeds, the Japanese Black, the Brown, the Poll\n",
            "model says:  <s><s> of the four wagyÅ« breeds, the Japanese Black and the Japanese Brown, the\n",
            "model says:  <s><s> of the four wagyÅ« breeds, the Black, the Brown, the Polled\n",
            "model says:  <s><s> were the four wagyÅ« breeds, the Japanese Black, the Brown, the Poll\n",
            "model says:  <s><s> of the four wagyÅ« breeds, the Japanese Black, the Brown Brown, the\n",
            "model says:  <s><s> of the four wagyÅ« breeds, the Japanese Black, the Japan Brown, the\n",
            "most greedy sentence:\n",
            "pair is:  <s>Kobe beef </s> Have you heard of Kobe beef? It is special beef from Japan. </s> No, i have never heard of Kobe beef could you tell me more about it?</s>These were the four wagyÅ« breeds, the Japanese Black, the Japanese Brown, the Japanese Polled and the Japanese Shorthorn.</s>\n",
            "response is:  <s>Yeah they kept the Kobe beef cow separate from cross breeding. There are 4 breeds for the purpose.</s>\n",
            "model says:  <s>They are from Japan.</s>\n",
            "train Loss rate: 2.6822487616539004 at step 1500\n",
            "valid Loss rate: 2.628739208303472 at step 1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-ddcecf4dbc84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mstep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-9f75b916d2bc>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch_idx, batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mpair_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow4c6BCePKec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e71d1052-fb48-4dbc-c434-3c950f68e09c"
      },
      "source": [
        "kwargs = {#'num_beams':8,\n",
        "          'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3,\n",
        "          'top-k':1\n",
        "          }\n",
        "valid_inference(idx=1200, **kwargs)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pair is:  <s>Veganism </s> I am following a strict vegan diet from the past six months. </s> what is vegan diet?</s>A follower of either the diet or the philosophy is known as a vegan ( ).</s>\n",
            "response is:  <s>vegan diet is the diet which include no animal products</s>\n",
            "model says:  <s>I am a follower of either the diet or the philosophy is known as a vegan ( ).</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlWb7ZY5ClYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d15898e9-2734-4201-da38-88af8bfcdadd"
      },
      "source": [
        "dec_tokenizer.encode(\"they\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2027, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001YzGTpEiV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22f816d3-aa9b-4257-c6bf-f96fe6283f0f"
      },
      "source": [
        "log_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'step': 1, 'train_loss': 10.614270210266113},\n",
              " {'step': 2, 'train_loss': 10.733108520507812},\n",
              " {'step': 3, 'train_loss': 10.35904312133789},\n",
              " {'step': 4, 'train_loss': 10.361538887023926},\n",
              " {'step': 5, 'train_loss': 9.957269668579102},\n",
              " {'step': 6, 'train_loss': 9.948104858398438},\n",
              " {'step': 7, 'train_loss': 9.55443286895752},\n",
              " {'step': 8, 'train_loss': 9.504170417785645},\n",
              " {'step': 9, 'train_loss': 9.426634788513184},\n",
              " {'step': 10, 'train_loss': 9.070025444030762},\n",
              " {'step': 11, 'train_loss': 8.891423225402832},\n",
              " {'step': 12, 'train_loss': 8.783164024353027},\n",
              " {'step': 13, 'train_loss': 8.70628547668457},\n",
              " {'step': 14, 'train_loss': 8.569317817687988},\n",
              " {'step': 15, 'train_loss': 8.292956352233887},\n",
              " {'step': 16, 'train_loss': 8.274083137512207},\n",
              " {'step': 17, 'train_loss': 7.799631595611572},\n",
              " {'step': 18, 'train_loss': 8.041912078857422},\n",
              " {'step': 19, 'train_loss': 7.653815269470215},\n",
              " {'step': 20, 'train_loss': 7.699405670166016},\n",
              " {'step': 21, 'train_loss': 7.541056156158447},\n",
              " {'step': 22, 'train_loss': 7.494517803192139},\n",
              " {'step': 23, 'train_loss': 7.430841445922852},\n",
              " {'step': 24, 'train_loss': 7.282088279724121},\n",
              " {'step': 25, 'train_loss': 7.419764518737793},\n",
              " {'step': 26, 'train_loss': 7.311008453369141},\n",
              " {'step': 27, 'train_loss': 7.324136257171631},\n",
              " {'step': 28, 'train_loss': 7.19038724899292},\n",
              " {'step': 29, 'train_loss': 7.139859676361084},\n",
              " {'step': 30, 'train_loss': 6.9642133712768555},\n",
              " {'step': 31, 'train_loss': 7.110976219177246},\n",
              " {'step': 32, 'train_loss': 6.959036827087402},\n",
              " {'step': 33, 'train_loss': 6.991216659545898},\n",
              " {'step': 34, 'train_loss': 7.028300762176514},\n",
              " {'step': 35, 'train_loss': 6.890758514404297},\n",
              " {'step': 36, 'train_loss': 6.940341949462891},\n",
              " {'step': 37, 'train_loss': 6.829961776733398},\n",
              " {'step': 38, 'train_loss': 6.790741443634033},\n",
              " {'step': 39, 'train_loss': 6.722304344177246},\n",
              " {'step': 40, 'train_loss': 6.799952030181885},\n",
              " {'step': 41, 'train_loss': 6.738827705383301},\n",
              " {'step': 42, 'train_loss': 6.836117744445801},\n",
              " {'step': 43, 'train_loss': 6.828161239624023},\n",
              " {'step': 44, 'train_loss': 6.477605819702148},\n",
              " {'step': 45, 'train_loss': 6.66423225402832},\n",
              " {'step': 46, 'train_loss': 6.619389057159424},\n",
              " {'step': 47, 'train_loss': 6.610867977142334},\n",
              " {'step': 48, 'train_loss': 6.634395599365234},\n",
              " {'step': 49, 'train_loss': 6.7043023109436035},\n",
              " {'step': 50, 'train_loss': 6.447009086608887},\n",
              " {'step': 51, 'train_loss': 6.404237747192383},\n",
              " {'step': 52, 'train_loss': 6.602799415588379},\n",
              " {'step': 53, 'train_loss': 6.495773792266846},\n",
              " {'step': 54, 'train_loss': 6.4824700355529785},\n",
              " {'step': 55, 'train_loss': 6.533472537994385},\n",
              " {'step': 56, 'train_loss': 6.473059177398682},\n",
              " {'step': 57, 'train_loss': 6.536724090576172},\n",
              " {'step': 58, 'train_loss': 6.466060638427734},\n",
              " {'step': 59, 'train_loss': 6.412276268005371},\n",
              " {'step': 60, 'train_loss': 6.33018684387207},\n",
              " {'step': 61, 'train_loss': 6.287384986877441},\n",
              " {'step': 62, 'train_loss': 6.26254415512085},\n",
              " {'step': 63, 'train_loss': 6.33486795425415},\n",
              " {'step': 64, 'train_loss': 6.475207328796387},\n",
              " {'step': 65, 'train_loss': 6.321694374084473},\n",
              " {'step': 66, 'train_loss': 6.318795204162598},\n",
              " {'step': 67, 'train_loss': 6.250856876373291},\n",
              " {'step': 68, 'train_loss': 6.273882865905762},\n",
              " {'step': 69, 'train_loss': 6.177679061889648},\n",
              " {'step': 70, 'train_loss': 6.31804895401001},\n",
              " {'step': 71, 'train_loss': 6.312829494476318},\n",
              " {'step': 72, 'train_loss': 6.408702373504639},\n",
              " {'step': 73, 'train_loss': 6.233015060424805},\n",
              " {'step': 74, 'train_loss': 6.162512302398682},\n",
              " {'step': 75, 'train_loss': 6.125713348388672},\n",
              " {'step': 76, 'train_loss': 6.25309419631958},\n",
              " {'step': 77, 'train_loss': 6.191492557525635},\n",
              " {'step': 78, 'train_loss': 6.253152370452881},\n",
              " {'step': 79, 'train_loss': 6.144394397735596},\n",
              " {'step': 80, 'train_loss': 6.068164348602295},\n",
              " {'step': 81, 'train_loss': 6.047217845916748},\n",
              " {'step': 82, 'train_loss': 6.155714511871338},\n",
              " {'step': 83, 'train_loss': 6.2831292152404785},\n",
              " {'step': 84, 'train_loss': 6.0289506912231445},\n",
              " {'step': 85, 'train_loss': 6.046760082244873},\n",
              " {'step': 86, 'train_loss': 6.0089263916015625},\n",
              " {'step': 87, 'train_loss': 6.149424076080322},\n",
              " {'step': 88, 'train_loss': 5.892147064208984},\n",
              " {'step': 89, 'train_loss': 6.167072296142578},\n",
              " {'step': 90, 'train_loss': 6.048231601715088},\n",
              " {'step': 91, 'train_loss': 6.064284324645996},\n",
              " {'step': 92, 'train_loss': 6.100862503051758},\n",
              " {'step': 93, 'train_loss': 6.143848419189453},\n",
              " {'step': 94, 'train_loss': 5.9826250076293945},\n",
              " {'step': 95, 'train_loss': 6.055506706237793},\n",
              " {'step': 96, 'train_loss': 6.1009111404418945},\n",
              " {'step': 97, 'train_loss': 5.9516167640686035},\n",
              " {'step': 98, 'train_loss': 5.892017841339111},\n",
              " {'step': 99, 'train_loss': 6.066226482391357},\n",
              " {'step': 100, 'train_loss': 6.033585071563721},\n",
              " {'step': 101, 'train_loss': 5.9667582511901855},\n",
              " {'step': 102, 'train_loss': 5.870423793792725},\n",
              " {'step': 103, 'train_loss': 5.994822025299072},\n",
              " {'step': 104, 'train_loss': 5.971651554107666},\n",
              " {'step': 105, 'train_loss': 5.9873247146606445},\n",
              " {'step': 106, 'train_loss': 6.104528903961182},\n",
              " {'step': 107, 'train_loss': 6.018568515777588},\n",
              " {'step': 108, 'train_loss': 5.905545711517334},\n",
              " {'step': 109, 'train_loss': 5.904337406158447},\n",
              " {'step': 110, 'train_loss': 5.857326984405518},\n",
              " {'step': 111, 'train_loss': 5.910941123962402},\n",
              " {'step': 112, 'train_loss': 5.952322959899902},\n",
              " {'step': 113, 'train_loss': 5.930358409881592},\n",
              " {'step': 114, 'train_loss': 5.820103645324707},\n",
              " {'step': 115, 'train_loss': 5.904860496520996},\n",
              " {'step': 116, 'train_loss': 5.746059894561768},\n",
              " {'step': 117, 'train_loss': 5.919399738311768},\n",
              " {'step': 118, 'train_loss': 5.721978664398193},\n",
              " {'step': 119, 'train_loss': 5.978499412536621},\n",
              " {'step': 120, 'train_loss': 5.803157806396484},\n",
              " {'step': 121, 'train_loss': 5.9035115242004395},\n",
              " {'step': 122, 'train_loss': 5.905656337738037},\n",
              " {'step': 123, 'train_loss': 5.965410232543945},\n",
              " {'step': 124, 'train_loss': 5.693082332611084},\n",
              " {'step': 125, 'train_loss': 5.800467491149902},\n",
              " {'step': 126, 'train_loss': 5.9416961669921875},\n",
              " {'step': 127, 'train_loss': 5.744022846221924},\n",
              " {'step': 128, 'train_loss': 5.756189823150635},\n",
              " {'step': 129, 'train_loss': 5.972407341003418},\n",
              " {'step': 130, 'train_loss': 5.739309787750244},\n",
              " {'step': 131, 'train_loss': 5.773653984069824},\n",
              " {'step': 132, 'train_loss': 5.7204270362854},\n",
              " {'step': 133, 'train_loss': 5.745061874389648},\n",
              " {'step': 134, 'train_loss': 5.694537162780762},\n",
              " {'step': 135, 'train_loss': 5.807111740112305},\n",
              " {'step': 136, 'train_loss': 5.677490234375},\n",
              " {'step': 137, 'train_loss': 5.84185791015625},\n",
              " {'step': 138, 'train_loss': 5.757626056671143},\n",
              " {'step': 139, 'train_loss': 5.838588237762451},\n",
              " {'step': 140, 'train_loss': 5.887659072875977},\n",
              " {'step': 141, 'train_loss': 5.799559116363525},\n",
              " {'step': 142, 'train_loss': 5.857546806335449},\n",
              " {'step': 143, 'train_loss': 5.841247081756592},\n",
              " {'step': 144, 'train_loss': 5.7828192710876465},\n",
              " {'step': 145, 'train_loss': 5.7508111000061035},\n",
              " {'step': 146, 'train_loss': 5.657776355743408},\n",
              " {'step': 147, 'train_loss': 5.773700714111328},\n",
              " {'step': 148, 'train_loss': 5.783103942871094},\n",
              " {'step': 149, 'train_loss': 5.6356306076049805},\n",
              " {'step': 150, 'train_loss': 5.7269606590271},\n",
              " {'step': 151, 'train_loss': 5.664881229400635},\n",
              " {'step': 152, 'train_loss': 5.8323140144348145},\n",
              " {'step': 153, 'train_loss': 5.798088073730469},\n",
              " {'step': 154, 'train_loss': 5.622040748596191},\n",
              " {'step': 155, 'train_loss': 5.643208980560303},\n",
              " {'step': 156, 'train_loss': 5.625682353973389},\n",
              " {'step': 157, 'train_loss': 5.750513076782227},\n",
              " {'step': 158, 'train_loss': 5.640925884246826},\n",
              " {'step': 159, 'train_loss': 5.544066905975342},\n",
              " {'step': 160, 'train_loss': 5.526726245880127},\n",
              " {'step': 161, 'train_loss': 5.635190963745117},\n",
              " {'step': 162, 'train_loss': 5.542055606842041},\n",
              " {'step': 163, 'train_loss': 5.692262172698975},\n",
              " {'step': 164, 'train_loss': 5.516684532165527},\n",
              " {'step': 165, 'train_loss': 5.639286518096924},\n",
              " {'step': 166, 'train_loss': 5.5649003982543945},\n",
              " {'step': 167, 'train_loss': 5.659287452697754},\n",
              " {'step': 168, 'train_loss': 5.723378658294678},\n",
              " {'step': 169, 'train_loss': 5.550490379333496},\n",
              " {'step': 170, 'train_loss': 5.501671314239502},\n",
              " {'step': 171, 'train_loss': 5.554276943206787},\n",
              " {'step': 172, 'train_loss': 5.663266658782959},\n",
              " {'step': 173, 'train_loss': 5.390931129455566},\n",
              " {'step': 174, 'train_loss': 5.539400100708008},\n",
              " {'step': 175, 'train_loss': 5.562276840209961},\n",
              " {'step': 176, 'train_loss': 5.4964823722839355},\n",
              " {'step': 177, 'train_loss': 5.461878299713135},\n",
              " {'step': 178, 'train_loss': 5.557440757751465},\n",
              " {'step': 179, 'train_loss': 5.599611282348633},\n",
              " {'step': 180, 'train_loss': 5.491677761077881},\n",
              " {'step': 181, 'train_loss': 5.663024425506592},\n",
              " {'step': 182, 'train_loss': 5.459636211395264},\n",
              " {'step': 183, 'train_loss': 5.422452449798584},\n",
              " {'step': 184, 'train_loss': 5.511804580688477},\n",
              " {'step': 185, 'train_loss': 5.4484710693359375},\n",
              " {'step': 186, 'train_loss': 5.597130298614502},\n",
              " {'step': 187, 'train_loss': 5.456928730010986},\n",
              " {'step': 188, 'train_loss': 5.553258895874023},\n",
              " {'step': 189, 'train_loss': 5.411586284637451},\n",
              " {'step': 190, 'train_loss': 5.478546619415283},\n",
              " {'step': 191, 'train_loss': 5.59134578704834},\n",
              " {'step': 192, 'train_loss': 5.498397350311279},\n",
              " {'step': 193, 'train_loss': 5.555095672607422},\n",
              " {'step': 194, 'train_loss': 5.665139198303223},\n",
              " {'step': 195, 'train_loss': 5.599613189697266},\n",
              " {'step': 196, 'train_loss': 5.510522842407227},\n",
              " {'step': 197, 'train_loss': 5.527666091918945},\n",
              " {'step': 198, 'train_loss': 5.446256160736084},\n",
              " {'step': 199, 'train_loss': 5.387380123138428},\n",
              " {'step': 200, 'train_loss': 5.571355819702148},\n",
              " {'step': 201, 'train_loss': 5.513912677764893},\n",
              " {'step': 202, 'train_loss': 5.607326030731201},\n",
              " {'step': 203, 'train_loss': 5.477540016174316},\n",
              " {'step': 204, 'train_loss': 5.47022819519043},\n",
              " {'step': 205, 'train_loss': 5.48403263092041},\n",
              " {'step': 206, 'train_loss': 5.518249988555908},\n",
              " {'step': 207, 'train_loss': 5.512309551239014},\n",
              " {'step': 208, 'train_loss': 5.531373023986816},\n",
              " {'step': 209, 'train_loss': 5.429182052612305},\n",
              " {'step': 210, 'train_loss': 5.482989311218262},\n",
              " {'step': 211, 'train_loss': 5.593931198120117},\n",
              " {'step': 212, 'train_loss': 5.483344554901123},\n",
              " {'step': 213, 'train_loss': 5.4552903175354},\n",
              " {'step': 214, 'train_loss': 5.425174713134766},\n",
              " {'step': 215, 'train_loss': 5.394619941711426},\n",
              " {'step': 216, 'train_loss': 5.496830940246582},\n",
              " {'step': 217, 'train_loss': 5.533327102661133},\n",
              " {'step': 218, 'train_loss': 5.4912238121032715},\n",
              " {'step': 219, 'train_loss': 5.562330722808838},\n",
              " {'step': 220, 'train_loss': 5.304871082305908},\n",
              " {'step': 221, 'train_loss': 5.3457746505737305},\n",
              " {'step': 222, 'train_loss': 5.41758918762207},\n",
              " {'step': 223, 'train_loss': 5.411736011505127},\n",
              " {'step': 224, 'train_loss': 5.412827014923096},\n",
              " {'step': 225, 'train_loss': 5.3450517654418945},\n",
              " {'step': 226, 'train_loss': 5.35407829284668},\n",
              " {'step': 227, 'train_loss': 5.5518341064453125},\n",
              " {'step': 228, 'train_loss': 5.4043169021606445},\n",
              " {'step': 229, 'train_loss': 5.436760902404785},\n",
              " {'step': 230, 'train_loss': 5.48104190826416},\n",
              " {'step': 231, 'train_loss': 5.299251079559326},\n",
              " {'step': 232, 'train_loss': 5.580989360809326},\n",
              " {'step': 233, 'train_loss': 5.41370153427124},\n",
              " {'step': 234, 'train_loss': 5.181121826171875},\n",
              " {'step': 235, 'train_loss': 5.367734432220459},\n",
              " {'step': 236, 'train_loss': 5.275777339935303},\n",
              " {'step': 237, 'train_loss': 5.550502300262451},\n",
              " {'step': 238, 'train_loss': 5.493572235107422},\n",
              " {'step': 239, 'train_loss': 5.453638553619385},\n",
              " {'step': 240, 'train_loss': 5.390020370483398},\n",
              " {'step': 241, 'train_loss': 5.64306640625},\n",
              " {'step': 242, 'train_loss': 5.400513648986816},\n",
              " {'step': 243, 'train_loss': 5.425976276397705},\n",
              " {'step': 244, 'train_loss': 5.3698296546936035},\n",
              " {'step': 245, 'train_loss': 5.198696613311768},\n",
              " {'step': 246, 'train_loss': 5.209316730499268},\n",
              " {'step': 247, 'train_loss': 5.377569675445557},\n",
              " {'step': 248, 'train_loss': 5.4149627685546875},\n",
              " {'step': 249, 'train_loss': 5.3666205406188965},\n",
              " {'step': 250, 'train_loss': 5.333164215087891},\n",
              " {'step': 251, 'train_loss': 5.156434059143066},\n",
              " {'step': 252, 'train_loss': 5.3128461837768555},\n",
              " {'step': 253, 'train_loss': 5.443748950958252},\n",
              " {'step': 254, 'train_loss': 5.282620906829834},\n",
              " {'step': 255, 'train_loss': 5.2941083908081055},\n",
              " {'step': 256, 'train_loss': 5.236748695373535},\n",
              " {'step': 257, 'train_loss': 5.346299171447754},\n",
              " {'step': 258, 'train_loss': 5.353781700134277},\n",
              " {'step': 259, 'train_loss': 5.340931415557861},\n",
              " {'step': 260, 'train_loss': 5.228150367736816},\n",
              " {'step': 261, 'train_loss': 5.342605113983154},\n",
              " {'step': 262, 'train_loss': 5.388302326202393},\n",
              " {'step': 263, 'train_loss': 5.460541248321533},\n",
              " {'step': 264, 'train_loss': 5.427804470062256},\n",
              " {'step': 265, 'train_loss': 5.254043102264404},\n",
              " {'step': 266, 'train_loss': 5.221750259399414},\n",
              " {'step': 267, 'train_loss': 5.38762903213501},\n",
              " {'step': 268, 'train_loss': 5.255697727203369},\n",
              " {'step': 269, 'train_loss': 5.259950637817383},\n",
              " {'step': 270, 'train_loss': 5.17145299911499},\n",
              " {'step': 271, 'train_loss': 5.386752605438232},\n",
              " {'step': 272, 'train_loss': 5.239328861236572},\n",
              " {'step': 273, 'train_loss': 5.372757911682129},\n",
              " {'step': 274, 'train_loss': 5.205066680908203},\n",
              " {'step': 275, 'train_loss': 5.192701816558838},\n",
              " {'step': 276, 'train_loss': 5.143523216247559},\n",
              " {'step': 277, 'train_loss': 5.302921772003174},\n",
              " {'step': 278, 'train_loss': 5.202968120574951},\n",
              " {'step': 279, 'train_loss': 5.311514377593994},\n",
              " {'step': 280, 'train_loss': 5.29379940032959},\n",
              " {'step': 281, 'train_loss': 5.106523036956787},\n",
              " {'step': 282, 'train_loss': 5.1381611824035645},\n",
              " {'step': 283, 'train_loss': 5.278992652893066},\n",
              " {'step': 284, 'train_loss': 5.234774589538574},\n",
              " {'step': 285, 'train_loss': 5.253359317779541},\n",
              " {'step': 286, 'train_loss': 5.254481315612793},\n",
              " {'step': 287, 'train_loss': 5.230638027191162},\n",
              " {'step': 288, 'train_loss': 5.305098056793213},\n",
              " {'step': 289, 'train_loss': 5.227379322052002},\n",
              " {'step': 290, 'train_loss': 5.2933573722839355},\n",
              " {'step': 291, 'train_loss': 5.462745189666748},\n",
              " {'step': 292, 'train_loss': 5.202146530151367},\n",
              " {'step': 293, 'train_loss': 5.285743713378906},\n",
              " {'step': 294, 'train_loss': 5.336248397827148},\n",
              " {'step': 295, 'train_loss': 5.283276557922363},\n",
              " {'step': 296, 'train_loss': 5.275354862213135},\n",
              " {'step': 297, 'train_loss': 5.258694171905518},\n",
              " {'step': 298, 'train_loss': 5.278975963592529},\n",
              " {'step': 299, 'train_loss': 5.130582809448242},\n",
              " {'step': 300, 'train_loss': 5.3244099617004395},\n",
              " {'step': 301, 'train_loss': 5.316249847412109},\n",
              " {'step': 302, 'train_loss': 5.144835948944092},\n",
              " {'step': 303, 'train_loss': 5.181732654571533},\n",
              " {'step': 304, 'train_loss': 5.234304428100586},\n",
              " {'step': 305, 'train_loss': 5.360167980194092},\n",
              " {'step': 306, 'train_loss': 5.211554050445557},\n",
              " {'step': 307, 'train_loss': 5.216710567474365},\n",
              " {'step': 308, 'train_loss': 5.191037178039551},\n",
              " {'step': 309, 'train_loss': 5.253116607666016},\n",
              " {'step': 310, 'train_loss': 5.272846698760986},\n",
              " {'step': 311, 'train_loss': 5.222359657287598},\n",
              " {'step': 312, 'train_loss': 5.204648017883301},\n",
              " {'step': 313, 'train_loss': 5.246396064758301},\n",
              " {'step': 314, 'train_loss': 5.259006977081299},\n",
              " {'step': 315, 'train_loss': 5.206407070159912},\n",
              " {'step': 316, 'train_loss': 5.08339262008667},\n",
              " {'step': 317, 'train_loss': 5.295568466186523},\n",
              " {'step': 318, 'train_loss': 5.240293025970459},\n",
              " {'step': 319, 'train_loss': 5.213573455810547},\n",
              " {'step': 320, 'train_loss': 4.895663261413574},\n",
              " {'step': 321, 'train_loss': 5.50667667388916},\n",
              " {'step': 322, 'train_loss': 5.187763690948486},\n",
              " {'step': 323, 'train_loss': 5.250135898590088},\n",
              " {'step': 324, 'train_loss': 5.1063313484191895},\n",
              " {'step': 325, 'train_loss': 5.174783229827881},\n",
              " {'step': 326, 'train_loss': 5.233711242675781},\n",
              " {'step': 327, 'train_loss': 5.135952472686768},\n",
              " {'step': 328, 'train_loss': 5.156679630279541},\n",
              " {'step': 329, 'train_loss': 5.114612579345703},\n",
              " {'step': 330, 'train_loss': 5.157589912414551},\n",
              " {'step': 331, 'train_loss': 5.21737813949585},\n",
              " {'step': 332, 'train_loss': 5.2145538330078125},\n",
              " {'step': 333, 'train_loss': 5.105071067810059},\n",
              " {'step': 334, 'train_loss': 5.173450946807861},\n",
              " {'step': 335, 'train_loss': 5.268897533416748},\n",
              " {'step': 336, 'train_loss': 5.095746994018555},\n",
              " {'step': 337, 'train_loss': 5.074581623077393},\n",
              " {'step': 338, 'train_loss': 5.216559886932373},\n",
              " {'step': 339, 'train_loss': 5.231313228607178},\n",
              " {'step': 340, 'train_loss': 5.179142475128174},\n",
              " {'step': 341, 'train_loss': 5.070371627807617},\n",
              " {'step': 342, 'train_loss': 5.1507720947265625},\n",
              " {'step': 343, 'train_loss': 5.125454425811768},\n",
              " {'step': 344, 'train_loss': 5.247156620025635},\n",
              " {'step': 345, 'train_loss': 4.955747127532959},\n",
              " {'step': 346, 'train_loss': 5.198351860046387},\n",
              " {'step': 347, 'train_loss': 5.244842052459717},\n",
              " {'step': 348, 'train_loss': 5.1056013107299805},\n",
              " {'step': 349, 'train_loss': 5.222116470336914},\n",
              " {'step': 350, 'train_loss': 5.171998023986816},\n",
              " {'step': 351, 'train_loss': 5.087792873382568},\n",
              " {'step': 352, 'train_loss': 5.151352882385254},\n",
              " {'step': 353, 'train_loss': 5.072177886962891},\n",
              " {'step': 354, 'train_loss': 5.1587090492248535},\n",
              " {'step': 355, 'train_loss': 5.172445297241211},\n",
              " {'step': 356, 'train_loss': 5.290968418121338},\n",
              " {'step': 357, 'train_loss': 5.2038116455078125},\n",
              " {'step': 358, 'train_loss': 5.205150604248047},\n",
              " {'step': 359, 'train_loss': 5.112959861755371},\n",
              " {'step': 360, 'train_loss': 5.100018501281738},\n",
              " {'step': 361, 'train_loss': 5.30513858795166},\n",
              " {'step': 362, 'train_loss': 5.061429500579834},\n",
              " {'step': 363, 'train_loss': 5.306804180145264},\n",
              " {'step': 364, 'train_loss': 5.22298526763916},\n",
              " {'step': 365, 'train_loss': 4.979709148406982},\n",
              " {'step': 366, 'train_loss': 5.270254135131836},\n",
              " {'step': 367, 'train_loss': 5.341934680938721},\n",
              " {'step': 368, 'train_loss': 5.328076362609863},\n",
              " {'step': 369, 'train_loss': 5.200632095336914},\n",
              " {'step': 370, 'train_loss': 5.0119218826293945},\n",
              " {'step': 371, 'train_loss': 5.029152870178223},\n",
              " {'step': 372, 'train_loss': 5.143714904785156},\n",
              " {'step': 373, 'train_loss': 5.10402774810791},\n",
              " {'step': 374, 'train_loss': 5.082812309265137},\n",
              " {'step': 375, 'train_loss': 5.298189163208008},\n",
              " {'step': 376, 'train_loss': 5.0597686767578125},\n",
              " {'step': 377, 'train_loss': 5.093031406402588},\n",
              " {'step': 378, 'train_loss': 5.162484169006348},\n",
              " {'step': 379, 'train_loss': 5.286736488342285},\n",
              " {'step': 380, 'train_loss': 5.101831436157227},\n",
              " {'step': 381, 'train_loss': 5.166261672973633},\n",
              " {'step': 382, 'train_loss': 5.011640548706055},\n",
              " {'step': 383, 'train_loss': 5.035333633422852},\n",
              " {'step': 384, 'train_loss': 5.036679744720459},\n",
              " {'step': 385, 'train_loss': 5.306996822357178},\n",
              " {'step': 386, 'train_loss': 5.0076003074646},\n",
              " {'step': 387, 'train_loss': 5.093479633331299},\n",
              " {'step': 388, 'train_loss': 4.976170063018799},\n",
              " {'step': 389, 'train_loss': 4.916290760040283},\n",
              " {'step': 390, 'train_loss': 5.040968418121338},\n",
              " {'step': 391, 'train_loss': 5.125514507293701},\n",
              " {'step': 392, 'train_loss': 5.093578338623047},\n",
              " {'step': 393, 'train_loss': 5.078884124755859},\n",
              " {'step': 394, 'train_loss': 5.019901275634766},\n",
              " {'step': 395, 'train_loss': 5.083425045013428},\n",
              " {'step': 396, 'train_loss': 5.183268070220947},\n",
              " {'step': 397, 'train_loss': 5.118241786956787},\n",
              " {'step': 398, 'train_loss': 5.050731658935547},\n",
              " {'step': 399, 'train_loss': 5.223462104797363},\n",
              " {'step': 400, 'train_loss': 5.006255149841309},\n",
              " {'step': 401, 'train_loss': 5.163806915283203},\n",
              " {'step': 402, 'train_loss': 5.151505947113037},\n",
              " {'step': 403, 'train_loss': 5.0700225830078125},\n",
              " {'step': 404, 'train_loss': 5.098755836486816},\n",
              " {'step': 405, 'train_loss': 5.1258015632629395},\n",
              " {'step': 406, 'train_loss': 5.315492630004883},\n",
              " {'step': 407, 'train_loss': 5.060413360595703},\n",
              " {'step': 408, 'train_loss': 5.063150405883789},\n",
              " {'step': 409, 'train_loss': 5.16451358795166},\n",
              " {'step': 410, 'train_loss': 4.921462535858154},\n",
              " {'step': 411, 'train_loss': 5.141750812530518},\n",
              " {'step': 412, 'train_loss': 5.0962958335876465},\n",
              " {'step': 413, 'train_loss': 5.095948219299316},\n",
              " {'step': 414, 'train_loss': 5.161494731903076},\n",
              " {'step': 415, 'train_loss': 5.221571445465088},\n",
              " {'step': 416, 'train_loss': 5.08030366897583},\n",
              " {'step': 417, 'train_loss': 5.055623531341553},\n",
              " {'step': 418, 'train_loss': 5.023617267608643},\n",
              " {'step': 419, 'train_loss': 5.07837438583374},\n",
              " {'step': 420, 'train_loss': 5.092581748962402},\n",
              " {'step': 421, 'train_loss': 5.072193622589111},\n",
              " {'step': 422, 'train_loss': 5.03213357925415},\n",
              " {'step': 423, 'train_loss': 5.305527687072754},\n",
              " {'step': 424, 'train_loss': 5.157072067260742},\n",
              " {'step': 425, 'train_loss': 5.059497356414795},\n",
              " {'step': 426, 'train_loss': 5.082494258880615},\n",
              " {'step': 427, 'train_loss': 5.146284103393555},\n",
              " {'step': 428, 'train_loss': 5.144371032714844},\n",
              " {'step': 429, 'train_loss': 5.043665885925293},\n",
              " {'step': 430, 'train_loss': 5.044711589813232},\n",
              " {'step': 431, 'train_loss': 5.031794548034668},\n",
              " {'step': 432, 'train_loss': 5.334057807922363},\n",
              " {'step': 433, 'train_loss': 5.106303691864014},\n",
              " {'step': 434, 'train_loss': 5.100714683532715},\n",
              " {'step': 435, 'train_loss': 5.054747104644775},\n",
              " {'step': 436, 'train_loss': 4.94317626953125},\n",
              " {'step': 437, 'train_loss': 4.928979873657227},\n",
              " {'step': 438, 'train_loss': 4.9707350730896},\n",
              " {'step': 439, 'train_loss': 5.006022930145264},\n",
              " {'step': 440, 'train_loss': 5.081789493560791},\n",
              " {'step': 441, 'train_loss': 5.076113224029541},\n",
              " {'step': 442, 'train_loss': 5.085782527923584},\n",
              " {'step': 443, 'train_loss': 4.937224388122559},\n",
              " {'step': 444, 'train_loss': 4.804088592529297},\n",
              " {'step': 445, 'train_loss': 5.01839017868042},\n",
              " {'step': 446, 'train_loss': 5.025193691253662},\n",
              " {'step': 447, 'train_loss': 4.9998626708984375},\n",
              " {'step': 448, 'train_loss': 5.040356159210205},\n",
              " {'step': 449, 'train_loss': 5.091433048248291},\n",
              " {'step': 450, 'train_loss': 5.015182018280029},\n",
              " {'step': 451, 'train_loss': 4.892190933227539},\n",
              " {'step': 452, 'train_loss': 4.899415016174316},\n",
              " {'step': 453, 'train_loss': 5.003859519958496},\n",
              " {'step': 454, 'train_loss': 5.149337291717529},\n",
              " {'step': 455, 'train_loss': 5.0463948249816895},\n",
              " {'step': 456, 'train_loss': 4.990828514099121},\n",
              " {'step': 457, 'train_loss': 5.085023403167725},\n",
              " {'step': 458, 'train_loss': 5.0593767166137695},\n",
              " {'step': 459, 'train_loss': 5.015804290771484},\n",
              " {'step': 460, 'train_loss': 5.101353168487549},\n",
              " {'step': 461, 'train_loss': 5.027591705322266},\n",
              " {'step': 462, 'train_loss': 5.019528865814209},\n",
              " {'step': 463, 'train_loss': 4.984124660491943},\n",
              " {'step': 464, 'train_loss': 4.940833568572998},\n",
              " {'step': 465, 'train_loss': 4.920216083526611},\n",
              " {'step': 466, 'train_loss': 4.989704132080078},\n",
              " {'step': 467, 'train_loss': 4.992586135864258},\n",
              " {'step': 468, 'train_loss': 5.075007438659668},\n",
              " {'step': 469, 'train_loss': 5.003719329833984},\n",
              " {'step': 470, 'train_loss': 4.943905353546143},\n",
              " {'step': 471, 'train_loss': 5.14833402633667},\n",
              " {'step': 472, 'train_loss': 5.0780720710754395},\n",
              " {'step': 473, 'train_loss': 4.882382392883301},\n",
              " {'step': 474, 'train_loss': 5.2562127113342285},\n",
              " {'step': 475, 'train_loss': 4.818055629730225},\n",
              " {'step': 476, 'train_loss': 5.037609577178955},\n",
              " {'step': 477, 'train_loss': 5.123337745666504},\n",
              " {'step': 478, 'train_loss': 4.985408306121826},\n",
              " {'step': 479, 'train_loss': 4.921868801116943},\n",
              " {'step': 480, 'train_loss': 4.8449320793151855},\n",
              " {'step': 481, 'train_loss': 5.036040782928467},\n",
              " {'step': 482, 'train_loss': 4.898875713348389},\n",
              " {'step': 483, 'train_loss': 5.009551525115967},\n",
              " {'step': 484, 'train_loss': 4.94397497177124},\n",
              " {'step': 485, 'train_loss': 5.13902473449707},\n",
              " {'step': 486, 'train_loss': 5.0791544914245605},\n",
              " {'step': 487, 'train_loss': 4.988691806793213},\n",
              " {'step': 488, 'train_loss': 5.013467788696289},\n",
              " {'step': 489, 'train_loss': 5.023211479187012},\n",
              " {'step': 490, 'train_loss': 4.9566168785095215},\n",
              " {'step': 491, 'train_loss': 5.128715991973877},\n",
              " {'step': 492, 'train_loss': 4.930099010467529},\n",
              " {'step': 493, 'train_loss': 4.9543046951293945},\n",
              " {'step': 494, 'train_loss': 5.083960056304932},\n",
              " {'step': 495, 'train_loss': 5.027308464050293},\n",
              " {'step': 496, 'train_loss': 5.060235977172852},\n",
              " {'step': 497, 'train_loss': 4.944437503814697},\n",
              " {'step': 498, 'train_loss': 4.9654765129089355},\n",
              " {'step': 499, 'train_loss': 5.12076997756958},\n",
              " {'step': 500, 'train_loss': 4.977789878845215},\n",
              " {'step': 501, 'train_loss': 4.978320121765137},\n",
              " {'step': 502, 'train_loss': 4.9235663414001465},\n",
              " {'step': 503, 'train_loss': 5.032637119293213},\n",
              " {'step': 504, 'train_loss': 5.109720706939697},\n",
              " {'step': 505, 'train_loss': 5.1807451248168945},\n",
              " {'step': 506, 'train_loss': 5.0508222579956055},\n",
              " {'step': 507, 'train_loss': 5.016037940979004},\n",
              " {'step': 508, 'train_loss': 5.1780195236206055},\n",
              " {'step': 509, 'train_loss': 5.124094486236572},\n",
              " {'step': 510, 'train_loss': 5.054069995880127},\n",
              " {'step': 511, 'train_loss': 5.034177780151367},\n",
              " {'step': 512, 'train_loss': 4.958723545074463},\n",
              " {'step': 513, 'train_loss': 4.880174160003662},\n",
              " {'step': 514, 'train_loss': 4.825078964233398},\n",
              " {'step': 515, 'train_loss': 5.016269207000732},\n",
              " {'step': 516, 'train_loss': 4.974560737609863},\n",
              " {'step': 517, 'train_loss': 4.799953460693359},\n",
              " {'step': 518, 'train_loss': 5.080667018890381},\n",
              " {'step': 519, 'train_loss': 4.890087604522705},\n",
              " {'step': 520, 'train_loss': 4.807104110717773},\n",
              " {'step': 521, 'train_loss': 5.067512035369873},\n",
              " {'step': 522, 'train_loss': 5.047885894775391},\n",
              " {'step': 523, 'train_loss': 4.994065761566162},\n",
              " {'step': 524, 'train_loss': 5.068122863769531},\n",
              " {'step': 525, 'train_loss': 5.0230302810668945},\n",
              " {'step': 526, 'train_loss': 5.002374649047852},\n",
              " {'step': 527, 'train_loss': 5.163885593414307},\n",
              " {'step': 528, 'train_loss': 5.157695293426514},\n",
              " {'step': 529, 'train_loss': 5.066279888153076},\n",
              " {'step': 530, 'train_loss': 4.8883442878723145},\n",
              " {'step': 531, 'train_loss': 4.973006725311279},\n",
              " {'step': 532, 'train_loss': 5.201048851013184},\n",
              " {'step': 533, 'train_loss': 4.960421085357666},\n",
              " {'step': 534, 'train_loss': 4.966756343841553},\n",
              " {'step': 535, 'train_loss': 4.993124961853027},\n",
              " {'step': 536, 'train_loss': 4.9253010749816895},\n",
              " {'step': 537, 'train_loss': 4.954239845275879},\n",
              " {'step': 538, 'train_loss': 4.973170280456543},\n",
              " {'step': 539, 'train_loss': 5.002407550811768},\n",
              " {'step': 540, 'train_loss': 4.930235385894775},\n",
              " {'step': 541, 'train_loss': 4.976437091827393},\n",
              " {'step': 542, 'train_loss': 4.968847274780273},\n",
              " {'step': 543, 'train_loss': 4.97325325012207},\n",
              " {'step': 544, 'train_loss': 4.949077606201172},\n",
              " {'step': 545, 'train_loss': 5.105555534362793},\n",
              " {'step': 546, 'train_loss': 4.924804210662842},\n",
              " {'step': 547, 'train_loss': 4.904389381408691},\n",
              " {'step': 548, 'train_loss': 5.0476837158203125},\n",
              " {'step': 549, 'train_loss': 5.156867027282715},\n",
              " {'step': 550, 'train_loss': 5.01181697845459},\n",
              " {'step': 551, 'train_loss': 5.041390419006348},\n",
              " {'step': 552, 'train_loss': 5.03542947769165},\n",
              " {'step': 553, 'train_loss': 4.950960636138916},\n",
              " {'step': 554, 'train_loss': 5.106527328491211},\n",
              " {'step': 555, 'train_loss': 4.907662391662598},\n",
              " {'step': 556, 'train_loss': 5.009424686431885},\n",
              " {'step': 557, 'train_loss': 4.871612548828125},\n",
              " {'step': 558, 'train_loss': 5.002490997314453},\n",
              " {'step': 559, 'train_loss': 4.842870235443115},\n",
              " {'step': 560, 'train_loss': 4.888885021209717},\n",
              " {'step': 561, 'train_loss': 5.004605293273926},\n",
              " {'step': 562, 'train_loss': 5.056156158447266},\n",
              " {'step': 563, 'train_loss': 5.050524711608887},\n",
              " {'step': 564, 'train_loss': 4.852752208709717},\n",
              " {'step': 565, 'train_loss': 5.127012252807617},\n",
              " {'step': 566, 'train_loss': 5.086915016174316},\n",
              " {'step': 567, 'train_loss': 4.917850494384766},\n",
              " {'step': 568, 'train_loss': 4.946150779724121},\n",
              " {'step': 569, 'train_loss': 5.019569396972656},\n",
              " {'step': 570, 'train_loss': 4.7489542961120605},\n",
              " {'step': 571, 'train_loss': 4.915191173553467},\n",
              " {'step': 572, 'train_loss': 5.098698139190674},\n",
              " {'step': 573, 'train_loss': 4.999419689178467},\n",
              " {'step': 574, 'train_loss': 5.158798694610596},\n",
              " {'step': 575, 'train_loss': 5.031079292297363},\n",
              " {'step': 576, 'train_loss': 5.061727523803711},\n",
              " {'step': 577, 'train_loss': 4.797098636627197},\n",
              " {'step': 578, 'train_loss': 4.893768787384033},\n",
              " {'step': 579, 'train_loss': 4.9636006355285645},\n",
              " {'step': 580, 'train_loss': 4.9237589836120605},\n",
              " {'step': 581, 'train_loss': 4.984252452850342},\n",
              " {'step': 582, 'train_loss': 4.800009250640869},\n",
              " {'step': 583, 'train_loss': 4.881263732910156},\n",
              " {'step': 584, 'train_loss': 4.960326671600342},\n",
              " {'step': 585, 'train_loss': 4.921307563781738},\n",
              " {'step': 586, 'train_loss': 4.927623748779297},\n",
              " {'step': 587, 'train_loss': 4.93699836730957},\n",
              " {'step': 588, 'train_loss': 4.800010681152344},\n",
              " {'step': 589, 'train_loss': 4.922676086425781},\n",
              " {'step': 590, 'train_loss': 4.922836780548096},\n",
              " {'step': 591, 'train_loss': 4.870185375213623},\n",
              " {'step': 592, 'train_loss': 4.940258502960205},\n",
              " {'step': 593, 'train_loss': 4.912626266479492},\n",
              " {'step': 594, 'train_loss': 4.880251407623291},\n",
              " {'step': 595, 'train_loss': 5.0073018074035645},\n",
              " {'step': 596, 'train_loss': 4.949254989624023},\n",
              " {'step': 597, 'train_loss': 4.861274719238281},\n",
              " {'step': 598, 'train_loss': 4.933833599090576},\n",
              " {'step': 599, 'train_loss': 4.872341156005859},\n",
              " {'step': 600, 'train_loss': 4.9262919425964355},\n",
              " {'step': 601, 'train_loss': 5.059436798095703},\n",
              " {'step': 602, 'train_loss': 5.071960926055908},\n",
              " {'step': 603, 'train_loss': 4.998400688171387},\n",
              " {'step': 604, 'train_loss': 4.873552322387695},\n",
              " {'step': 605, 'train_loss': 4.856155872344971},\n",
              " {'step': 606, 'train_loss': 4.899999141693115},\n",
              " {'step': 607, 'train_loss': 4.90328311920166},\n",
              " {'step': 608, 'train_loss': 4.968526363372803},\n",
              " {'step': 609, 'train_loss': 4.836572170257568},\n",
              " {'step': 610, 'train_loss': 4.8698859214782715},\n",
              " {'step': 611, 'train_loss': 4.817019462585449},\n",
              " {'step': 612, 'train_loss': 4.964895248413086},\n",
              " {'step': 613, 'train_loss': 4.891618728637695},\n",
              " {'step': 614, 'train_loss': 4.944984436035156},\n",
              " {'step': 615, 'train_loss': 4.873797416687012},\n",
              " {'step': 616, 'train_loss': 4.8616719245910645},\n",
              " {'step': 617, 'train_loss': 5.0115180015563965},\n",
              " {'step': 618, 'train_loss': 4.917518138885498},\n",
              " {'step': 619, 'train_loss': 4.886629104614258},\n",
              " {'step': 620, 'train_loss': 5.0087761878967285},\n",
              " {'step': 621, 'train_loss': 4.889346122741699},\n",
              " {'step': 622, 'train_loss': 4.918785572052002},\n",
              " {'step': 623, 'train_loss': 5.024064064025879},\n",
              " {'step': 624, 'train_loss': 4.92282247543335},\n",
              " {'step': 625, 'train_loss': 4.891600608825684},\n",
              " {'step': 626, 'train_loss': 4.8728203773498535},\n",
              " {'step': 627, 'train_loss': 4.8233795166015625},\n",
              " {'step': 628, 'train_loss': 4.943695068359375},\n",
              " {'step': 629, 'train_loss': 4.853024482727051},\n",
              " {'step': 630, 'train_loss': 5.065876007080078},\n",
              " {'step': 631, 'train_loss': 5.069857120513916},\n",
              " {'step': 632, 'train_loss': 5.016073703765869},\n",
              " {'step': 633, 'train_loss': 5.041351318359375},\n",
              " {'step': 634, 'train_loss': 4.945940971374512},\n",
              " {'step': 635, 'train_loss': 4.961482048034668},\n",
              " {'step': 636, 'train_loss': 4.914465427398682},\n",
              " {'step': 637, 'train_loss': 5.028171539306641},\n",
              " {'step': 638, 'train_loss': 5.029642105102539},\n",
              " {'step': 639, 'train_loss': 5.0083794593811035},\n",
              " {'step': 640, 'train_loss': 4.903229236602783},\n",
              " {'step': 641, 'train_loss': 4.844906806945801},\n",
              " {'step': 642, 'train_loss': 4.936007499694824},\n",
              " {'step': 643, 'train_loss': 4.84823751449585},\n",
              " {'step': 644, 'train_loss': 4.803854465484619},\n",
              " {'step': 645, 'train_loss': 4.85464334487915},\n",
              " {'step': 646, 'train_loss': 4.885584354400635},\n",
              " {'step': 647, 'train_loss': 4.897927284240723},\n",
              " {'step': 648, 'train_loss': 4.927600860595703},\n",
              " {'step': 649, 'train_loss': 4.7541422843933105},\n",
              " {'step': 650, 'train_loss': 4.9117326736450195},\n",
              " {'step': 651, 'train_loss': 4.975740909576416},\n",
              " {'step': 652, 'train_loss': 4.81834077835083},\n",
              " {'step': 653, 'train_loss': 5.004146575927734},\n",
              " {'step': 654, 'train_loss': 4.871242523193359},\n",
              " {'step': 655, 'train_loss': 4.8181986808776855},\n",
              " {'step': 656, 'train_loss': 4.78465461730957},\n",
              " {'step': 657, 'train_loss': 4.8530988693237305},\n",
              " {'step': 658, 'train_loss': 4.935529708862305},\n",
              " {'step': 659, 'train_loss': 4.82033109664917},\n",
              " {'step': 660, 'train_loss': 4.767595291137695},\n",
              " {'step': 661, 'train_loss': 4.81071138381958},\n",
              " {'step': 662, 'train_loss': 4.808255195617676},\n",
              " {'step': 663, 'train_loss': 4.812199115753174},\n",
              " {'step': 664, 'train_loss': 4.932823181152344},\n",
              " {'step': 665, 'train_loss': 4.791365146636963},\n",
              " {'step': 666, 'train_loss': 4.9075164794921875},\n",
              " {'step': 667, 'train_loss': 4.767513751983643},\n",
              " {'step': 668, 'train_loss': 4.905014514923096},\n",
              " {'step': 669, 'train_loss': 4.834194183349609},\n",
              " {'step': 670, 'train_loss': 4.734471321105957},\n",
              " {'step': 671, 'train_loss': 4.823004722595215},\n",
              " {'step': 672, 'train_loss': 4.879371166229248},\n",
              " {'step': 673, 'train_loss': 4.9375224113464355},\n",
              " {'step': 674, 'train_loss': 5.001861095428467},\n",
              " {'step': 675, 'train_loss': 4.739859580993652},\n",
              " {'step': 676, 'train_loss': 4.82335901260376},\n",
              " {'step': 677, 'train_loss': 4.67854118347168},\n",
              " {'step': 678, 'train_loss': 4.896256446838379},\n",
              " {'step': 679, 'train_loss': 5.042855739593506},\n",
              " {'step': 680, 'train_loss': 4.881466865539551},\n",
              " {'step': 681, 'train_loss': 4.845956802368164},\n",
              " {'step': 682, 'train_loss': 4.920372009277344},\n",
              " {'step': 683, 'train_loss': 4.6515655517578125},\n",
              " {'step': 684, 'train_loss': 4.932341575622559},\n",
              " {'step': 685, 'train_loss': 4.871348857879639},\n",
              " {'step': 686, 'train_loss': 4.805248737335205},\n",
              " {'step': 687, 'train_loss': 4.764315605163574},\n",
              " {'step': 688, 'train_loss': 4.864315986633301},\n",
              " {'step': 689, 'train_loss': 4.788247108459473},\n",
              " {'step': 690, 'train_loss': 4.947995185852051},\n",
              " {'step': 691, 'train_loss': 4.944516181945801},\n",
              " {'step': 692, 'train_loss': 4.895016670227051},\n",
              " {'step': 693, 'train_loss': 4.634767532348633},\n",
              " {'step': 694, 'train_loss': 4.853531360626221},\n",
              " {'step': 695, 'train_loss': 4.868062496185303},\n",
              " {'step': 696, 'train_loss': 4.72724723815918},\n",
              " {'step': 697, 'train_loss': 4.803262710571289},\n",
              " {'step': 698, 'train_loss': 4.7533040046691895},\n",
              " {'step': 699, 'train_loss': 4.709687232971191},\n",
              " {'step': 700, 'train_loss': 4.8886895179748535},\n",
              " {'step': 701, 'train_loss': 4.702383995056152},\n",
              " {'step': 702, 'train_loss': 4.809493064880371},\n",
              " {'step': 703, 'train_loss': 4.844295024871826},\n",
              " {'step': 704, 'train_loss': 4.81089973449707},\n",
              " {'step': 705, 'train_loss': 4.96072244644165},\n",
              " {'step': 706, 'train_loss': 4.841848373413086},\n",
              " {'step': 707, 'train_loss': 4.922619342803955},\n",
              " {'step': 708, 'train_loss': 4.900825500488281},\n",
              " {'step': 709, 'train_loss': 4.703988552093506},\n",
              " {'step': 710, 'train_loss': 4.67334508895874},\n",
              " {'step': 711, 'train_loss': 4.816013813018799},\n",
              " {'step': 712, 'train_loss': 4.760804653167725},\n",
              " {'step': 713, 'train_loss': 4.829108238220215},\n",
              " {'step': 714, 'train_loss': 4.884246826171875},\n",
              " {'step': 715, 'train_loss': 4.927090167999268},\n",
              " {'step': 716, 'train_loss': 4.824532508850098},\n",
              " {'step': 717, 'train_loss': 4.836040019989014},\n",
              " {'step': 718, 'train_loss': 4.77356481552124},\n",
              " {'step': 719, 'train_loss': 4.883303642272949},\n",
              " {'step': 720, 'train_loss': 4.736125469207764},\n",
              " {'step': 721, 'train_loss': 4.924013137817383},\n",
              " {'step': 722, 'train_loss': 4.9179911613464355},\n",
              " {'step': 723, 'train_loss': 4.9151201248168945},\n",
              " {'step': 724, 'train_loss': 4.63739538192749},\n",
              " {'step': 725, 'train_loss': 4.684614181518555},\n",
              " {'step': 726, 'train_loss': 4.814596176147461},\n",
              " {'step': 727, 'train_loss': 4.737786769866943},\n",
              " {'step': 728, 'train_loss': 4.830571174621582},\n",
              " {'step': 729, 'train_loss': 4.738523483276367},\n",
              " {'step': 730, 'train_loss': 4.824923515319824},\n",
              " {'step': 731, 'train_loss': 5.02046012878418},\n",
              " {'step': 732, 'train_loss': 4.865375995635986},\n",
              " {'step': 733, 'train_loss': 4.822602272033691},\n",
              " {'step': 734, 'train_loss': 4.897233009338379},\n",
              " {'step': 735, 'train_loss': 4.762199878692627},\n",
              " {'step': 736, 'train_loss': 4.814811706542969},\n",
              " {'step': 737, 'train_loss': 4.999599933624268},\n",
              " {'step': 738, 'train_loss': 4.7997870445251465},\n",
              " {'step': 739, 'train_loss': 4.764865875244141},\n",
              " {'step': 740, 'train_loss': 4.739400863647461},\n",
              " {'step': 741, 'train_loss': 4.785422325134277},\n",
              " {'step': 742, 'train_loss': 4.903478145599365},\n",
              " {'step': 743, 'train_loss': 4.860511302947998},\n",
              " {'step': 744, 'train_loss': 4.68583345413208},\n",
              " {'step': 745, 'train_loss': 4.917549133300781},\n",
              " {'step': 746, 'train_loss': 4.816150665283203},\n",
              " {'step': 747, 'train_loss': 4.739798545837402},\n",
              " {'step': 748, 'train_loss': 4.814108371734619},\n",
              " {'step': 749, 'train_loss': 4.756093502044678},\n",
              " {'step': 750, 'train_loss': 4.751804351806641},\n",
              " {'step': 751, 'train_loss': 4.963374614715576},\n",
              " {'step': 752, 'train_loss': 4.784327983856201},\n",
              " {'step': 753, 'train_loss': 4.826559066772461},\n",
              " {'step': 754, 'train_loss': 4.728576183319092},\n",
              " {'step': 755, 'train_loss': 4.845527172088623},\n",
              " {'step': 756, 'train_loss': 4.7639689445495605},\n",
              " {'step': 757, 'train_loss': 4.803358554840088},\n",
              " {'step': 758, 'train_loss': 4.592474937438965},\n",
              " {'step': 759, 'train_loss': 4.822757720947266},\n",
              " {'step': 760, 'train_loss': 4.845363616943359},\n",
              " {'step': 761, 'train_loss': 4.883949279785156},\n",
              " {'step': 762, 'train_loss': 4.848867893218994},\n",
              " {'step': 763, 'train_loss': 4.824899196624756},\n",
              " {'step': 764, 'train_loss': 4.790734767913818},\n",
              " {'step': 765, 'train_loss': 4.808805465698242},\n",
              " {'step': 766, 'train_loss': 4.7342448234558105},\n",
              " {'step': 767, 'train_loss': 4.949429512023926},\n",
              " {'step': 768, 'train_loss': 4.986042499542236},\n",
              " {'step': 769, 'train_loss': 4.787067413330078},\n",
              " {'step': 770, 'train_loss': 4.7711920738220215},\n",
              " {'step': 771, 'train_loss': 4.662242889404297},\n",
              " {'step': 772, 'train_loss': 4.721757411956787},\n",
              " {'step': 773, 'train_loss': 4.928629398345947},\n",
              " {'step': 774, 'train_loss': 4.7573442459106445},\n",
              " {'step': 775, 'train_loss': 4.707421779632568},\n",
              " {'step': 776, 'train_loss': 4.855259895324707},\n",
              " {'step': 777, 'train_loss': 4.946381092071533},\n",
              " {'step': 778, 'train_loss': 4.7584123611450195},\n",
              " {'step': 779, 'train_loss': 4.919162750244141},\n",
              " {'step': 780, 'train_loss': 4.7576775550842285},\n",
              " {'step': 781, 'train_loss': 4.8721466064453125},\n",
              " {'step': 782, 'train_loss': 4.715890407562256},\n",
              " {'step': 783, 'train_loss': 4.8499369621276855},\n",
              " {'step': 784, 'train_loss': 4.813864707946777},\n",
              " {'step': 785, 'train_loss': 4.744193077087402},\n",
              " {'step': 786, 'train_loss': 4.910788059234619},\n",
              " {'step': 787, 'train_loss': 4.803667068481445},\n",
              " {'step': 788, 'train_loss': 4.818739891052246},\n",
              " {'step': 789, 'train_loss': 4.818401336669922},\n",
              " {'step': 790, 'train_loss': 4.877914905548096},\n",
              " {'step': 791, 'train_loss': 4.788551330566406},\n",
              " {'step': 792, 'train_loss': 4.581672668457031},\n",
              " {'step': 793, 'train_loss': 4.725655555725098},\n",
              " {'step': 794, 'train_loss': 4.440052032470703},\n",
              " {'step': 795, 'train_loss': 4.7598090171813965},\n",
              " {'step': 796, 'train_loss': 4.895411491394043},\n",
              " {'step': 797, 'train_loss': 4.776676654815674},\n",
              " {'step': 798, 'train_loss': 4.749563217163086},\n",
              " {'step': 799, 'train_loss': 4.773685932159424},\n",
              " {'step': 800, 'train_loss': 4.973230361938477},\n",
              " {'step': 801, 'train_loss': 4.867336750030518},\n",
              " {'step': 802, 'train_loss': 4.871286869049072},\n",
              " {'step': 803, 'train_loss': 4.704392910003662},\n",
              " {'step': 804, 'train_loss': 4.946804046630859},\n",
              " {'step': 805, 'train_loss': 4.792552471160889},\n",
              " {'step': 806, 'train_loss': 4.716226100921631},\n",
              " {'step': 807, 'train_loss': 4.600923538208008},\n",
              " {'step': 808, 'train_loss': 4.716732501983643},\n",
              " {'step': 809, 'train_loss': 4.75696325302124},\n",
              " {'step': 810, 'train_loss': 4.857464790344238},\n",
              " {'step': 811, 'train_loss': 4.822353839874268},\n",
              " {'step': 812, 'train_loss': 4.789158821105957},\n",
              " {'step': 813, 'train_loss': 4.717778205871582},\n",
              " {'step': 814, 'train_loss': 4.815674304962158},\n",
              " {'step': 815, 'train_loss': 4.837523937225342},\n",
              " {'step': 816, 'train_loss': 4.9073486328125},\n",
              " {'step': 817, 'train_loss': 4.81270170211792},\n",
              " {'step': 818, 'train_loss': 4.758237838745117},\n",
              " {'step': 819, 'train_loss': 4.913079261779785},\n",
              " {'step': 820, 'train_loss': 4.737768650054932},\n",
              " {'step': 821, 'train_loss': 4.908742904663086},\n",
              " {'step': 822, 'train_loss': 4.7926926612854},\n",
              " {'step': 823, 'train_loss': 4.763210296630859},\n",
              " {'step': 824, 'train_loss': 4.82732629776001},\n",
              " {'step': 825, 'train_loss': 4.685711860656738},\n",
              " {'step': 826, 'train_loss': 4.87658166885376},\n",
              " {'step': 827, 'train_loss': 4.733327388763428},\n",
              " {'step': 828, 'train_loss': 4.906244277954102},\n",
              " {'step': 829, 'train_loss': 4.738551139831543},\n",
              " {'step': 830, 'train_loss': 4.811468601226807},\n",
              " {'step': 831, 'train_loss': 4.615466117858887},\n",
              " {'step': 832, 'train_loss': 4.846179962158203},\n",
              " {'step': 833, 'train_loss': 4.800503730773926},\n",
              " {'step': 834, 'train_loss': 4.651414394378662},\n",
              " {'step': 835, 'train_loss': 4.727301597595215},\n",
              " {'step': 836, 'train_loss': 4.725016117095947},\n",
              " {'step': 837, 'train_loss': 4.6528191566467285},\n",
              " {'step': 838, 'train_loss': 4.828373432159424},\n",
              " {'step': 839, 'train_loss': 4.71514892578125},\n",
              " {'step': 840, 'train_loss': 4.7281174659729},\n",
              " {'step': 841, 'train_loss': 4.820094108581543},\n",
              " {'step': 842, 'train_loss': 4.6863298416137695},\n",
              " {'step': 843, 'train_loss': 4.706833839416504},\n",
              " {'step': 844, 'train_loss': 4.737392902374268},\n",
              " {'step': 845, 'train_loss': 4.867528915405273},\n",
              " {'step': 846, 'train_loss': 4.651278018951416},\n",
              " {'step': 847, 'train_loss': 4.7404704093933105},\n",
              " {'step': 848, 'train_loss': 4.7077131271362305},\n",
              " {'step': 849, 'train_loss': 4.696532249450684},\n",
              " {'step': 850, 'train_loss': 4.643098831176758},\n",
              " {'step': 851, 'train_loss': 4.787202835083008},\n",
              " {'step': 852, 'train_loss': 4.783825874328613},\n",
              " {'step': 853, 'train_loss': 4.8985161781311035},\n",
              " {'step': 854, 'train_loss': 4.766648292541504},\n",
              " {'step': 855, 'train_loss': 4.949474334716797},\n",
              " {'step': 856, 'train_loss': 4.8357391357421875},\n",
              " {'step': 857, 'train_loss': 4.749491214752197},\n",
              " {'step': 858, 'train_loss': 4.988775730133057},\n",
              " {'step': 859, 'train_loss': 4.628385543823242},\n",
              " {'step': 860, 'train_loss': 4.75705623626709},\n",
              " {'step': 861, 'train_loss': 4.703607082366943},\n",
              " {'step': 862, 'train_loss': 4.760298728942871},\n",
              " {'step': 863, 'train_loss': 4.753278732299805},\n",
              " {'step': 864, 'train_loss': 4.73444128036499},\n",
              " {'step': 865, 'train_loss': 4.93168830871582},\n",
              " {'step': 866, 'train_loss': 4.656091213226318},\n",
              " {'step': 867, 'train_loss': 4.8041582107543945},\n",
              " {'step': 868, 'train_loss': 4.763566017150879},\n",
              " {'step': 869, 'train_loss': 4.805486679077148},\n",
              " {'step': 870, 'train_loss': 4.641883373260498},\n",
              " {'step': 871, 'train_loss': 4.733224391937256},\n",
              " {'step': 872, 'train_loss': 4.6237382888793945},\n",
              " {'step': 873, 'train_loss': 4.707955837249756},\n",
              " {'step': 874, 'train_loss': 4.843612194061279},\n",
              " {'step': 875, 'train_loss': 4.718810081481934},\n",
              " {'step': 876, 'train_loss': 4.5871710777282715},\n",
              " {'step': 877, 'train_loss': 4.728589057922363},\n",
              " {'step': 878, 'train_loss': 4.6306610107421875},\n",
              " {'step': 879, 'train_loss': 4.765659809112549},\n",
              " {'step': 880, 'train_loss': 4.764143943786621},\n",
              " {'step': 881, 'train_loss': 4.852651596069336},\n",
              " {'step': 882, 'train_loss': 4.697822093963623},\n",
              " {'step': 883, 'train_loss': 4.683632850646973},\n",
              " {'step': 884, 'train_loss': 4.83239221572876},\n",
              " {'step': 885, 'train_loss': 4.611653804779053},\n",
              " {'step': 886, 'train_loss': 4.748926162719727},\n",
              " {'step': 887, 'train_loss': 4.631779193878174},\n",
              " {'step': 888, 'train_loss': 4.7331767082214355},\n",
              " {'step': 889, 'train_loss': 4.683620452880859},\n",
              " {'step': 890, 'train_loss': 4.628809452056885},\n",
              " {'step': 891, 'train_loss': 4.662234783172607},\n",
              " {'step': 892, 'train_loss': 4.794139385223389},\n",
              " {'step': 893, 'train_loss': 4.725749969482422},\n",
              " {'step': 894, 'train_loss': 4.857354640960693},\n",
              " {'step': 895, 'train_loss': 4.906673908233643},\n",
              " {'step': 896, 'train_loss': 4.8066277503967285},\n",
              " {'step': 897, 'train_loss': 4.6546478271484375},\n",
              " {'step': 898, 'train_loss': 4.695059299468994},\n",
              " {'step': 899, 'train_loss': 4.781772613525391},\n",
              " {'step': 900, 'train_loss': 4.782492637634277},\n",
              " {'step': 901, 'train_loss': 4.942199230194092},\n",
              " {'step': 902, 'train_loss': 4.577890396118164},\n",
              " {'step': 903, 'train_loss': 4.65969705581665},\n",
              " {'step': 904, 'train_loss': 4.639951229095459},\n",
              " {'step': 905, 'train_loss': 4.599673748016357},\n",
              " {'step': 906, 'train_loss': 4.919940948486328},\n",
              " {'step': 907, 'train_loss': 4.662766933441162},\n",
              " {'step': 908, 'train_loss': 4.5024213790893555},\n",
              " {'step': 909, 'train_loss': 4.936429977416992},\n",
              " {'step': 910, 'train_loss': 4.863910675048828},\n",
              " {'step': 911, 'train_loss': 4.765405654907227},\n",
              " {'step': 912, 'train_loss': 4.769711971282959},\n",
              " {'step': 913, 'train_loss': 4.7402191162109375},\n",
              " {'step': 914, 'train_loss': 4.885500431060791},\n",
              " {'step': 915, 'train_loss': 4.83290958404541},\n",
              " {'step': 916, 'train_loss': 4.578702449798584},\n",
              " {'step': 917, 'train_loss': 4.811155796051025},\n",
              " {'step': 918, 'train_loss': 4.92717170715332},\n",
              " {'step': 919, 'train_loss': 4.836104869842529},\n",
              " {'step': 920, 'train_loss': 4.882083892822266},\n",
              " {'step': 921, 'train_loss': 4.737152099609375},\n",
              " {'step': 922, 'train_loss': 4.804265975952148},\n",
              " {'step': 923, 'train_loss': 4.659135818481445},\n",
              " {'step': 924, 'train_loss': 4.769461631774902},\n",
              " {'step': 925, 'train_loss': 4.786387920379639},\n",
              " {'step': 926, 'train_loss': 4.772644996643066},\n",
              " {'step': 927, 'train_loss': 4.6775288581848145},\n",
              " {'step': 928, 'train_loss': 4.8153862953186035},\n",
              " {'step': 929, 'train_loss': 4.64382266998291},\n",
              " {'step': 930, 'train_loss': 4.867033958435059},\n",
              " {'step': 931, 'train_loss': 4.856082916259766},\n",
              " {'step': 932, 'train_loss': 4.877945423126221},\n",
              " {'step': 933, 'train_loss': 4.686275005340576},\n",
              " {'step': 934, 'train_loss': 4.769906997680664},\n",
              " {'step': 935, 'train_loss': 4.838961601257324},\n",
              " {'step': 936, 'train_loss': 4.671967029571533},\n",
              " {'step': 937, 'train_loss': 4.5379204750061035},\n",
              " {'step': 938, 'train_loss': 4.812243938446045},\n",
              " {'step': 939, 'train_loss': 4.863182067871094},\n",
              " {'step': 940, 'train_loss': 4.71045446395874},\n",
              " {'step': 941, 'train_loss': 4.714067459106445},\n",
              " {'step': 942, 'train_loss': 4.769529819488525},\n",
              " {'step': 943, 'train_loss': 4.824869632720947},\n",
              " {'step': 944, 'train_loss': 4.6067423820495605},\n",
              " {'step': 945, 'train_loss': 4.752866744995117},\n",
              " {'step': 946, 'train_loss': 4.6775288581848145},\n",
              " {'step': 947, 'train_loss': 4.733726978302002},\n",
              " {'step': 948, 'train_loss': 4.620345115661621},\n",
              " {'step': 949, 'train_loss': 4.702925205230713},\n",
              " {'step': 950, 'train_loss': 4.688531398773193},\n",
              " {'step': 951, 'train_loss': 4.633930683135986},\n",
              " {'step': 952, 'train_loss': 4.641327857971191},\n",
              " {'step': 953, 'train_loss': 4.725861549377441},\n",
              " {'step': 954, 'train_loss': 4.649229526519775},\n",
              " {'step': 955, 'train_loss': 4.7611002922058105},\n",
              " {'step': 956, 'train_loss': 4.6958746910095215},\n",
              " {'step': 957, 'train_loss': 4.54047966003418},\n",
              " {'step': 958, 'train_loss': 4.823179244995117},\n",
              " {'step': 959, 'train_loss': 4.859213352203369},\n",
              " {'step': 960, 'train_loss': 4.641848087310791},\n",
              " {'step': 961, 'train_loss': 4.65487003326416},\n",
              " {'step': 962, 'train_loss': 4.868044376373291},\n",
              " {'step': 963, 'train_loss': 4.767735481262207},\n",
              " {'step': 964, 'train_loss': 4.657695293426514},\n",
              " {'step': 965, 'train_loss': 4.81974458694458},\n",
              " {'step': 966, 'train_loss': 4.7981109619140625},\n",
              " {'step': 967, 'train_loss': 4.826697826385498},\n",
              " {'step': 968, 'train_loss': 4.671542644500732},\n",
              " {'step': 969, 'train_loss': 4.758530139923096},\n",
              " {'step': 970, 'train_loss': 4.7321085929870605},\n",
              " {'step': 971, 'train_loss': 4.588334560394287},\n",
              " {'step': 972, 'train_loss': 4.781353950500488},\n",
              " {'step': 973, 'train_loss': 4.770920276641846},\n",
              " {'step': 974, 'train_loss': 4.829546928405762},\n",
              " {'step': 975, 'train_loss': 4.718590259552002},\n",
              " {'step': 976, 'train_loss': 4.746920585632324},\n",
              " {'step': 977, 'train_loss': 4.64173698425293},\n",
              " {'step': 978, 'train_loss': 4.720598220825195},\n",
              " {'step': 979, 'train_loss': 4.6713385581970215},\n",
              " {'step': 980, 'train_loss': 4.585251331329346},\n",
              " {'step': 981, 'train_loss': 4.802215576171875},\n",
              " {'step': 982, 'train_loss': 4.807521820068359},\n",
              " {'step': 983, 'train_loss': 4.853146553039551},\n",
              " {'step': 984, 'train_loss': 4.8594536781311035},\n",
              " {'step': 985, 'train_loss': 4.679919242858887},\n",
              " {'step': 986, 'train_loss': 4.817830562591553},\n",
              " {'step': 987, 'train_loss': 4.744649887084961},\n",
              " {'step': 988, 'train_loss': 4.8365092277526855},\n",
              " {'step': 989, 'train_loss': 4.653956413269043},\n",
              " {'step': 990, 'train_loss': 4.860816478729248},\n",
              " {'step': 991, 'train_loss': 4.7883405685424805},\n",
              " {'step': 992, 'train_loss': 4.785364151000977},\n",
              " {'step': 993, 'train_loss': 4.613116264343262},\n",
              " {'step': 994, 'train_loss': 4.649063587188721},\n",
              " {'step': 995, 'train_loss': 4.818434715270996},\n",
              " {'step': 996, 'train_loss': 4.809483528137207},\n",
              " {'step': 997, 'train_loss': 4.729892730712891},\n",
              " {'step': 998, 'train_loss': 4.631223201751709},\n",
              " {'step': 999, 'train_loss': 4.810287952423096},\n",
              " {'step': 1000,\n",
              "  'train_loss': 4.82926607131958,\n",
              "  'valid_loss': 4.631684786932809},\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgO77jkVjDe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "fc0802b27fc24f73b3a9f503ea4f2a6e",
            "98290768498e41ba9cc358d49de85377",
            "275cb38742904662868ae1619b9a5089",
            "fed9295e85f7417390f23380ea5e419e",
            "643ff90197a2445caf4fa6dacc9d7b46",
            "b0cf37cacdd14944b4efb5e40934da15",
            "f27694adee7745729e2d9615c6dbd08f",
            "8e1fbb3621894fb1bbf84bd4311f0cfa"
          ]
        },
        "outputId": "f9f52b18-32a6-4c60-805a-83c87b8f1cfd"
      },
      "source": [
        "import numpy as np\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "f_scores = []\n",
        "for i in tqdm(range(len(test_seen_dataset))):\n",
        "  kwargs = {'num_beams':8,\n",
        "            'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "            'no_repeat_ngram_size':3,\n",
        "            #'top-k':1\n",
        "            }\n",
        "  idx = 100\n",
        "  hk_pair =  test_seen_dataset[idx]['input_pair'].to(dev)\n",
        "  hk_segment = test_seen_dataset[idx]['input_pair_segments'].to(dev)\n",
        "  response = test_seen_dataset[idx]['response'].to(dev)\n",
        "  generateds = model.generate(hk_pair, hk_segment, **kwargs)\n",
        "  generateds = generateds.squeeze(0).cpu().numpy()\n",
        "  response = response.squeeze(0).cpu().numpy()\n",
        "  intersections = np.intersect1d(generateds, response)\n",
        "  recall = len(intersections) / len(response)\n",
        "  precision = len(intersections) / len(generateds)\n",
        "  f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "  f_scores.append(f1_score)\n",
        "  if i % 100 == 0:\n",
        "    print(sum(f_scores) / len(f_scores))\n",
        "\n",
        "print( sum(f_scores) / len(f_scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc0802b27fc24f73b3a9f503ea4f2a6e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2224.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.2807017543859649\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}