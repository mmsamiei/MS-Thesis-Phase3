{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled162(5).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9cc110c7746459e9bb8b0a9f4162dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b224a00ad426456db8f324d77d268952",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c47ef0837f5d4de3b7f20001d9b2fd25",
              "IPY_MODEL_66534fff3b2d473b98afeb28d775e565"
            ]
          }
        },
        "b224a00ad426456db8f324d77d268952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c47ef0837f5d4de3b7f20001d9b2fd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ce963bfe0694be88f23d0dac7d2c6f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0216e6fe072644d59858d150d7f88200"
          }
        },
        "66534fff3b2d473b98afeb28d775e565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_065502aa3790454e915c5c904d32efbb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00,  5.87it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73c58b7fac0c4160981ad7e11e16b201"
          }
        },
        "2ce963bfe0694be88f23d0dac7d2c6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0216e6fe072644d59858d150d7f88200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "065502aa3790454e915c5c904d32efbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73c58b7fac0c4160981ad7e11e16b201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bd07de2e72f4f40b4155bf79a99f8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac4735d278c4411886e06733354d6699",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0fa7f934aa6542fb906bbdcfac934aa9",
              "IPY_MODEL_b1ae681cdbc4498fa8961221f3f77c7e"
            ]
          }
        },
        "ac4735d278c4411886e06733354d6699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fa7f934aa6542fb906bbdcfac934aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed8bab8b635b46e18d8b8ea71eaa8746",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecfc8f32e1e24fd4aede10c33edce091"
          }
        },
        "b1ae681cdbc4498fa8961221f3f77c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_540134f24f314325b3be8ab8dac9ef86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20000/20000 [15:29&lt;00:00, 21.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35fca405d2da4f16b3042004e02e5355"
          }
        },
        "ed8bab8b635b46e18d8b8ea71eaa8746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecfc8f32e1e24fd4aede10c33edce091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "540134f24f314325b3be8ab8dac9ef86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35fca405d2da4f16b3042004e02e5355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d33bd2a14075424288853f5993dc256d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8225a784e81a45d099f9d83679ccc1d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6522285a78914520bb9a9f7960c9880d",
              "IPY_MODEL_623611430d5a4b17a0314414c7d3e952"
            ]
          }
        },
        "8225a784e81a45d099f9d83679ccc1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6522285a78914520bb9a9f7960c9880d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_661d74892eb34e34a640edf264f01f00",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 41489,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 41489,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9c03dc6f1d4428d8b7d010d228f8219"
          }
        },
        "623611430d5a4b17a0314414c7d3e952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_829375a205114806a195928efaf27e4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 41489/41489 [00:24&lt;00:00, 1693.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f0c2491a7514203bef922764f0201a7"
          }
        },
        "661d74892eb34e34a640edf264f01f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9c03dc6f1d4428d8b7d010d228f8219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "829375a205114806a195928efaf27e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f0c2491a7514203bef922764f0201a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cab0836524f4431fa0ba8cfa9359eb1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97e19459d308481a8fae9f197d1e92c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_667244e96baf4a34a61cd3b34cf06b76",
              "IPY_MODEL_da2e53e089e24b1a9e4148f473ca31b3"
            ]
          }
        },
        "97e19459d308481a8fae9f197d1e92c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "667244e96baf4a34a61cd3b34cf06b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71a1bcd0ca994cdfb77608688ef31cb2",
            "_dom_classes": [],
            "description": " 22%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 5187,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1162,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_029ee88c80a747e2b9762c9afd9833b3"
          }
        },
        "da2e53e089e24b1a9e4148f473ca31b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_342d1f9ba2a44cff9f5d0446741949ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1162/5187 [10:55&lt;28:26,  2.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bfb2e9e7eda46b7aafc11e03c35b6bc"
          }
        },
        "71a1bcd0ca994cdfb77608688ef31cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "029ee88c80a747e2b9762c9afd9833b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "342d1f9ba2a44cff9f5d0446741949ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bfb2e9e7eda46b7aafc11e03c35b6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cfc461dd8c54b9cb560a0fe61c1064a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e352e4cc665f44ae87fdf3607cf7a6c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e8a954ee460949e08f7d43d197a81ec1",
              "IPY_MODEL_948d0c30c64141c68ee42692ac3fa38a"
            ]
          }
        },
        "e352e4cc665f44ae87fdf3607cf7a6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8a954ee460949e08f7d43d197a81ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e032dba7a1b4b69b76724e7bda5072f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 558,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f5c1213957948ceb82264aaa1aa9573"
          }
        },
        "948d0c30c64141c68ee42692ac3fa38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdce838f9ea14821a432ff8a8377367a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558/558 [01:25&lt;00:00,  3.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_873a5e2c00c94f1ba3f9a483c8278b84"
          }
        },
        "6e032dba7a1b4b69b76724e7bda5072f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f5c1213957948ceb82264aaa1aa9573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdce838f9ea14821a432ff8a8377367a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "873a5e2c00c94f1ba3f9a483c8278b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1892fa00293e406f8f42225949d31c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47b6bf358c6c49d5a8abc7e0d77f9bec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be382908d70e4a028e597e11aa8fa3e1",
              "IPY_MODEL_130d560795374ea79ee48aadb2dce533"
            ]
          }
        },
        "47b6bf358c6c49d5a8abc7e0d77f9bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be382908d70e4a028e597e11aa8fa3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e28f66ef9ad44d7d8a14b0fb556d26c3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 558,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd9e1777771a4aa68ddf3e9ccb4304f5"
          }
        },
        "130d560795374ea79ee48aadb2dce533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_82c6be61a6684a6bbbe1568bacbbd95e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558/558 [01:25&lt;00:00,  3.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af462ccec6104c8ea9222bc3efc4d9cb"
          }
        },
        "e28f66ef9ad44d7d8a14b0fb556d26c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd9e1777771a4aa68ddf3e9ccb4304f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82c6be61a6684a6bbbe1568bacbbd95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af462ccec6104c8ea9222bc3efc4d9cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/MS-Thesis-Phase3/blob/master/Models/Beheshti/Beheshti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkQPQqY6s8-v",
        "colab_type": "text"
      },
      "source": [
        "#In the name of God"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SudnGM-6qcaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "950a3060-7735-47d0-9fa5-b4f5f6ea2223"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        "  function ClickConnect(){\n",
        "    console.log(\"Working\"); \n",
        "    document.querySelector(\"colab-connect-button\").click() \n",
        "  }\n",
        "  var connect_timer = setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  function ClickConnect(){\n",
              "    console.log(\"Working\"); \n",
              "    document.querySelector(\"colab-connect-button\").click() \n",
              "  }\n",
              "  var connect_timer = setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTGb1dOrs48Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "51acd637-5644-49de-8197-b2e23539fe68"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul  5 19:53:54 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    58W / 149W |   5413MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyf240b5tD82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "976a57f5-3801-4317-ba92-3bac58c98b98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcbfW-tZtpLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eweO40_dtxZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from transformers import AutoTokenizer\n",
        "import random\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModel"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X2E9kZ5tJRA",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eddoohNmtKug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = '/content/drive/My Drive/Thesis/phase-3/hkr_train.csv'\n",
        "valid_file =  '/content/drive/My Drive/Thesis/phase-3/hkr_valid.csv'\n",
        "test_seen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_seen.csv'\n",
        "test_unseen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_unseen.csv'\n",
        "last_sentence_file = '/content/drive/My Drive/Thesis/phase-3/last_sentence.csv'\n",
        "squad_file = '/content/drive/My Drive/Thesis/phase-3/squad.csv'"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCX3Tv8tqPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n",
        "dec_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu21rVUPuIvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"My dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, frac=1, split_rate=1, max_len=512, sort=True, bound=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "        \"\"\"\n",
        "        self.dialogues = pd.read_csv(csv_file)\n",
        "        #self.dialogues.dropna(inplace=True)\n",
        "        \n",
        "        self.dialogues.fillna(\"\", inplace=True)\n",
        "        self.dialogues = self.dialogues[self.dialogues.index % split_rate == 0]\n",
        "\n",
        "        self.dialogues = self.dialogues.sample(frac=frac)\n",
        "\n",
        "        self.dialogues.history = self.dialogues.history.str.replace(\n",
        "            \"[SEP]\", \"</s>\", n=-1, regex=False) ### SPECIAL CHARACHTER FOR TURN\n",
        "        \n",
        "        if bound:\n",
        "          len_prt = int(len(self.dialogues) / 5)\n",
        "          self.dialogues = self.dialogues[ : len_prt]\n",
        "\n",
        "        s = self.dialogues['response'].apply(dec_tokenizer.encode).apply(len).sort_values().index\n",
        "        self.dialogues = self.dialogues.reindex(s)\n",
        "\n",
        "        \n",
        "\n",
        "        #self.dialogues.dropna(inplace=True)\n",
        "\n",
        "        self.max_len = max_len\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    @staticmethod\n",
        "    def truncuate_join_pair_sentence(sentence1, sentence2, max_len=510):\n",
        "\n",
        "        \"\"\"\n",
        "        truncuate sentence one from head and sentence two from tail\n",
        "        Args:\n",
        "            sentence1 (string): first sentence\n",
        "            sentence2 (string): seconde sentence\n",
        "        \"\"\"\n",
        "        temp1 = enc_tokenizer.encode(sentence1,add_special_tokens=False)\n",
        "        temp2 = enc_tokenizer.encode(sentence2,add_special_tokens=False)\n",
        "        ### two above line may cause warning but no problem because we've handle them below\n",
        "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "        seq_1 = temp1\n",
        "        seq_2 = temp2\n",
        "        num_tokens_to_remove = len(temp1) + len(temp2) + 3 - max_len\n",
        "        if num_tokens_to_remove > 0 :\n",
        "            seq_1, seq_2, _ = enc_tokenizer.truncate_sequences(temp1[::-1],temp2, num_tokens_to_remove=num_tokens_to_remove,\n",
        "                                                               truncation_strategy='longest_first')\n",
        "            seq_1.reverse()\n",
        "        result_list = [enc_tokenizer.cls_token_id]+seq_1+[enc_tokenizer.sep_token_id]+seq_2+[enc_tokenizer.sep_token_id]\n",
        "        token_type_ids = [0] * (len(seq_1) + 2) + [1] * (len(seq_2) + 1)\n",
        "\n",
        "        if(len(result_list)>1000):\n",
        "          print(len(result_list))\n",
        "\n",
        "        return result_list, token_type_ids\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        \n",
        "        history = self.dialogues.iloc[idx].history\n",
        "        knowledge = self.dialogues.iloc[idx].knowledge\n",
        "        response = self.dialogues.iloc[idx].response\n",
        "\n",
        "\n",
        "        input_pair, input_pair_segments = MyDataset.truncuate_join_pair_sentence(history, knowledge, self.max_len)\n",
        "                \n",
        "\n",
        "        input_pair = torch.LongTensor(input_pair)\n",
        "\n",
        "        input_pair_segments = torch.LongTensor(input_pair_segments)\n",
        "\n",
        "        response_tensor = torch.LongTensor(dec_tokenizer.encode(response, truncation=True, max_length=128))\n",
        "\n",
        "        sample = {'input_pair': input_pair,\n",
        "                  'input_pair_segments': input_pair_segments,\n",
        "                  'response': response_tensor}\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0jkglqFwFQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "93167e88-7c9c-4b30-c540-4c61268a3d74"
      },
      "source": [
        "train_dataset = MyDataset(train_file, max_len=128, bound=False)\n",
        "valid_dataset = MyDataset(valid_file, max_len=510)\n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "41489\n",
            "4458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VasXIkuLwHnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "86c64fcf-5f77-470c-e908-c3e62ce505c5"
      },
      "source": [
        "print(enc_tokenizer.decode(train_dataset[600]['input_pair']))\n",
        "print(dec_tokenizer.decode(train_dataset[600]['response']))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s>New York-style pizza </s> do you like pizza? </s> I do. Especially with spicy toppings like jalapenos and buffalo sauce. What toppings do you like?</s>Pizza became a popular fast food in Bangladeshi urban areas.</s>\n",
            "<s>pizza is popular in many cultures</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Z5ZeAT2oii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "c9cc110c7746459e9bb8b0a9f4162dd9",
            "b224a00ad426456db8f324d77d268952",
            "c47ef0837f5d4de3b7f20001d9b2fd25",
            "66534fff3b2d473b98afeb28d775e565",
            "2ce963bfe0694be88f23d0dac7d2c6f1",
            "0216e6fe072644d59858d150d7f88200",
            "065502aa3790454e915c5c904d32efbb",
            "73c58b7fac0c4160981ad7e11e16b201"
          ]
        },
        "outputId": "9d88ab44-f459-4c31-c2b0-b24911b5d15c"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "\n",
        "  len_batch = len(batch)\n",
        "\n",
        "  \n",
        "  max_len_input_pair = max([len(data['input_pair']) for data in batch])\n",
        "\n",
        "  max_len_response = max([len(data['response']) for data in batch])\n",
        "  \n",
        "  padding_ind = 0 ## for bert is 0 DON'T THINK BAD IT IS NOT REFACTORING !!!!!!\n",
        "  result_input_pair = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_input_pair_segments = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_response = torch.zeros(len_batch, max_len_response)\n",
        "\n",
        "  for i, data in enumerate(batch):\n",
        "    p1 = len(data['input_pair'])\n",
        "    result_input_pair[i, :p1] = data['input_pair']\n",
        "\n",
        "    p3 = len(data['input_pair_segments'])\n",
        "    result_input_pair_segments[i, :p3] = data['input_pair_segments']\n",
        "\n",
        "    p4 = len(data['response'])\n",
        "    result_response[i, :p4] = data['response']\n",
        "\n",
        "  return result_input_pair.long(), result_input_pair_segments.long(), result_response.long()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16,\n",
        "                                             shuffle=True, collate_fn=my_collate_fn,\n",
        "                                           num_workers=1)\n",
        "\n",
        "#valid_sampler = torch.utils.data.SequentialSampler(valid_dataset)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn, num_workers=1)\n",
        "\n",
        "i = 0 \n",
        "for batch_idx, batch  in tqdm(enumerate(train_loader)):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  print(pair_batch.shape)\n",
        "  print(segment_batch.shape)\n",
        "  print(response_batch.shape)\n",
        "  print(\"****\")\n",
        "  i += 1 \n",
        "  if(i==2):\n",
        "    break\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(valid_loader))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9cc110c7746459e9bb8b0a9f4162dd9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 72])\n",
            "****\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 33])\n",
            "****\n",
            "2594\n",
            "279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoQlszJw_hFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "c5ef1ed1-4202-4916-d65d-d7cab8869c62"
      },
      "source": [
        "o = torch.rand(8,5)\n",
        "o"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7971, 0.5570, 0.6176, 0.8620, 0.0346],\n",
              "        [0.2617, 0.9808, 0.7682, 0.6243, 0.2782],\n",
              "        [0.4833, 0.6336, 0.0463, 0.0938, 0.4098],\n",
              "        [0.9999, 0.7067, 0.1404, 0.7106, 0.1492],\n",
              "        [0.0357, 0.5070, 0.1811, 0.8164, 0.6623],\n",
              "        [0.6191, 0.1194, 0.4503, 0.9537, 0.8837],\n",
              "        [0.2407, 0.3513, 0.4584, 0.2995, 0.2904],\n",
              "        [0.1673, 0.0891, 0.2090, 0.0751, 0.6567]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzwNQ5HwD5hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0aec0d8-18f3-43e7-f137-27cc4551bceb"
      },
      "source": [
        "y = torch.LongTensor(8).random_(0,5)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0, 0, 0, 4, 1, 4, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0fr2mAvGYA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "749be628-2f4b-4379-c354-d490ccde15dd"
      },
      "source": [
        "o[y!=2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2617, 0.9808, 0.7682, 0.6243, 0.2782],\n",
              "        [0.4833, 0.6336, 0.0463, 0.0938, 0.4098],\n",
              "        [0.9999, 0.7067, 0.1404, 0.7106, 0.1492],\n",
              "        [0.0357, 0.5070, 0.1811, 0.8164, 0.6623],\n",
              "        [0.6191, 0.1194, 0.4503, 0.9537, 0.8837],\n",
              "        [0.2407, 0.3513, 0.4584, 0.2995, 0.2904]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxXzuZtMINMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cafb2b27-0aaf-4bb8-8d21-a759de573555"
      },
      "source": [
        "z = torch.LongTensor(o[y!=2].shape[0]).fill_(2)\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J49VS8z3Ilz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfWWb-ayBCsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7132afe9-8373-49be-9a7b-225c4c8afa97"
      },
      "source": [
        "-1*F.nll_loss(nn.functional.log_softmax(o[y!=2]), z, reduction='mean')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7754)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXB7YVVgDyPU",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfGvoJMiEicR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizer\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    # self.seq2seq = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    #     'google/bert_uncased_L-2_H-128_A-2', 'google/bert_uncased_L-6_H-128_A-2')\n",
        "    \n",
        "    # for p in self.seq2seq.encoder.embeddings.parameters():\n",
        "    #    p.requires_grad = False\n",
        "    \n",
        "    # for p in self.seq2seq.decoder.bert.embeddings.parameters():\n",
        "    #    p.requires_grad = False\n",
        "\n",
        "    self.seq2seq = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "\n",
        "  def forward(self, encoder_input, segments_tensors, decoder_input):\n",
        "    '''\n",
        "    encoder_input = [batch_size, enc_len]\n",
        "    segments_tensors = [batch_size, enc_len]\n",
        "    decoder_input = [batch_size, dec_len]\n",
        "    '''\n",
        "    kwargs = {'token_type_ids':segments_tensors}\n",
        "    kwargs = {}\n",
        "    outputs = self.seq2seq(input_ids=encoder_input, decoder_input_ids=decoder_input, labels=decoder_input, **kwargs)[1]\n",
        "    return outputs\n",
        "  \n",
        "  def generate(self, encoder_input, segments_tensors, **kwargs):\n",
        "    ### encoder_input = [len] in int format\n",
        "    ### segment_tensors = [len]\n",
        "    encoder_input = encoder_input.unsqueeze(0)\n",
        "    segments_tensors = segments_tensors.unsqueeze(0)\n",
        "    \n",
        "    model_specific_kwargs = {}\n",
        "    #model_specific_kwargs['token_type_ids'] = {'token_type_ids':segments_tensors}\n",
        "\n",
        "    generated = model.seq2seq.generate(encoder_input, decoder_start_token_id=101,\n",
        "                                       eos_token_id=102, ## [SEP] = 102\n",
        "                                       **kwargs, **model_specific_kwargs)\n",
        "\n",
        "    #### generated = [1, len]\n",
        "    return generated"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxsRPOHFGrBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "09310741-aa47-4b51-d960-09a7aebc5c60"
      },
      "source": [
        "dev = torch.device('cuda')\n",
        "model = Model().to(dev)\n",
        "\n",
        "x = torch.LongTensor(8, 40).random_(1,1000).to(dev)\n",
        "y = torch.LongTensor(8, 10).random_(1,1000).to(dev)\n",
        "print(model(x,x,y).shape)\n",
        "\n",
        "\n",
        "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(count_parameters(model))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 10, 50265])\n",
            "139420416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb5uvuCKL0cj",
        "colab_type": "text"
      },
      "source": [
        "#Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxB7zLBDZQXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJplUNA2A-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_cosine_schedule_with_warmup\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=1000, num_training_steps=10000, num_cycles=0.5)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ofqAPp12OnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "4bd07de2e72f4f40b4155bf79a99f8c5",
            "ac4735d278c4411886e06733354d6699",
            "0fa7f934aa6542fb906bbdcfac934aa9",
            "b1ae681cdbc4498fa8961221f3f77c7e",
            "ed8bab8b635b46e18d8b8ea71eaa8746",
            "ecfc8f32e1e24fd4aede10c33edce091",
            "540134f24f314325b3be8ab8dac9ef86",
            "35fca405d2da4f16b3042004e02e5355"
          ]
        },
        "outputId": "cc0d3533-817d-4f02-a994-d78dc9828229"
      },
      "source": [
        "lrs = []\n",
        "for i in tqdm(range(20000)):\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "  lrs.append(scheduler.get_last_lr()[0])\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lrs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bd07de2e72f4f40b4155bf79a99f8c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f13bde89b38>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufFe-Q62ZaFW",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfNUyJV1DfaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "d33bd2a14075424288853f5993dc256d",
            "8225a784e81a45d099f9d83679ccc1d3",
            "6522285a78914520bb9a9f7960c9880d",
            "623611430d5a4b17a0314414c7d3e952",
            "661d74892eb34e34a640edf264f01f00",
            "c9c03dc6f1d4428d8b7d010d228f8219",
            "829375a205114806a195928efaf27e4d",
            "4f0c2491a7514203bef922764f0201a7"
          ]
        },
        "outputId": "49cae613-3615-461f-9e0e-52d2a5c12c28"
      },
      "source": [
        "df = pd.read_csv(train_file)\n",
        "freqs = [1] * dec_tokenizer.vocab_size\n",
        "for response in tqdm(df['response']):\n",
        "  tknzd = dec_tokenizer.encode(response)\n",
        "  for tkn in tknzd:\n",
        "    freqs[tkn] += 1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d33bd2a14075424288853f5993dc256d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=41489.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_YgBP3AFXF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weights(_lambda = 0.2):\n",
        "  weights = torch.ones(dec_tokenizer.vocab_size)\n",
        "  for idx, freq in enumerate(freqs):\n",
        "    weight = 1 / (freq**_lambda)\n",
        "    weights[idx] = weight\n",
        "  return weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-t7PADEZcZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn\n",
        "\n",
        "weight = get_weights().to(dev)\n",
        "\n",
        "def mahdi_loss(model_output, true_trg, **kwargs):\n",
        "  '''\n",
        "  model_output: [batch, len, hidden]\n",
        "  true_trg: [batch, len]\n",
        "  '''\n",
        "  model_output = model_output[:,:-1,:]\n",
        "  true_trg = true_trg[:,1:]\n",
        "\n",
        "  # cold\n",
        "  #T = 1\n",
        "  #model_output = model_output / T\n",
        "\n",
        "  if 'easy_training' in kwargs:\n",
        "    print(\"Easy training\")\n",
        "    limit_last_tokens = kwargs['easy_training']\n",
        "    model_output = model_output[:,-limit_last_tokens:,:]\n",
        "    true_trg = true_trg[:,-limit_last_tokens:]\n",
        "\n",
        "  batch_len = model_output.shape[0]\n",
        "  snt_len = model_output.shape[1]\n",
        "  hidden_size = model_output.shape[2]\n",
        "\n",
        "  model_output = model_output.reshape(-1, hidden_size)\n",
        "  true_trg = true_trg.reshape(-1)\n",
        "\n",
        "  loss_mod = nn.CrossEntropyLoss(weight=weight, ignore_index=0)## PAD = 0\n",
        "  loss = loss_mod(model_output, true_trg)\n",
        "\n",
        "\n",
        "\n",
        "  #z = torch.LongTensor(model_output[true_trg!=1045].shape[0]).fill_(1045).to(dev)\n",
        "  #neg_loss = -0.5*F.nll_loss(nn.functional.log_softmax(model_output[true_trg!=1045]), z, reduction='mean')\n",
        "\n",
        "  return loss "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmuTGJMJbR9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(batch_idx, batch):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  pair_batch = pair_batch.to(dev)\n",
        "  segment_batch = segment_batch.to(dev)\n",
        "  response_batch = response_batch.to(dev)\n",
        "  model_output = model(pair_batch, segment_batch, response_batch)\n",
        "  #kwargs = {'easy_training':4}\n",
        "  loss = mahdi_loss(model_output, response_batch)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "  del pair_batch\n",
        "  del segment_batch\n",
        "  del response_batch\n",
        "  return loss.item()\n",
        "\n",
        "def valid_step(batch_idx, batch):\n",
        "  with torch.no_grad():\n",
        "    pair_batch, segment_batch, response_batch = batch\n",
        "    pair_batch = pair_batch.to(dev)\n",
        "    segment_batch = segment_batch.to(dev)\n",
        "    response_batch = response_batch.to(dev)\n",
        "    model_output = model(pair_batch, segment_batch, response_batch)\n",
        "    loss = mahdi_loss(model_output, response_batch)\n",
        "    del pair_batch\n",
        "    del segment_batch\n",
        "    del response_batch\n",
        "    return loss.item()\n",
        "\n",
        "def valid_loop(valid_loader):\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "  for batch_idx, batch in tqdm(enumerate(valid_loader),  total=len(valid_loader), leave=False):\n",
        "    total_loss += valid_step(batch_idx, batch)\n",
        "  \n",
        "  print(\"temperature is 1:\")\n",
        "  kwargs = {'num_beams':16,'num_return_sequences':8,'temperature':1,\n",
        "            'no_repeat_ngram_size':3}\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  print(\"most greedy sentence:\")\n",
        "  kwargs = {\n",
        "          'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3,\n",
        "          'top-k':1\n",
        "          }\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  # print(\"temperature is 2:\")\n",
        "  # kwargs = {'num_beams':16,'num_return_sequences':16,'temperature':2}\n",
        "  # valid_inference(**kwargs)\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  return total_loss / len(valid_loader)\n",
        "\n",
        "def valid_inference(idx=100, **kwargs):\n",
        "  hk_pair =  train_dataset[idx]['input_pair'].to(dev)\n",
        "  hk_segment = train_dataset[idx]['input_pair_segments'].to(dev)\n",
        "  response = train_dataset[idx]['response'].to(dev)\n",
        "  generateds = model.generate(hk_pair, hk_segment, **kwargs)\n",
        "  print(\"pair is: \",enc_tokenizer.decode(hk_pair))\n",
        "  print(\"response is: \",dec_tokenizer.decode(response))\n",
        "  for generated in generateds:\n",
        "    print(\"model says: \",dec_tokenizer.decode(generated))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pxjS0PQfKU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_learning = True\n",
        "if new_learning:\n",
        "  # optimizer = NoamOpt(128, 1, 2000,\n",
        "  #           torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "  model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Squad/\"\n",
        "  step = 0\n",
        "  log_list = []"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZD1hD7rfNFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b619ef5b-b500-4a2a-e393-fb7c19e4531c"
      },
      "source": [
        "## if continue learning:\n",
        "#!wget -q https://github.com/mmsamiei/MS-Thesis-Phase2/raw/master/Models/hashemi_16000steps.model\n",
        "model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Montazeri\"\n",
        "checkpoint = torch.load(model_dir+'/montazeri_15000steps.model')\n",
        "step = checkpoint['log_list'][-1]['step']\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "optimizer._step = step\n",
        "log_list = checkpoint['log_list']\n",
        "new_learning = False\n",
        "print(step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHv6tC4YfZI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cab0836524f4431fa0ba8cfa9359eb1a",
            "97e19459d308481a8fae9f197d1e92c8",
            "667244e96baf4a34a61cd3b34cf06b76",
            "da2e53e089e24b1a9e4148f473ca31b3",
            "71a1bcd0ca994cdfb77608688ef31cb2",
            "029ee88c80a747e2b9762c9afd9833b3",
            "342d1f9ba2a44cff9f5d0446741949ad",
            "4bfb2e9e7eda46b7aafc11e03c35b6bc",
            "5cfc461dd8c54b9cb560a0fe61c1064a",
            "e352e4cc665f44ae87fdf3607cf7a6c1",
            "e8a954ee460949e08f7d43d197a81ec1",
            "948d0c30c64141c68ee42692ac3fa38a",
            "6e032dba7a1b4b69b76724e7bda5072f",
            "4f5c1213957948ceb82264aaa1aa9573",
            "cdce838f9ea14821a432ff8a8377367a",
            "873a5e2c00c94f1ba3f9a483c8278b84",
            "1892fa00293e406f8f42225949d31c42",
            "47b6bf358c6c49d5a8abc7e0d77f9bec",
            "be382908d70e4a028e597e11aa8fa3e1",
            "130d560795374ea79ee48aadb2dce533",
            "e28f66ef9ad44d7d8a14b0fb556d26c3",
            "bd9e1777771a4aa68ddf3e9ccb4304f5",
            "82c6be61a6684a6bbbe1568bacbbd95e",
            "af462ccec6104c8ea9222bc3efc4d9cb"
          ]
        },
        "outputId": "2a599ffb-d7e9-496f-8c2e-2d97b2c0d37a"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "MAX_STEP = 6000\n",
        "STEP_SAVE = 5000\n",
        "STEP_CHECK = 500\n",
        "step_num = step + 1\n",
        "log_list = log_list ### Check if new learning or not\n",
        "print(step_num)\n",
        "while step_num <= MAX_STEP:\n",
        "  model.train()\n",
        "  for batch_idx, batch in tqdm(enumerate(iter(train_loader)), total=len(train_loader), leave=False):\n",
        "    step_loss = train_step(batch_idx, batch)\n",
        "    log = {'step':step_num, 'train_loss':step_loss}\n",
        "\n",
        "    if(step_num % STEP_CHECK == 0):\n",
        "      valid_error = valid_loop(valid_loader)\n",
        "      train_losses = [step['train_loss'] for step in log_list[-100:]]\n",
        "      avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "      print(\"train Loss rate: {} at step {}\".format(avg_train_loss, step_num))  \n",
        "      print(\"valid Loss rate: {} at step {}\".format(valid_error, step_num))  \n",
        "      log['valid_loss'] = valid_error\n",
        "\n",
        "    log_list.append(log)\n",
        "\n",
        "    if(step_num % STEP_SAVE == 0):\n",
        "      torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'log_list': log_list,\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, model_dir+'montazeri_{}steps.model'.format(step_num))\n",
        "    step_num += 1"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cab0836524f4431fa0ba8cfa9359eb1a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5187.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cfc461dd8c54b9cb560a0fe61c1064a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=558.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "temperature is 1:\n",
            "pair is:  <s>Recreational fishing </s> I love sport fishing! Do it for pleasure but would also do it for competition! </s> very nice, I have only been sports fishing once off the coast of mexico.  </s> Did you use a rod, a reel, a line, hooks and baits? </s> we had many rods set up and trailed the ocean for many hours.  </s> I usually use lures in place of bait. </s> What kind of fish do you fish for?</s></s>\n",
            "response is:  <s>Trout! you?</s>\n",
            "model says:   like<s>III theII III,IITheII aI</s>\n",
            "model says:   like<s>III theII III,II aIITheI</s>\n",
            "model says:   like<s>III III theII,II aIITheI</s>\n",
            "model says:   like<s>III theII,II III aIITheI</s>\n",
            "model says:   like<s>III III,II theII aIITheI</s>\n",
            "model says:   like<s>III theII,II aII IIITheI</s>\n",
            "model says:   like<s>II theIII III,II aIITheI</s>\n",
            "model says:   like<s>III,II III theII aIITheI</s>\n",
            "most greedy sentence:\n",
            "pair is:  <s>Recreational fishing </s> I love sport fishing! Do it for pleasure but would also do it for competition! </s> very nice, I have only been sports fishing once off the coast of mexico.  </s> Did you use a rod, a reel, a line, hooks and baits? </s> we had many rods set up and trailed the ocean for many hours.  </s> I usually use lures in place of bait. </s> What kind of fish do you fish for?</s></s>\n",
            "response is:  <s>Trout! you?</s>\n",
            "model says:   likeIII,II theII III aIITheII isII.II inIIItII thatII youII ofII toIIYesII itII are\n",
            "train Loss rate: 8.698938698768616 at step 500\n",
            "valid Loss rate: 8.89278801794975 at step 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1892fa00293e406f8f42225949d31c42",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=558.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "temperature is 1:\n",
            "pair is:  <s>Recreational fishing </s> I love sport fishing! Do it for pleasure but would also do it for competition! </s> very nice, I have only been sports fishing once off the coast of mexico.  </s> Did you use a rod, a reel, a line, hooks and baits? </s> we had many rods set up and trailed the ocean for many hours.  </s> I usually use lures in place of bait. </s> What kind of fish do you fish for?</s></s>\n",
            "response is:  <s>Trout! you?</s>\n",
            "model says:   like<s>IIIYeahIIItIITheIITheyIIYesI</s>\n",
            "model says:   like<s>IIItIIITheIITheyIIYeahIIYesI</s>\n",
            "model says:   like<s>IITheIIItIIITheyIIYeahIIYesI</s>\n",
            "model says:   like<s>IIITheyIIItIITheIIYeahIIYesI</s>\n",
            "model says:   like<s>IITheyIIIItIITheIIYeahIIYesI</s>\n",
            "model says:   like<s>IIIItIITheIITheyIIYeahIIYesI</s>\n",
            "model says:   like<s>IIYeahIIIItIITheIITheyIIYesI</s>\n",
            "model says:   like<s>IITheIIIItIITheyIIYeahIIYesI</s>\n",
            "most greedy sentence:\n",
            "pair is:  <s>Recreational fishing </s> I love sport fishing! Do it for pleasure but would also do it for competition! </s> very nice, I have only been sports fishing once off the coast of mexico.  </s> Did you use a rod, a reel, a line, hooks and baits? </s> we had many rods set up and trailed the ocean for many hours.  </s> I usually use lures in place of bait. </s> What kind of fish do you fish for?</s></s>\n",
            "response is:  <s>Trout! you?</s>\n",
            "model says:   likeIIIItIITheIITheyIIYeahIIYesIIDoIIWellIIThatIIMostIIYouIIMyIINoIIThereII loveIISomeIIOh\n",
            "train Loss rate: 8.54568169593811 at step 1000\n",
            "valid Loss rate: 10.543168484951005 at step 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d6da6fe69aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mstep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-de10415ec553>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch_idx, batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmahdi_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow4c6BCePKec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "56045194-5a19-419b-ad19-2e7106786bfa"
      },
      "source": [
        "kwargs = {#'num_beams':8,\n",
        "          'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3,\n",
        "          'top-k':1\n",
        "          }\n",
        "valid_inference(idx=1200, **kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pair is:  [CLS] divorce [SEP] reasons for divorce vary, from sexual incompatibility or lack of independence for one or both spouses to a personality clash. [SEP]\n",
            "response is:  [CLS] people get divorced for many different reasons. [SEP]\n",
            "model says:  [CLS] they are not a lot. they are a lot, they are also a lot more different differences. [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlWb7ZY5ClYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d15898e9-2734-4201-da38-88af8bfcdadd"
      },
      "source": [
        "dec_tokenizer.encode(\"they\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2027, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001YzGTpEiV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22f816d3-aa9b-4257-c6bf-f96fe6283f0f"
      },
      "source": [
        "log_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'step': 1, 'train_loss': 10.614270210266113},\n",
              " {'step': 2, 'train_loss': 10.733108520507812},\n",
              " {'step': 3, 'train_loss': 10.35904312133789},\n",
              " {'step': 4, 'train_loss': 10.361538887023926},\n",
              " {'step': 5, 'train_loss': 9.957269668579102},\n",
              " {'step': 6, 'train_loss': 9.948104858398438},\n",
              " {'step': 7, 'train_loss': 9.55443286895752},\n",
              " {'step': 8, 'train_loss': 9.504170417785645},\n",
              " {'step': 9, 'train_loss': 9.426634788513184},\n",
              " {'step': 10, 'train_loss': 9.070025444030762},\n",
              " {'step': 11, 'train_loss': 8.891423225402832},\n",
              " {'step': 12, 'train_loss': 8.783164024353027},\n",
              " {'step': 13, 'train_loss': 8.70628547668457},\n",
              " {'step': 14, 'train_loss': 8.569317817687988},\n",
              " {'step': 15, 'train_loss': 8.292956352233887},\n",
              " {'step': 16, 'train_loss': 8.274083137512207},\n",
              " {'step': 17, 'train_loss': 7.799631595611572},\n",
              " {'step': 18, 'train_loss': 8.041912078857422},\n",
              " {'step': 19, 'train_loss': 7.653815269470215},\n",
              " {'step': 20, 'train_loss': 7.699405670166016},\n",
              " {'step': 21, 'train_loss': 7.541056156158447},\n",
              " {'step': 22, 'train_loss': 7.494517803192139},\n",
              " {'step': 23, 'train_loss': 7.430841445922852},\n",
              " {'step': 24, 'train_loss': 7.282088279724121},\n",
              " {'step': 25, 'train_loss': 7.419764518737793},\n",
              " {'step': 26, 'train_loss': 7.311008453369141},\n",
              " {'step': 27, 'train_loss': 7.324136257171631},\n",
              " {'step': 28, 'train_loss': 7.19038724899292},\n",
              " {'step': 29, 'train_loss': 7.139859676361084},\n",
              " {'step': 30, 'train_loss': 6.9642133712768555},\n",
              " {'step': 31, 'train_loss': 7.110976219177246},\n",
              " {'step': 32, 'train_loss': 6.959036827087402},\n",
              " {'step': 33, 'train_loss': 6.991216659545898},\n",
              " {'step': 34, 'train_loss': 7.028300762176514},\n",
              " {'step': 35, 'train_loss': 6.890758514404297},\n",
              " {'step': 36, 'train_loss': 6.940341949462891},\n",
              " {'step': 37, 'train_loss': 6.829961776733398},\n",
              " {'step': 38, 'train_loss': 6.790741443634033},\n",
              " {'step': 39, 'train_loss': 6.722304344177246},\n",
              " {'step': 40, 'train_loss': 6.799952030181885},\n",
              " {'step': 41, 'train_loss': 6.738827705383301},\n",
              " {'step': 42, 'train_loss': 6.836117744445801},\n",
              " {'step': 43, 'train_loss': 6.828161239624023},\n",
              " {'step': 44, 'train_loss': 6.477605819702148},\n",
              " {'step': 45, 'train_loss': 6.66423225402832},\n",
              " {'step': 46, 'train_loss': 6.619389057159424},\n",
              " {'step': 47, 'train_loss': 6.610867977142334},\n",
              " {'step': 48, 'train_loss': 6.634395599365234},\n",
              " {'step': 49, 'train_loss': 6.7043023109436035},\n",
              " {'step': 50, 'train_loss': 6.447009086608887},\n",
              " {'step': 51, 'train_loss': 6.404237747192383},\n",
              " {'step': 52, 'train_loss': 6.602799415588379},\n",
              " {'step': 53, 'train_loss': 6.495773792266846},\n",
              " {'step': 54, 'train_loss': 6.4824700355529785},\n",
              " {'step': 55, 'train_loss': 6.533472537994385},\n",
              " {'step': 56, 'train_loss': 6.473059177398682},\n",
              " {'step': 57, 'train_loss': 6.536724090576172},\n",
              " {'step': 58, 'train_loss': 6.466060638427734},\n",
              " {'step': 59, 'train_loss': 6.412276268005371},\n",
              " {'step': 60, 'train_loss': 6.33018684387207},\n",
              " {'step': 61, 'train_loss': 6.287384986877441},\n",
              " {'step': 62, 'train_loss': 6.26254415512085},\n",
              " {'step': 63, 'train_loss': 6.33486795425415},\n",
              " {'step': 64, 'train_loss': 6.475207328796387},\n",
              " {'step': 65, 'train_loss': 6.321694374084473},\n",
              " {'step': 66, 'train_loss': 6.318795204162598},\n",
              " {'step': 67, 'train_loss': 6.250856876373291},\n",
              " {'step': 68, 'train_loss': 6.273882865905762},\n",
              " {'step': 69, 'train_loss': 6.177679061889648},\n",
              " {'step': 70, 'train_loss': 6.31804895401001},\n",
              " {'step': 71, 'train_loss': 6.312829494476318},\n",
              " {'step': 72, 'train_loss': 6.408702373504639},\n",
              " {'step': 73, 'train_loss': 6.233015060424805},\n",
              " {'step': 74, 'train_loss': 6.162512302398682},\n",
              " {'step': 75, 'train_loss': 6.125713348388672},\n",
              " {'step': 76, 'train_loss': 6.25309419631958},\n",
              " {'step': 77, 'train_loss': 6.191492557525635},\n",
              " {'step': 78, 'train_loss': 6.253152370452881},\n",
              " {'step': 79, 'train_loss': 6.144394397735596},\n",
              " {'step': 80, 'train_loss': 6.068164348602295},\n",
              " {'step': 81, 'train_loss': 6.047217845916748},\n",
              " {'step': 82, 'train_loss': 6.155714511871338},\n",
              " {'step': 83, 'train_loss': 6.2831292152404785},\n",
              " {'step': 84, 'train_loss': 6.0289506912231445},\n",
              " {'step': 85, 'train_loss': 6.046760082244873},\n",
              " {'step': 86, 'train_loss': 6.0089263916015625},\n",
              " {'step': 87, 'train_loss': 6.149424076080322},\n",
              " {'step': 88, 'train_loss': 5.892147064208984},\n",
              " {'step': 89, 'train_loss': 6.167072296142578},\n",
              " {'step': 90, 'train_loss': 6.048231601715088},\n",
              " {'step': 91, 'train_loss': 6.064284324645996},\n",
              " {'step': 92, 'train_loss': 6.100862503051758},\n",
              " {'step': 93, 'train_loss': 6.143848419189453},\n",
              " {'step': 94, 'train_loss': 5.9826250076293945},\n",
              " {'step': 95, 'train_loss': 6.055506706237793},\n",
              " {'step': 96, 'train_loss': 6.1009111404418945},\n",
              " {'step': 97, 'train_loss': 5.9516167640686035},\n",
              " {'step': 98, 'train_loss': 5.892017841339111},\n",
              " {'step': 99, 'train_loss': 6.066226482391357},\n",
              " {'step': 100, 'train_loss': 6.033585071563721},\n",
              " {'step': 101, 'train_loss': 5.9667582511901855},\n",
              " {'step': 102, 'train_loss': 5.870423793792725},\n",
              " {'step': 103, 'train_loss': 5.994822025299072},\n",
              " {'step': 104, 'train_loss': 5.971651554107666},\n",
              " {'step': 105, 'train_loss': 5.9873247146606445},\n",
              " {'step': 106, 'train_loss': 6.104528903961182},\n",
              " {'step': 107, 'train_loss': 6.018568515777588},\n",
              " {'step': 108, 'train_loss': 5.905545711517334},\n",
              " {'step': 109, 'train_loss': 5.904337406158447},\n",
              " {'step': 110, 'train_loss': 5.857326984405518},\n",
              " {'step': 111, 'train_loss': 5.910941123962402},\n",
              " {'step': 112, 'train_loss': 5.952322959899902},\n",
              " {'step': 113, 'train_loss': 5.930358409881592},\n",
              " {'step': 114, 'train_loss': 5.820103645324707},\n",
              " {'step': 115, 'train_loss': 5.904860496520996},\n",
              " {'step': 116, 'train_loss': 5.746059894561768},\n",
              " {'step': 117, 'train_loss': 5.919399738311768},\n",
              " {'step': 118, 'train_loss': 5.721978664398193},\n",
              " {'step': 119, 'train_loss': 5.978499412536621},\n",
              " {'step': 120, 'train_loss': 5.803157806396484},\n",
              " {'step': 121, 'train_loss': 5.9035115242004395},\n",
              " {'step': 122, 'train_loss': 5.905656337738037},\n",
              " {'step': 123, 'train_loss': 5.965410232543945},\n",
              " {'step': 124, 'train_loss': 5.693082332611084},\n",
              " {'step': 125, 'train_loss': 5.800467491149902},\n",
              " {'step': 126, 'train_loss': 5.9416961669921875},\n",
              " {'step': 127, 'train_loss': 5.744022846221924},\n",
              " {'step': 128, 'train_loss': 5.756189823150635},\n",
              " {'step': 129, 'train_loss': 5.972407341003418},\n",
              " {'step': 130, 'train_loss': 5.739309787750244},\n",
              " {'step': 131, 'train_loss': 5.773653984069824},\n",
              " {'step': 132, 'train_loss': 5.7204270362854},\n",
              " {'step': 133, 'train_loss': 5.745061874389648},\n",
              " {'step': 134, 'train_loss': 5.694537162780762},\n",
              " {'step': 135, 'train_loss': 5.807111740112305},\n",
              " {'step': 136, 'train_loss': 5.677490234375},\n",
              " {'step': 137, 'train_loss': 5.84185791015625},\n",
              " {'step': 138, 'train_loss': 5.757626056671143},\n",
              " {'step': 139, 'train_loss': 5.838588237762451},\n",
              " {'step': 140, 'train_loss': 5.887659072875977},\n",
              " {'step': 141, 'train_loss': 5.799559116363525},\n",
              " {'step': 142, 'train_loss': 5.857546806335449},\n",
              " {'step': 143, 'train_loss': 5.841247081756592},\n",
              " {'step': 144, 'train_loss': 5.7828192710876465},\n",
              " {'step': 145, 'train_loss': 5.7508111000061035},\n",
              " {'step': 146, 'train_loss': 5.657776355743408},\n",
              " {'step': 147, 'train_loss': 5.773700714111328},\n",
              " {'step': 148, 'train_loss': 5.783103942871094},\n",
              " {'step': 149, 'train_loss': 5.6356306076049805},\n",
              " {'step': 150, 'train_loss': 5.7269606590271},\n",
              " {'step': 151, 'train_loss': 5.664881229400635},\n",
              " {'step': 152, 'train_loss': 5.8323140144348145},\n",
              " {'step': 153, 'train_loss': 5.798088073730469},\n",
              " {'step': 154, 'train_loss': 5.622040748596191},\n",
              " {'step': 155, 'train_loss': 5.643208980560303},\n",
              " {'step': 156, 'train_loss': 5.625682353973389},\n",
              " {'step': 157, 'train_loss': 5.750513076782227},\n",
              " {'step': 158, 'train_loss': 5.640925884246826},\n",
              " {'step': 159, 'train_loss': 5.544066905975342},\n",
              " {'step': 160, 'train_loss': 5.526726245880127},\n",
              " {'step': 161, 'train_loss': 5.635190963745117},\n",
              " {'step': 162, 'train_loss': 5.542055606842041},\n",
              " {'step': 163, 'train_loss': 5.692262172698975},\n",
              " {'step': 164, 'train_loss': 5.516684532165527},\n",
              " {'step': 165, 'train_loss': 5.639286518096924},\n",
              " {'step': 166, 'train_loss': 5.5649003982543945},\n",
              " {'step': 167, 'train_loss': 5.659287452697754},\n",
              " {'step': 168, 'train_loss': 5.723378658294678},\n",
              " {'step': 169, 'train_loss': 5.550490379333496},\n",
              " {'step': 170, 'train_loss': 5.501671314239502},\n",
              " {'step': 171, 'train_loss': 5.554276943206787},\n",
              " {'step': 172, 'train_loss': 5.663266658782959},\n",
              " {'step': 173, 'train_loss': 5.390931129455566},\n",
              " {'step': 174, 'train_loss': 5.539400100708008},\n",
              " {'step': 175, 'train_loss': 5.562276840209961},\n",
              " {'step': 176, 'train_loss': 5.4964823722839355},\n",
              " {'step': 177, 'train_loss': 5.461878299713135},\n",
              " {'step': 178, 'train_loss': 5.557440757751465},\n",
              " {'step': 179, 'train_loss': 5.599611282348633},\n",
              " {'step': 180, 'train_loss': 5.491677761077881},\n",
              " {'step': 181, 'train_loss': 5.663024425506592},\n",
              " {'step': 182, 'train_loss': 5.459636211395264},\n",
              " {'step': 183, 'train_loss': 5.422452449798584},\n",
              " {'step': 184, 'train_loss': 5.511804580688477},\n",
              " {'step': 185, 'train_loss': 5.4484710693359375},\n",
              " {'step': 186, 'train_loss': 5.597130298614502},\n",
              " {'step': 187, 'train_loss': 5.456928730010986},\n",
              " {'step': 188, 'train_loss': 5.553258895874023},\n",
              " {'step': 189, 'train_loss': 5.411586284637451},\n",
              " {'step': 190, 'train_loss': 5.478546619415283},\n",
              " {'step': 191, 'train_loss': 5.59134578704834},\n",
              " {'step': 192, 'train_loss': 5.498397350311279},\n",
              " {'step': 193, 'train_loss': 5.555095672607422},\n",
              " {'step': 194, 'train_loss': 5.665139198303223},\n",
              " {'step': 195, 'train_loss': 5.599613189697266},\n",
              " {'step': 196, 'train_loss': 5.510522842407227},\n",
              " {'step': 197, 'train_loss': 5.527666091918945},\n",
              " {'step': 198, 'train_loss': 5.446256160736084},\n",
              " {'step': 199, 'train_loss': 5.387380123138428},\n",
              " {'step': 200, 'train_loss': 5.571355819702148},\n",
              " {'step': 201, 'train_loss': 5.513912677764893},\n",
              " {'step': 202, 'train_loss': 5.607326030731201},\n",
              " {'step': 203, 'train_loss': 5.477540016174316},\n",
              " {'step': 204, 'train_loss': 5.47022819519043},\n",
              " {'step': 205, 'train_loss': 5.48403263092041},\n",
              " {'step': 206, 'train_loss': 5.518249988555908},\n",
              " {'step': 207, 'train_loss': 5.512309551239014},\n",
              " {'step': 208, 'train_loss': 5.531373023986816},\n",
              " {'step': 209, 'train_loss': 5.429182052612305},\n",
              " {'step': 210, 'train_loss': 5.482989311218262},\n",
              " {'step': 211, 'train_loss': 5.593931198120117},\n",
              " {'step': 212, 'train_loss': 5.483344554901123},\n",
              " {'step': 213, 'train_loss': 5.4552903175354},\n",
              " {'step': 214, 'train_loss': 5.425174713134766},\n",
              " {'step': 215, 'train_loss': 5.394619941711426},\n",
              " {'step': 216, 'train_loss': 5.496830940246582},\n",
              " {'step': 217, 'train_loss': 5.533327102661133},\n",
              " {'step': 218, 'train_loss': 5.4912238121032715},\n",
              " {'step': 219, 'train_loss': 5.562330722808838},\n",
              " {'step': 220, 'train_loss': 5.304871082305908},\n",
              " {'step': 221, 'train_loss': 5.3457746505737305},\n",
              " {'step': 222, 'train_loss': 5.41758918762207},\n",
              " {'step': 223, 'train_loss': 5.411736011505127},\n",
              " {'step': 224, 'train_loss': 5.412827014923096},\n",
              " {'step': 225, 'train_loss': 5.3450517654418945},\n",
              " {'step': 226, 'train_loss': 5.35407829284668},\n",
              " {'step': 227, 'train_loss': 5.5518341064453125},\n",
              " {'step': 228, 'train_loss': 5.4043169021606445},\n",
              " {'step': 229, 'train_loss': 5.436760902404785},\n",
              " {'step': 230, 'train_loss': 5.48104190826416},\n",
              " {'step': 231, 'train_loss': 5.299251079559326},\n",
              " {'step': 232, 'train_loss': 5.580989360809326},\n",
              " {'step': 233, 'train_loss': 5.41370153427124},\n",
              " {'step': 234, 'train_loss': 5.181121826171875},\n",
              " {'step': 235, 'train_loss': 5.367734432220459},\n",
              " {'step': 236, 'train_loss': 5.275777339935303},\n",
              " {'step': 237, 'train_loss': 5.550502300262451},\n",
              " {'step': 238, 'train_loss': 5.493572235107422},\n",
              " {'step': 239, 'train_loss': 5.453638553619385},\n",
              " {'step': 240, 'train_loss': 5.390020370483398},\n",
              " {'step': 241, 'train_loss': 5.64306640625},\n",
              " {'step': 242, 'train_loss': 5.400513648986816},\n",
              " {'step': 243, 'train_loss': 5.425976276397705},\n",
              " {'step': 244, 'train_loss': 5.3698296546936035},\n",
              " {'step': 245, 'train_loss': 5.198696613311768},\n",
              " {'step': 246, 'train_loss': 5.209316730499268},\n",
              " {'step': 247, 'train_loss': 5.377569675445557},\n",
              " {'step': 248, 'train_loss': 5.4149627685546875},\n",
              " {'step': 249, 'train_loss': 5.3666205406188965},\n",
              " {'step': 250, 'train_loss': 5.333164215087891},\n",
              " {'step': 251, 'train_loss': 5.156434059143066},\n",
              " {'step': 252, 'train_loss': 5.3128461837768555},\n",
              " {'step': 253, 'train_loss': 5.443748950958252},\n",
              " {'step': 254, 'train_loss': 5.282620906829834},\n",
              " {'step': 255, 'train_loss': 5.2941083908081055},\n",
              " {'step': 256, 'train_loss': 5.236748695373535},\n",
              " {'step': 257, 'train_loss': 5.346299171447754},\n",
              " {'step': 258, 'train_loss': 5.353781700134277},\n",
              " {'step': 259, 'train_loss': 5.340931415557861},\n",
              " {'step': 260, 'train_loss': 5.228150367736816},\n",
              " {'step': 261, 'train_loss': 5.342605113983154},\n",
              " {'step': 262, 'train_loss': 5.388302326202393},\n",
              " {'step': 263, 'train_loss': 5.460541248321533},\n",
              " {'step': 264, 'train_loss': 5.427804470062256},\n",
              " {'step': 265, 'train_loss': 5.254043102264404},\n",
              " {'step': 266, 'train_loss': 5.221750259399414},\n",
              " {'step': 267, 'train_loss': 5.38762903213501},\n",
              " {'step': 268, 'train_loss': 5.255697727203369},\n",
              " {'step': 269, 'train_loss': 5.259950637817383},\n",
              " {'step': 270, 'train_loss': 5.17145299911499},\n",
              " {'step': 271, 'train_loss': 5.386752605438232},\n",
              " {'step': 272, 'train_loss': 5.239328861236572},\n",
              " {'step': 273, 'train_loss': 5.372757911682129},\n",
              " {'step': 274, 'train_loss': 5.205066680908203},\n",
              " {'step': 275, 'train_loss': 5.192701816558838},\n",
              " {'step': 276, 'train_loss': 5.143523216247559},\n",
              " {'step': 277, 'train_loss': 5.302921772003174},\n",
              " {'step': 278, 'train_loss': 5.202968120574951},\n",
              " {'step': 279, 'train_loss': 5.311514377593994},\n",
              " {'step': 280, 'train_loss': 5.29379940032959},\n",
              " {'step': 281, 'train_loss': 5.106523036956787},\n",
              " {'step': 282, 'train_loss': 5.1381611824035645},\n",
              " {'step': 283, 'train_loss': 5.278992652893066},\n",
              " {'step': 284, 'train_loss': 5.234774589538574},\n",
              " {'step': 285, 'train_loss': 5.253359317779541},\n",
              " {'step': 286, 'train_loss': 5.254481315612793},\n",
              " {'step': 287, 'train_loss': 5.230638027191162},\n",
              " {'step': 288, 'train_loss': 5.305098056793213},\n",
              " {'step': 289, 'train_loss': 5.227379322052002},\n",
              " {'step': 290, 'train_loss': 5.2933573722839355},\n",
              " {'step': 291, 'train_loss': 5.462745189666748},\n",
              " {'step': 292, 'train_loss': 5.202146530151367},\n",
              " {'step': 293, 'train_loss': 5.285743713378906},\n",
              " {'step': 294, 'train_loss': 5.336248397827148},\n",
              " {'step': 295, 'train_loss': 5.283276557922363},\n",
              " {'step': 296, 'train_loss': 5.275354862213135},\n",
              " {'step': 297, 'train_loss': 5.258694171905518},\n",
              " {'step': 298, 'train_loss': 5.278975963592529},\n",
              " {'step': 299, 'train_loss': 5.130582809448242},\n",
              " {'step': 300, 'train_loss': 5.3244099617004395},\n",
              " {'step': 301, 'train_loss': 5.316249847412109},\n",
              " {'step': 302, 'train_loss': 5.144835948944092},\n",
              " {'step': 303, 'train_loss': 5.181732654571533},\n",
              " {'step': 304, 'train_loss': 5.234304428100586},\n",
              " {'step': 305, 'train_loss': 5.360167980194092},\n",
              " {'step': 306, 'train_loss': 5.211554050445557},\n",
              " {'step': 307, 'train_loss': 5.216710567474365},\n",
              " {'step': 308, 'train_loss': 5.191037178039551},\n",
              " {'step': 309, 'train_loss': 5.253116607666016},\n",
              " {'step': 310, 'train_loss': 5.272846698760986},\n",
              " {'step': 311, 'train_loss': 5.222359657287598},\n",
              " {'step': 312, 'train_loss': 5.204648017883301},\n",
              " {'step': 313, 'train_loss': 5.246396064758301},\n",
              " {'step': 314, 'train_loss': 5.259006977081299},\n",
              " {'step': 315, 'train_loss': 5.206407070159912},\n",
              " {'step': 316, 'train_loss': 5.08339262008667},\n",
              " {'step': 317, 'train_loss': 5.295568466186523},\n",
              " {'step': 318, 'train_loss': 5.240293025970459},\n",
              " {'step': 319, 'train_loss': 5.213573455810547},\n",
              " {'step': 320, 'train_loss': 4.895663261413574},\n",
              " {'step': 321, 'train_loss': 5.50667667388916},\n",
              " {'step': 322, 'train_loss': 5.187763690948486},\n",
              " {'step': 323, 'train_loss': 5.250135898590088},\n",
              " {'step': 324, 'train_loss': 5.1063313484191895},\n",
              " {'step': 325, 'train_loss': 5.174783229827881},\n",
              " {'step': 326, 'train_loss': 5.233711242675781},\n",
              " {'step': 327, 'train_loss': 5.135952472686768},\n",
              " {'step': 328, 'train_loss': 5.156679630279541},\n",
              " {'step': 329, 'train_loss': 5.114612579345703},\n",
              " {'step': 330, 'train_loss': 5.157589912414551},\n",
              " {'step': 331, 'train_loss': 5.21737813949585},\n",
              " {'step': 332, 'train_loss': 5.2145538330078125},\n",
              " {'step': 333, 'train_loss': 5.105071067810059},\n",
              " {'step': 334, 'train_loss': 5.173450946807861},\n",
              " {'step': 335, 'train_loss': 5.268897533416748},\n",
              " {'step': 336, 'train_loss': 5.095746994018555},\n",
              " {'step': 337, 'train_loss': 5.074581623077393},\n",
              " {'step': 338, 'train_loss': 5.216559886932373},\n",
              " {'step': 339, 'train_loss': 5.231313228607178},\n",
              " {'step': 340, 'train_loss': 5.179142475128174},\n",
              " {'step': 341, 'train_loss': 5.070371627807617},\n",
              " {'step': 342, 'train_loss': 5.1507720947265625},\n",
              " {'step': 343, 'train_loss': 5.125454425811768},\n",
              " {'step': 344, 'train_loss': 5.247156620025635},\n",
              " {'step': 345, 'train_loss': 4.955747127532959},\n",
              " {'step': 346, 'train_loss': 5.198351860046387},\n",
              " {'step': 347, 'train_loss': 5.244842052459717},\n",
              " {'step': 348, 'train_loss': 5.1056013107299805},\n",
              " {'step': 349, 'train_loss': 5.222116470336914},\n",
              " {'step': 350, 'train_loss': 5.171998023986816},\n",
              " {'step': 351, 'train_loss': 5.087792873382568},\n",
              " {'step': 352, 'train_loss': 5.151352882385254},\n",
              " {'step': 353, 'train_loss': 5.072177886962891},\n",
              " {'step': 354, 'train_loss': 5.1587090492248535},\n",
              " {'step': 355, 'train_loss': 5.172445297241211},\n",
              " {'step': 356, 'train_loss': 5.290968418121338},\n",
              " {'step': 357, 'train_loss': 5.2038116455078125},\n",
              " {'step': 358, 'train_loss': 5.205150604248047},\n",
              " {'step': 359, 'train_loss': 5.112959861755371},\n",
              " {'step': 360, 'train_loss': 5.100018501281738},\n",
              " {'step': 361, 'train_loss': 5.30513858795166},\n",
              " {'step': 362, 'train_loss': 5.061429500579834},\n",
              " {'step': 363, 'train_loss': 5.306804180145264},\n",
              " {'step': 364, 'train_loss': 5.22298526763916},\n",
              " {'step': 365, 'train_loss': 4.979709148406982},\n",
              " {'step': 366, 'train_loss': 5.270254135131836},\n",
              " {'step': 367, 'train_loss': 5.341934680938721},\n",
              " {'step': 368, 'train_loss': 5.328076362609863},\n",
              " {'step': 369, 'train_loss': 5.200632095336914},\n",
              " {'step': 370, 'train_loss': 5.0119218826293945},\n",
              " {'step': 371, 'train_loss': 5.029152870178223},\n",
              " {'step': 372, 'train_loss': 5.143714904785156},\n",
              " {'step': 373, 'train_loss': 5.10402774810791},\n",
              " {'step': 374, 'train_loss': 5.082812309265137},\n",
              " {'step': 375, 'train_loss': 5.298189163208008},\n",
              " {'step': 376, 'train_loss': 5.0597686767578125},\n",
              " {'step': 377, 'train_loss': 5.093031406402588},\n",
              " {'step': 378, 'train_loss': 5.162484169006348},\n",
              " {'step': 379, 'train_loss': 5.286736488342285},\n",
              " {'step': 380, 'train_loss': 5.101831436157227},\n",
              " {'step': 381, 'train_loss': 5.166261672973633},\n",
              " {'step': 382, 'train_loss': 5.011640548706055},\n",
              " {'step': 383, 'train_loss': 5.035333633422852},\n",
              " {'step': 384, 'train_loss': 5.036679744720459},\n",
              " {'step': 385, 'train_loss': 5.306996822357178},\n",
              " {'step': 386, 'train_loss': 5.0076003074646},\n",
              " {'step': 387, 'train_loss': 5.093479633331299},\n",
              " {'step': 388, 'train_loss': 4.976170063018799},\n",
              " {'step': 389, 'train_loss': 4.916290760040283},\n",
              " {'step': 390, 'train_loss': 5.040968418121338},\n",
              " {'step': 391, 'train_loss': 5.125514507293701},\n",
              " {'step': 392, 'train_loss': 5.093578338623047},\n",
              " {'step': 393, 'train_loss': 5.078884124755859},\n",
              " {'step': 394, 'train_loss': 5.019901275634766},\n",
              " {'step': 395, 'train_loss': 5.083425045013428},\n",
              " {'step': 396, 'train_loss': 5.183268070220947},\n",
              " {'step': 397, 'train_loss': 5.118241786956787},\n",
              " {'step': 398, 'train_loss': 5.050731658935547},\n",
              " {'step': 399, 'train_loss': 5.223462104797363},\n",
              " {'step': 400, 'train_loss': 5.006255149841309},\n",
              " {'step': 401, 'train_loss': 5.163806915283203},\n",
              " {'step': 402, 'train_loss': 5.151505947113037},\n",
              " {'step': 403, 'train_loss': 5.0700225830078125},\n",
              " {'step': 404, 'train_loss': 5.098755836486816},\n",
              " {'step': 405, 'train_loss': 5.1258015632629395},\n",
              " {'step': 406, 'train_loss': 5.315492630004883},\n",
              " {'step': 407, 'train_loss': 5.060413360595703},\n",
              " {'step': 408, 'train_loss': 5.063150405883789},\n",
              " {'step': 409, 'train_loss': 5.16451358795166},\n",
              " {'step': 410, 'train_loss': 4.921462535858154},\n",
              " {'step': 411, 'train_loss': 5.141750812530518},\n",
              " {'step': 412, 'train_loss': 5.0962958335876465},\n",
              " {'step': 413, 'train_loss': 5.095948219299316},\n",
              " {'step': 414, 'train_loss': 5.161494731903076},\n",
              " {'step': 415, 'train_loss': 5.221571445465088},\n",
              " {'step': 416, 'train_loss': 5.08030366897583},\n",
              " {'step': 417, 'train_loss': 5.055623531341553},\n",
              " {'step': 418, 'train_loss': 5.023617267608643},\n",
              " {'step': 419, 'train_loss': 5.07837438583374},\n",
              " {'step': 420, 'train_loss': 5.092581748962402},\n",
              " {'step': 421, 'train_loss': 5.072193622589111},\n",
              " {'step': 422, 'train_loss': 5.03213357925415},\n",
              " {'step': 423, 'train_loss': 5.305527687072754},\n",
              " {'step': 424, 'train_loss': 5.157072067260742},\n",
              " {'step': 425, 'train_loss': 5.059497356414795},\n",
              " {'step': 426, 'train_loss': 5.082494258880615},\n",
              " {'step': 427, 'train_loss': 5.146284103393555},\n",
              " {'step': 428, 'train_loss': 5.144371032714844},\n",
              " {'step': 429, 'train_loss': 5.043665885925293},\n",
              " {'step': 430, 'train_loss': 5.044711589813232},\n",
              " {'step': 431, 'train_loss': 5.031794548034668},\n",
              " {'step': 432, 'train_loss': 5.334057807922363},\n",
              " {'step': 433, 'train_loss': 5.106303691864014},\n",
              " {'step': 434, 'train_loss': 5.100714683532715},\n",
              " {'step': 435, 'train_loss': 5.054747104644775},\n",
              " {'step': 436, 'train_loss': 4.94317626953125},\n",
              " {'step': 437, 'train_loss': 4.928979873657227},\n",
              " {'step': 438, 'train_loss': 4.9707350730896},\n",
              " {'step': 439, 'train_loss': 5.006022930145264},\n",
              " {'step': 440, 'train_loss': 5.081789493560791},\n",
              " {'step': 441, 'train_loss': 5.076113224029541},\n",
              " {'step': 442, 'train_loss': 5.085782527923584},\n",
              " {'step': 443, 'train_loss': 4.937224388122559},\n",
              " {'step': 444, 'train_loss': 4.804088592529297},\n",
              " {'step': 445, 'train_loss': 5.01839017868042},\n",
              " {'step': 446, 'train_loss': 5.025193691253662},\n",
              " {'step': 447, 'train_loss': 4.9998626708984375},\n",
              " {'step': 448, 'train_loss': 5.040356159210205},\n",
              " {'step': 449, 'train_loss': 5.091433048248291},\n",
              " {'step': 450, 'train_loss': 5.015182018280029},\n",
              " {'step': 451, 'train_loss': 4.892190933227539},\n",
              " {'step': 452, 'train_loss': 4.899415016174316},\n",
              " {'step': 453, 'train_loss': 5.003859519958496},\n",
              " {'step': 454, 'train_loss': 5.149337291717529},\n",
              " {'step': 455, 'train_loss': 5.0463948249816895},\n",
              " {'step': 456, 'train_loss': 4.990828514099121},\n",
              " {'step': 457, 'train_loss': 5.085023403167725},\n",
              " {'step': 458, 'train_loss': 5.0593767166137695},\n",
              " {'step': 459, 'train_loss': 5.015804290771484},\n",
              " {'step': 460, 'train_loss': 5.101353168487549},\n",
              " {'step': 461, 'train_loss': 5.027591705322266},\n",
              " {'step': 462, 'train_loss': 5.019528865814209},\n",
              " {'step': 463, 'train_loss': 4.984124660491943},\n",
              " {'step': 464, 'train_loss': 4.940833568572998},\n",
              " {'step': 465, 'train_loss': 4.920216083526611},\n",
              " {'step': 466, 'train_loss': 4.989704132080078},\n",
              " {'step': 467, 'train_loss': 4.992586135864258},\n",
              " {'step': 468, 'train_loss': 5.075007438659668},\n",
              " {'step': 469, 'train_loss': 5.003719329833984},\n",
              " {'step': 470, 'train_loss': 4.943905353546143},\n",
              " {'step': 471, 'train_loss': 5.14833402633667},\n",
              " {'step': 472, 'train_loss': 5.0780720710754395},\n",
              " {'step': 473, 'train_loss': 4.882382392883301},\n",
              " {'step': 474, 'train_loss': 5.2562127113342285},\n",
              " {'step': 475, 'train_loss': 4.818055629730225},\n",
              " {'step': 476, 'train_loss': 5.037609577178955},\n",
              " {'step': 477, 'train_loss': 5.123337745666504},\n",
              " {'step': 478, 'train_loss': 4.985408306121826},\n",
              " {'step': 479, 'train_loss': 4.921868801116943},\n",
              " {'step': 480, 'train_loss': 4.8449320793151855},\n",
              " {'step': 481, 'train_loss': 5.036040782928467},\n",
              " {'step': 482, 'train_loss': 4.898875713348389},\n",
              " {'step': 483, 'train_loss': 5.009551525115967},\n",
              " {'step': 484, 'train_loss': 4.94397497177124},\n",
              " {'step': 485, 'train_loss': 5.13902473449707},\n",
              " {'step': 486, 'train_loss': 5.0791544914245605},\n",
              " {'step': 487, 'train_loss': 4.988691806793213},\n",
              " {'step': 488, 'train_loss': 5.013467788696289},\n",
              " {'step': 489, 'train_loss': 5.023211479187012},\n",
              " {'step': 490, 'train_loss': 4.9566168785095215},\n",
              " {'step': 491, 'train_loss': 5.128715991973877},\n",
              " {'step': 492, 'train_loss': 4.930099010467529},\n",
              " {'step': 493, 'train_loss': 4.9543046951293945},\n",
              " {'step': 494, 'train_loss': 5.083960056304932},\n",
              " {'step': 495, 'train_loss': 5.027308464050293},\n",
              " {'step': 496, 'train_loss': 5.060235977172852},\n",
              " {'step': 497, 'train_loss': 4.944437503814697},\n",
              " {'step': 498, 'train_loss': 4.9654765129089355},\n",
              " {'step': 499, 'train_loss': 5.12076997756958},\n",
              " {'step': 500, 'train_loss': 4.977789878845215},\n",
              " {'step': 501, 'train_loss': 4.978320121765137},\n",
              " {'step': 502, 'train_loss': 4.9235663414001465},\n",
              " {'step': 503, 'train_loss': 5.032637119293213},\n",
              " {'step': 504, 'train_loss': 5.109720706939697},\n",
              " {'step': 505, 'train_loss': 5.1807451248168945},\n",
              " {'step': 506, 'train_loss': 5.0508222579956055},\n",
              " {'step': 507, 'train_loss': 5.016037940979004},\n",
              " {'step': 508, 'train_loss': 5.1780195236206055},\n",
              " {'step': 509, 'train_loss': 5.124094486236572},\n",
              " {'step': 510, 'train_loss': 5.054069995880127},\n",
              " {'step': 511, 'train_loss': 5.034177780151367},\n",
              " {'step': 512, 'train_loss': 4.958723545074463},\n",
              " {'step': 513, 'train_loss': 4.880174160003662},\n",
              " {'step': 514, 'train_loss': 4.825078964233398},\n",
              " {'step': 515, 'train_loss': 5.016269207000732},\n",
              " {'step': 516, 'train_loss': 4.974560737609863},\n",
              " {'step': 517, 'train_loss': 4.799953460693359},\n",
              " {'step': 518, 'train_loss': 5.080667018890381},\n",
              " {'step': 519, 'train_loss': 4.890087604522705},\n",
              " {'step': 520, 'train_loss': 4.807104110717773},\n",
              " {'step': 521, 'train_loss': 5.067512035369873},\n",
              " {'step': 522, 'train_loss': 5.047885894775391},\n",
              " {'step': 523, 'train_loss': 4.994065761566162},\n",
              " {'step': 524, 'train_loss': 5.068122863769531},\n",
              " {'step': 525, 'train_loss': 5.0230302810668945},\n",
              " {'step': 526, 'train_loss': 5.002374649047852},\n",
              " {'step': 527, 'train_loss': 5.163885593414307},\n",
              " {'step': 528, 'train_loss': 5.157695293426514},\n",
              " {'step': 529, 'train_loss': 5.066279888153076},\n",
              " {'step': 530, 'train_loss': 4.8883442878723145},\n",
              " {'step': 531, 'train_loss': 4.973006725311279},\n",
              " {'step': 532, 'train_loss': 5.201048851013184},\n",
              " {'step': 533, 'train_loss': 4.960421085357666},\n",
              " {'step': 534, 'train_loss': 4.966756343841553},\n",
              " {'step': 535, 'train_loss': 4.993124961853027},\n",
              " {'step': 536, 'train_loss': 4.9253010749816895},\n",
              " {'step': 537, 'train_loss': 4.954239845275879},\n",
              " {'step': 538, 'train_loss': 4.973170280456543},\n",
              " {'step': 539, 'train_loss': 5.002407550811768},\n",
              " {'step': 540, 'train_loss': 4.930235385894775},\n",
              " {'step': 541, 'train_loss': 4.976437091827393},\n",
              " {'step': 542, 'train_loss': 4.968847274780273},\n",
              " {'step': 543, 'train_loss': 4.97325325012207},\n",
              " {'step': 544, 'train_loss': 4.949077606201172},\n",
              " {'step': 545, 'train_loss': 5.105555534362793},\n",
              " {'step': 546, 'train_loss': 4.924804210662842},\n",
              " {'step': 547, 'train_loss': 4.904389381408691},\n",
              " {'step': 548, 'train_loss': 5.0476837158203125},\n",
              " {'step': 549, 'train_loss': 5.156867027282715},\n",
              " {'step': 550, 'train_loss': 5.01181697845459},\n",
              " {'step': 551, 'train_loss': 5.041390419006348},\n",
              " {'step': 552, 'train_loss': 5.03542947769165},\n",
              " {'step': 553, 'train_loss': 4.950960636138916},\n",
              " {'step': 554, 'train_loss': 5.106527328491211},\n",
              " {'step': 555, 'train_loss': 4.907662391662598},\n",
              " {'step': 556, 'train_loss': 5.009424686431885},\n",
              " {'step': 557, 'train_loss': 4.871612548828125},\n",
              " {'step': 558, 'train_loss': 5.002490997314453},\n",
              " {'step': 559, 'train_loss': 4.842870235443115},\n",
              " {'step': 560, 'train_loss': 4.888885021209717},\n",
              " {'step': 561, 'train_loss': 5.004605293273926},\n",
              " {'step': 562, 'train_loss': 5.056156158447266},\n",
              " {'step': 563, 'train_loss': 5.050524711608887},\n",
              " {'step': 564, 'train_loss': 4.852752208709717},\n",
              " {'step': 565, 'train_loss': 5.127012252807617},\n",
              " {'step': 566, 'train_loss': 5.086915016174316},\n",
              " {'step': 567, 'train_loss': 4.917850494384766},\n",
              " {'step': 568, 'train_loss': 4.946150779724121},\n",
              " {'step': 569, 'train_loss': 5.019569396972656},\n",
              " {'step': 570, 'train_loss': 4.7489542961120605},\n",
              " {'step': 571, 'train_loss': 4.915191173553467},\n",
              " {'step': 572, 'train_loss': 5.098698139190674},\n",
              " {'step': 573, 'train_loss': 4.999419689178467},\n",
              " {'step': 574, 'train_loss': 5.158798694610596},\n",
              " {'step': 575, 'train_loss': 5.031079292297363},\n",
              " {'step': 576, 'train_loss': 5.061727523803711},\n",
              " {'step': 577, 'train_loss': 4.797098636627197},\n",
              " {'step': 578, 'train_loss': 4.893768787384033},\n",
              " {'step': 579, 'train_loss': 4.9636006355285645},\n",
              " {'step': 580, 'train_loss': 4.9237589836120605},\n",
              " {'step': 581, 'train_loss': 4.984252452850342},\n",
              " {'step': 582, 'train_loss': 4.800009250640869},\n",
              " {'step': 583, 'train_loss': 4.881263732910156},\n",
              " {'step': 584, 'train_loss': 4.960326671600342},\n",
              " {'step': 585, 'train_loss': 4.921307563781738},\n",
              " {'step': 586, 'train_loss': 4.927623748779297},\n",
              " {'step': 587, 'train_loss': 4.93699836730957},\n",
              " {'step': 588, 'train_loss': 4.800010681152344},\n",
              " {'step': 589, 'train_loss': 4.922676086425781},\n",
              " {'step': 590, 'train_loss': 4.922836780548096},\n",
              " {'step': 591, 'train_loss': 4.870185375213623},\n",
              " {'step': 592, 'train_loss': 4.940258502960205},\n",
              " {'step': 593, 'train_loss': 4.912626266479492},\n",
              " {'step': 594, 'train_loss': 4.880251407623291},\n",
              " {'step': 595, 'train_loss': 5.0073018074035645},\n",
              " {'step': 596, 'train_loss': 4.949254989624023},\n",
              " {'step': 597, 'train_loss': 4.861274719238281},\n",
              " {'step': 598, 'train_loss': 4.933833599090576},\n",
              " {'step': 599, 'train_loss': 4.872341156005859},\n",
              " {'step': 600, 'train_loss': 4.9262919425964355},\n",
              " {'step': 601, 'train_loss': 5.059436798095703},\n",
              " {'step': 602, 'train_loss': 5.071960926055908},\n",
              " {'step': 603, 'train_loss': 4.998400688171387},\n",
              " {'step': 604, 'train_loss': 4.873552322387695},\n",
              " {'step': 605, 'train_loss': 4.856155872344971},\n",
              " {'step': 606, 'train_loss': 4.899999141693115},\n",
              " {'step': 607, 'train_loss': 4.90328311920166},\n",
              " {'step': 608, 'train_loss': 4.968526363372803},\n",
              " {'step': 609, 'train_loss': 4.836572170257568},\n",
              " {'step': 610, 'train_loss': 4.8698859214782715},\n",
              " {'step': 611, 'train_loss': 4.817019462585449},\n",
              " {'step': 612, 'train_loss': 4.964895248413086},\n",
              " {'step': 613, 'train_loss': 4.891618728637695},\n",
              " {'step': 614, 'train_loss': 4.944984436035156},\n",
              " {'step': 615, 'train_loss': 4.873797416687012},\n",
              " {'step': 616, 'train_loss': 4.8616719245910645},\n",
              " {'step': 617, 'train_loss': 5.0115180015563965},\n",
              " {'step': 618, 'train_loss': 4.917518138885498},\n",
              " {'step': 619, 'train_loss': 4.886629104614258},\n",
              " {'step': 620, 'train_loss': 5.0087761878967285},\n",
              " {'step': 621, 'train_loss': 4.889346122741699},\n",
              " {'step': 622, 'train_loss': 4.918785572052002},\n",
              " {'step': 623, 'train_loss': 5.024064064025879},\n",
              " {'step': 624, 'train_loss': 4.92282247543335},\n",
              " {'step': 625, 'train_loss': 4.891600608825684},\n",
              " {'step': 626, 'train_loss': 4.8728203773498535},\n",
              " {'step': 627, 'train_loss': 4.8233795166015625},\n",
              " {'step': 628, 'train_loss': 4.943695068359375},\n",
              " {'step': 629, 'train_loss': 4.853024482727051},\n",
              " {'step': 630, 'train_loss': 5.065876007080078},\n",
              " {'step': 631, 'train_loss': 5.069857120513916},\n",
              " {'step': 632, 'train_loss': 5.016073703765869},\n",
              " {'step': 633, 'train_loss': 5.041351318359375},\n",
              " {'step': 634, 'train_loss': 4.945940971374512},\n",
              " {'step': 635, 'train_loss': 4.961482048034668},\n",
              " {'step': 636, 'train_loss': 4.914465427398682},\n",
              " {'step': 637, 'train_loss': 5.028171539306641},\n",
              " {'step': 638, 'train_loss': 5.029642105102539},\n",
              " {'step': 639, 'train_loss': 5.0083794593811035},\n",
              " {'step': 640, 'train_loss': 4.903229236602783},\n",
              " {'step': 641, 'train_loss': 4.844906806945801},\n",
              " {'step': 642, 'train_loss': 4.936007499694824},\n",
              " {'step': 643, 'train_loss': 4.84823751449585},\n",
              " {'step': 644, 'train_loss': 4.803854465484619},\n",
              " {'step': 645, 'train_loss': 4.85464334487915},\n",
              " {'step': 646, 'train_loss': 4.885584354400635},\n",
              " {'step': 647, 'train_loss': 4.897927284240723},\n",
              " {'step': 648, 'train_loss': 4.927600860595703},\n",
              " {'step': 649, 'train_loss': 4.7541422843933105},\n",
              " {'step': 650, 'train_loss': 4.9117326736450195},\n",
              " {'step': 651, 'train_loss': 4.975740909576416},\n",
              " {'step': 652, 'train_loss': 4.81834077835083},\n",
              " {'step': 653, 'train_loss': 5.004146575927734},\n",
              " {'step': 654, 'train_loss': 4.871242523193359},\n",
              " {'step': 655, 'train_loss': 4.8181986808776855},\n",
              " {'step': 656, 'train_loss': 4.78465461730957},\n",
              " {'step': 657, 'train_loss': 4.8530988693237305},\n",
              " {'step': 658, 'train_loss': 4.935529708862305},\n",
              " {'step': 659, 'train_loss': 4.82033109664917},\n",
              " {'step': 660, 'train_loss': 4.767595291137695},\n",
              " {'step': 661, 'train_loss': 4.81071138381958},\n",
              " {'step': 662, 'train_loss': 4.808255195617676},\n",
              " {'step': 663, 'train_loss': 4.812199115753174},\n",
              " {'step': 664, 'train_loss': 4.932823181152344},\n",
              " {'step': 665, 'train_loss': 4.791365146636963},\n",
              " {'step': 666, 'train_loss': 4.9075164794921875},\n",
              " {'step': 667, 'train_loss': 4.767513751983643},\n",
              " {'step': 668, 'train_loss': 4.905014514923096},\n",
              " {'step': 669, 'train_loss': 4.834194183349609},\n",
              " {'step': 670, 'train_loss': 4.734471321105957},\n",
              " {'step': 671, 'train_loss': 4.823004722595215},\n",
              " {'step': 672, 'train_loss': 4.879371166229248},\n",
              " {'step': 673, 'train_loss': 4.9375224113464355},\n",
              " {'step': 674, 'train_loss': 5.001861095428467},\n",
              " {'step': 675, 'train_loss': 4.739859580993652},\n",
              " {'step': 676, 'train_loss': 4.82335901260376},\n",
              " {'step': 677, 'train_loss': 4.67854118347168},\n",
              " {'step': 678, 'train_loss': 4.896256446838379},\n",
              " {'step': 679, 'train_loss': 5.042855739593506},\n",
              " {'step': 680, 'train_loss': 4.881466865539551},\n",
              " {'step': 681, 'train_loss': 4.845956802368164},\n",
              " {'step': 682, 'train_loss': 4.920372009277344},\n",
              " {'step': 683, 'train_loss': 4.6515655517578125},\n",
              " {'step': 684, 'train_loss': 4.932341575622559},\n",
              " {'step': 685, 'train_loss': 4.871348857879639},\n",
              " {'step': 686, 'train_loss': 4.805248737335205},\n",
              " {'step': 687, 'train_loss': 4.764315605163574},\n",
              " {'step': 688, 'train_loss': 4.864315986633301},\n",
              " {'step': 689, 'train_loss': 4.788247108459473},\n",
              " {'step': 690, 'train_loss': 4.947995185852051},\n",
              " {'step': 691, 'train_loss': 4.944516181945801},\n",
              " {'step': 692, 'train_loss': 4.895016670227051},\n",
              " {'step': 693, 'train_loss': 4.634767532348633},\n",
              " {'step': 694, 'train_loss': 4.853531360626221},\n",
              " {'step': 695, 'train_loss': 4.868062496185303},\n",
              " {'step': 696, 'train_loss': 4.72724723815918},\n",
              " {'step': 697, 'train_loss': 4.803262710571289},\n",
              " {'step': 698, 'train_loss': 4.7533040046691895},\n",
              " {'step': 699, 'train_loss': 4.709687232971191},\n",
              " {'step': 700, 'train_loss': 4.8886895179748535},\n",
              " {'step': 701, 'train_loss': 4.702383995056152},\n",
              " {'step': 702, 'train_loss': 4.809493064880371},\n",
              " {'step': 703, 'train_loss': 4.844295024871826},\n",
              " {'step': 704, 'train_loss': 4.81089973449707},\n",
              " {'step': 705, 'train_loss': 4.96072244644165},\n",
              " {'step': 706, 'train_loss': 4.841848373413086},\n",
              " {'step': 707, 'train_loss': 4.922619342803955},\n",
              " {'step': 708, 'train_loss': 4.900825500488281},\n",
              " {'step': 709, 'train_loss': 4.703988552093506},\n",
              " {'step': 710, 'train_loss': 4.67334508895874},\n",
              " {'step': 711, 'train_loss': 4.816013813018799},\n",
              " {'step': 712, 'train_loss': 4.760804653167725},\n",
              " {'step': 713, 'train_loss': 4.829108238220215},\n",
              " {'step': 714, 'train_loss': 4.884246826171875},\n",
              " {'step': 715, 'train_loss': 4.927090167999268},\n",
              " {'step': 716, 'train_loss': 4.824532508850098},\n",
              " {'step': 717, 'train_loss': 4.836040019989014},\n",
              " {'step': 718, 'train_loss': 4.77356481552124},\n",
              " {'step': 719, 'train_loss': 4.883303642272949},\n",
              " {'step': 720, 'train_loss': 4.736125469207764},\n",
              " {'step': 721, 'train_loss': 4.924013137817383},\n",
              " {'step': 722, 'train_loss': 4.9179911613464355},\n",
              " {'step': 723, 'train_loss': 4.9151201248168945},\n",
              " {'step': 724, 'train_loss': 4.63739538192749},\n",
              " {'step': 725, 'train_loss': 4.684614181518555},\n",
              " {'step': 726, 'train_loss': 4.814596176147461},\n",
              " {'step': 727, 'train_loss': 4.737786769866943},\n",
              " {'step': 728, 'train_loss': 4.830571174621582},\n",
              " {'step': 729, 'train_loss': 4.738523483276367},\n",
              " {'step': 730, 'train_loss': 4.824923515319824},\n",
              " {'step': 731, 'train_loss': 5.02046012878418},\n",
              " {'step': 732, 'train_loss': 4.865375995635986},\n",
              " {'step': 733, 'train_loss': 4.822602272033691},\n",
              " {'step': 734, 'train_loss': 4.897233009338379},\n",
              " {'step': 735, 'train_loss': 4.762199878692627},\n",
              " {'step': 736, 'train_loss': 4.814811706542969},\n",
              " {'step': 737, 'train_loss': 4.999599933624268},\n",
              " {'step': 738, 'train_loss': 4.7997870445251465},\n",
              " {'step': 739, 'train_loss': 4.764865875244141},\n",
              " {'step': 740, 'train_loss': 4.739400863647461},\n",
              " {'step': 741, 'train_loss': 4.785422325134277},\n",
              " {'step': 742, 'train_loss': 4.903478145599365},\n",
              " {'step': 743, 'train_loss': 4.860511302947998},\n",
              " {'step': 744, 'train_loss': 4.68583345413208},\n",
              " {'step': 745, 'train_loss': 4.917549133300781},\n",
              " {'step': 746, 'train_loss': 4.816150665283203},\n",
              " {'step': 747, 'train_loss': 4.739798545837402},\n",
              " {'step': 748, 'train_loss': 4.814108371734619},\n",
              " {'step': 749, 'train_loss': 4.756093502044678},\n",
              " {'step': 750, 'train_loss': 4.751804351806641},\n",
              " {'step': 751, 'train_loss': 4.963374614715576},\n",
              " {'step': 752, 'train_loss': 4.784327983856201},\n",
              " {'step': 753, 'train_loss': 4.826559066772461},\n",
              " {'step': 754, 'train_loss': 4.728576183319092},\n",
              " {'step': 755, 'train_loss': 4.845527172088623},\n",
              " {'step': 756, 'train_loss': 4.7639689445495605},\n",
              " {'step': 757, 'train_loss': 4.803358554840088},\n",
              " {'step': 758, 'train_loss': 4.592474937438965},\n",
              " {'step': 759, 'train_loss': 4.822757720947266},\n",
              " {'step': 760, 'train_loss': 4.845363616943359},\n",
              " {'step': 761, 'train_loss': 4.883949279785156},\n",
              " {'step': 762, 'train_loss': 4.848867893218994},\n",
              " {'step': 763, 'train_loss': 4.824899196624756},\n",
              " {'step': 764, 'train_loss': 4.790734767913818},\n",
              " {'step': 765, 'train_loss': 4.808805465698242},\n",
              " {'step': 766, 'train_loss': 4.7342448234558105},\n",
              " {'step': 767, 'train_loss': 4.949429512023926},\n",
              " {'step': 768, 'train_loss': 4.986042499542236},\n",
              " {'step': 769, 'train_loss': 4.787067413330078},\n",
              " {'step': 770, 'train_loss': 4.7711920738220215},\n",
              " {'step': 771, 'train_loss': 4.662242889404297},\n",
              " {'step': 772, 'train_loss': 4.721757411956787},\n",
              " {'step': 773, 'train_loss': 4.928629398345947},\n",
              " {'step': 774, 'train_loss': 4.7573442459106445},\n",
              " {'step': 775, 'train_loss': 4.707421779632568},\n",
              " {'step': 776, 'train_loss': 4.855259895324707},\n",
              " {'step': 777, 'train_loss': 4.946381092071533},\n",
              " {'step': 778, 'train_loss': 4.7584123611450195},\n",
              " {'step': 779, 'train_loss': 4.919162750244141},\n",
              " {'step': 780, 'train_loss': 4.7576775550842285},\n",
              " {'step': 781, 'train_loss': 4.8721466064453125},\n",
              " {'step': 782, 'train_loss': 4.715890407562256},\n",
              " {'step': 783, 'train_loss': 4.8499369621276855},\n",
              " {'step': 784, 'train_loss': 4.813864707946777},\n",
              " {'step': 785, 'train_loss': 4.744193077087402},\n",
              " {'step': 786, 'train_loss': 4.910788059234619},\n",
              " {'step': 787, 'train_loss': 4.803667068481445},\n",
              " {'step': 788, 'train_loss': 4.818739891052246},\n",
              " {'step': 789, 'train_loss': 4.818401336669922},\n",
              " {'step': 790, 'train_loss': 4.877914905548096},\n",
              " {'step': 791, 'train_loss': 4.788551330566406},\n",
              " {'step': 792, 'train_loss': 4.581672668457031},\n",
              " {'step': 793, 'train_loss': 4.725655555725098},\n",
              " {'step': 794, 'train_loss': 4.440052032470703},\n",
              " {'step': 795, 'train_loss': 4.7598090171813965},\n",
              " {'step': 796, 'train_loss': 4.895411491394043},\n",
              " {'step': 797, 'train_loss': 4.776676654815674},\n",
              " {'step': 798, 'train_loss': 4.749563217163086},\n",
              " {'step': 799, 'train_loss': 4.773685932159424},\n",
              " {'step': 800, 'train_loss': 4.973230361938477},\n",
              " {'step': 801, 'train_loss': 4.867336750030518},\n",
              " {'step': 802, 'train_loss': 4.871286869049072},\n",
              " {'step': 803, 'train_loss': 4.704392910003662},\n",
              " {'step': 804, 'train_loss': 4.946804046630859},\n",
              " {'step': 805, 'train_loss': 4.792552471160889},\n",
              " {'step': 806, 'train_loss': 4.716226100921631},\n",
              " {'step': 807, 'train_loss': 4.600923538208008},\n",
              " {'step': 808, 'train_loss': 4.716732501983643},\n",
              " {'step': 809, 'train_loss': 4.75696325302124},\n",
              " {'step': 810, 'train_loss': 4.857464790344238},\n",
              " {'step': 811, 'train_loss': 4.822353839874268},\n",
              " {'step': 812, 'train_loss': 4.789158821105957},\n",
              " {'step': 813, 'train_loss': 4.717778205871582},\n",
              " {'step': 814, 'train_loss': 4.815674304962158},\n",
              " {'step': 815, 'train_loss': 4.837523937225342},\n",
              " {'step': 816, 'train_loss': 4.9073486328125},\n",
              " {'step': 817, 'train_loss': 4.81270170211792},\n",
              " {'step': 818, 'train_loss': 4.758237838745117},\n",
              " {'step': 819, 'train_loss': 4.913079261779785},\n",
              " {'step': 820, 'train_loss': 4.737768650054932},\n",
              " {'step': 821, 'train_loss': 4.908742904663086},\n",
              " {'step': 822, 'train_loss': 4.7926926612854},\n",
              " {'step': 823, 'train_loss': 4.763210296630859},\n",
              " {'step': 824, 'train_loss': 4.82732629776001},\n",
              " {'step': 825, 'train_loss': 4.685711860656738},\n",
              " {'step': 826, 'train_loss': 4.87658166885376},\n",
              " {'step': 827, 'train_loss': 4.733327388763428},\n",
              " {'step': 828, 'train_loss': 4.906244277954102},\n",
              " {'step': 829, 'train_loss': 4.738551139831543},\n",
              " {'step': 830, 'train_loss': 4.811468601226807},\n",
              " {'step': 831, 'train_loss': 4.615466117858887},\n",
              " {'step': 832, 'train_loss': 4.846179962158203},\n",
              " {'step': 833, 'train_loss': 4.800503730773926},\n",
              " {'step': 834, 'train_loss': 4.651414394378662},\n",
              " {'step': 835, 'train_loss': 4.727301597595215},\n",
              " {'step': 836, 'train_loss': 4.725016117095947},\n",
              " {'step': 837, 'train_loss': 4.6528191566467285},\n",
              " {'step': 838, 'train_loss': 4.828373432159424},\n",
              " {'step': 839, 'train_loss': 4.71514892578125},\n",
              " {'step': 840, 'train_loss': 4.7281174659729},\n",
              " {'step': 841, 'train_loss': 4.820094108581543},\n",
              " {'step': 842, 'train_loss': 4.6863298416137695},\n",
              " {'step': 843, 'train_loss': 4.706833839416504},\n",
              " {'step': 844, 'train_loss': 4.737392902374268},\n",
              " {'step': 845, 'train_loss': 4.867528915405273},\n",
              " {'step': 846, 'train_loss': 4.651278018951416},\n",
              " {'step': 847, 'train_loss': 4.7404704093933105},\n",
              " {'step': 848, 'train_loss': 4.7077131271362305},\n",
              " {'step': 849, 'train_loss': 4.696532249450684},\n",
              " {'step': 850, 'train_loss': 4.643098831176758},\n",
              " {'step': 851, 'train_loss': 4.787202835083008},\n",
              " {'step': 852, 'train_loss': 4.783825874328613},\n",
              " {'step': 853, 'train_loss': 4.8985161781311035},\n",
              " {'step': 854, 'train_loss': 4.766648292541504},\n",
              " {'step': 855, 'train_loss': 4.949474334716797},\n",
              " {'step': 856, 'train_loss': 4.8357391357421875},\n",
              " {'step': 857, 'train_loss': 4.749491214752197},\n",
              " {'step': 858, 'train_loss': 4.988775730133057},\n",
              " {'step': 859, 'train_loss': 4.628385543823242},\n",
              " {'step': 860, 'train_loss': 4.75705623626709},\n",
              " {'step': 861, 'train_loss': 4.703607082366943},\n",
              " {'step': 862, 'train_loss': 4.760298728942871},\n",
              " {'step': 863, 'train_loss': 4.753278732299805},\n",
              " {'step': 864, 'train_loss': 4.73444128036499},\n",
              " {'step': 865, 'train_loss': 4.93168830871582},\n",
              " {'step': 866, 'train_loss': 4.656091213226318},\n",
              " {'step': 867, 'train_loss': 4.8041582107543945},\n",
              " {'step': 868, 'train_loss': 4.763566017150879},\n",
              " {'step': 869, 'train_loss': 4.805486679077148},\n",
              " {'step': 870, 'train_loss': 4.641883373260498},\n",
              " {'step': 871, 'train_loss': 4.733224391937256},\n",
              " {'step': 872, 'train_loss': 4.6237382888793945},\n",
              " {'step': 873, 'train_loss': 4.707955837249756},\n",
              " {'step': 874, 'train_loss': 4.843612194061279},\n",
              " {'step': 875, 'train_loss': 4.718810081481934},\n",
              " {'step': 876, 'train_loss': 4.5871710777282715},\n",
              " {'step': 877, 'train_loss': 4.728589057922363},\n",
              " {'step': 878, 'train_loss': 4.6306610107421875},\n",
              " {'step': 879, 'train_loss': 4.765659809112549},\n",
              " {'step': 880, 'train_loss': 4.764143943786621},\n",
              " {'step': 881, 'train_loss': 4.852651596069336},\n",
              " {'step': 882, 'train_loss': 4.697822093963623},\n",
              " {'step': 883, 'train_loss': 4.683632850646973},\n",
              " {'step': 884, 'train_loss': 4.83239221572876},\n",
              " {'step': 885, 'train_loss': 4.611653804779053},\n",
              " {'step': 886, 'train_loss': 4.748926162719727},\n",
              " {'step': 887, 'train_loss': 4.631779193878174},\n",
              " {'step': 888, 'train_loss': 4.7331767082214355},\n",
              " {'step': 889, 'train_loss': 4.683620452880859},\n",
              " {'step': 890, 'train_loss': 4.628809452056885},\n",
              " {'step': 891, 'train_loss': 4.662234783172607},\n",
              " {'step': 892, 'train_loss': 4.794139385223389},\n",
              " {'step': 893, 'train_loss': 4.725749969482422},\n",
              " {'step': 894, 'train_loss': 4.857354640960693},\n",
              " {'step': 895, 'train_loss': 4.906673908233643},\n",
              " {'step': 896, 'train_loss': 4.8066277503967285},\n",
              " {'step': 897, 'train_loss': 4.6546478271484375},\n",
              " {'step': 898, 'train_loss': 4.695059299468994},\n",
              " {'step': 899, 'train_loss': 4.781772613525391},\n",
              " {'step': 900, 'train_loss': 4.782492637634277},\n",
              " {'step': 901, 'train_loss': 4.942199230194092},\n",
              " {'step': 902, 'train_loss': 4.577890396118164},\n",
              " {'step': 903, 'train_loss': 4.65969705581665},\n",
              " {'step': 904, 'train_loss': 4.639951229095459},\n",
              " {'step': 905, 'train_loss': 4.599673748016357},\n",
              " {'step': 906, 'train_loss': 4.919940948486328},\n",
              " {'step': 907, 'train_loss': 4.662766933441162},\n",
              " {'step': 908, 'train_loss': 4.5024213790893555},\n",
              " {'step': 909, 'train_loss': 4.936429977416992},\n",
              " {'step': 910, 'train_loss': 4.863910675048828},\n",
              " {'step': 911, 'train_loss': 4.765405654907227},\n",
              " {'step': 912, 'train_loss': 4.769711971282959},\n",
              " {'step': 913, 'train_loss': 4.7402191162109375},\n",
              " {'step': 914, 'train_loss': 4.885500431060791},\n",
              " {'step': 915, 'train_loss': 4.83290958404541},\n",
              " {'step': 916, 'train_loss': 4.578702449798584},\n",
              " {'step': 917, 'train_loss': 4.811155796051025},\n",
              " {'step': 918, 'train_loss': 4.92717170715332},\n",
              " {'step': 919, 'train_loss': 4.836104869842529},\n",
              " {'step': 920, 'train_loss': 4.882083892822266},\n",
              " {'step': 921, 'train_loss': 4.737152099609375},\n",
              " {'step': 922, 'train_loss': 4.804265975952148},\n",
              " {'step': 923, 'train_loss': 4.659135818481445},\n",
              " {'step': 924, 'train_loss': 4.769461631774902},\n",
              " {'step': 925, 'train_loss': 4.786387920379639},\n",
              " {'step': 926, 'train_loss': 4.772644996643066},\n",
              " {'step': 927, 'train_loss': 4.6775288581848145},\n",
              " {'step': 928, 'train_loss': 4.8153862953186035},\n",
              " {'step': 929, 'train_loss': 4.64382266998291},\n",
              " {'step': 930, 'train_loss': 4.867033958435059},\n",
              " {'step': 931, 'train_loss': 4.856082916259766},\n",
              " {'step': 932, 'train_loss': 4.877945423126221},\n",
              " {'step': 933, 'train_loss': 4.686275005340576},\n",
              " {'step': 934, 'train_loss': 4.769906997680664},\n",
              " {'step': 935, 'train_loss': 4.838961601257324},\n",
              " {'step': 936, 'train_loss': 4.671967029571533},\n",
              " {'step': 937, 'train_loss': 4.5379204750061035},\n",
              " {'step': 938, 'train_loss': 4.812243938446045},\n",
              " {'step': 939, 'train_loss': 4.863182067871094},\n",
              " {'step': 940, 'train_loss': 4.71045446395874},\n",
              " {'step': 941, 'train_loss': 4.714067459106445},\n",
              " {'step': 942, 'train_loss': 4.769529819488525},\n",
              " {'step': 943, 'train_loss': 4.824869632720947},\n",
              " {'step': 944, 'train_loss': 4.6067423820495605},\n",
              " {'step': 945, 'train_loss': 4.752866744995117},\n",
              " {'step': 946, 'train_loss': 4.6775288581848145},\n",
              " {'step': 947, 'train_loss': 4.733726978302002},\n",
              " {'step': 948, 'train_loss': 4.620345115661621},\n",
              " {'step': 949, 'train_loss': 4.702925205230713},\n",
              " {'step': 950, 'train_loss': 4.688531398773193},\n",
              " {'step': 951, 'train_loss': 4.633930683135986},\n",
              " {'step': 952, 'train_loss': 4.641327857971191},\n",
              " {'step': 953, 'train_loss': 4.725861549377441},\n",
              " {'step': 954, 'train_loss': 4.649229526519775},\n",
              " {'step': 955, 'train_loss': 4.7611002922058105},\n",
              " {'step': 956, 'train_loss': 4.6958746910095215},\n",
              " {'step': 957, 'train_loss': 4.54047966003418},\n",
              " {'step': 958, 'train_loss': 4.823179244995117},\n",
              " {'step': 959, 'train_loss': 4.859213352203369},\n",
              " {'step': 960, 'train_loss': 4.641848087310791},\n",
              " {'step': 961, 'train_loss': 4.65487003326416},\n",
              " {'step': 962, 'train_loss': 4.868044376373291},\n",
              " {'step': 963, 'train_loss': 4.767735481262207},\n",
              " {'step': 964, 'train_loss': 4.657695293426514},\n",
              " {'step': 965, 'train_loss': 4.81974458694458},\n",
              " {'step': 966, 'train_loss': 4.7981109619140625},\n",
              " {'step': 967, 'train_loss': 4.826697826385498},\n",
              " {'step': 968, 'train_loss': 4.671542644500732},\n",
              " {'step': 969, 'train_loss': 4.758530139923096},\n",
              " {'step': 970, 'train_loss': 4.7321085929870605},\n",
              " {'step': 971, 'train_loss': 4.588334560394287},\n",
              " {'step': 972, 'train_loss': 4.781353950500488},\n",
              " {'step': 973, 'train_loss': 4.770920276641846},\n",
              " {'step': 974, 'train_loss': 4.829546928405762},\n",
              " {'step': 975, 'train_loss': 4.718590259552002},\n",
              " {'step': 976, 'train_loss': 4.746920585632324},\n",
              " {'step': 977, 'train_loss': 4.64173698425293},\n",
              " {'step': 978, 'train_loss': 4.720598220825195},\n",
              " {'step': 979, 'train_loss': 4.6713385581970215},\n",
              " {'step': 980, 'train_loss': 4.585251331329346},\n",
              " {'step': 981, 'train_loss': 4.802215576171875},\n",
              " {'step': 982, 'train_loss': 4.807521820068359},\n",
              " {'step': 983, 'train_loss': 4.853146553039551},\n",
              " {'step': 984, 'train_loss': 4.8594536781311035},\n",
              " {'step': 985, 'train_loss': 4.679919242858887},\n",
              " {'step': 986, 'train_loss': 4.817830562591553},\n",
              " {'step': 987, 'train_loss': 4.744649887084961},\n",
              " {'step': 988, 'train_loss': 4.8365092277526855},\n",
              " {'step': 989, 'train_loss': 4.653956413269043},\n",
              " {'step': 990, 'train_loss': 4.860816478729248},\n",
              " {'step': 991, 'train_loss': 4.7883405685424805},\n",
              " {'step': 992, 'train_loss': 4.785364151000977},\n",
              " {'step': 993, 'train_loss': 4.613116264343262},\n",
              " {'step': 994, 'train_loss': 4.649063587188721},\n",
              " {'step': 995, 'train_loss': 4.818434715270996},\n",
              " {'step': 996, 'train_loss': 4.809483528137207},\n",
              " {'step': 997, 'train_loss': 4.729892730712891},\n",
              " {'step': 998, 'train_loss': 4.631223201751709},\n",
              " {'step': 999, 'train_loss': 4.810287952423096},\n",
              " {'step': 1000,\n",
              "  'train_loss': 4.82926607131958,\n",
              "  'valid_loss': 4.631684786932809},\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgO77jkVjDe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aea12818-1d59-4999-e18b-1b600d180c3c"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss(input, target)\n",
        "print(output)\n",
        "output.backward()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.5508, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}