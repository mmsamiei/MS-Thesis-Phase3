{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled162(5).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3999435efa04adb8b5da5c6163c5577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7aac9c0e8db49b4adca2d4eb060744b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23bfea2555bf49a79462b6d286925cbb",
              "IPY_MODEL_2841a2249f8f4bde90837e509697685b"
            ]
          }
        },
        "b7aac9c0e8db49b4adca2d4eb060744b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23bfea2555bf49a79462b6d286925cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ded062aa0b44bc8b838d06540e83580",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d9e65189d054d3cbfea82198d9fef4d"
          }
        },
        "2841a2249f8f4bde90837e509697685b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1402043cca4249b7b70640b0125407f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.00k/1.00k [00:04&lt;00:00, 205B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd0f4ec917104e778c58d604457e17c3"
          }
        },
        "6ded062aa0b44bc8b838d06540e83580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d9e65189d054d3cbfea82198d9fef4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1402043cca4249b7b70640b0125407f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd0f4ec917104e778c58d604457e17c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29ebac02821540dd80d472cdec415500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d881f4720df24f529a6088800fa7c9ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3648377571dd4cfabf7bb3157c436ae1",
              "IPY_MODEL_ec16333dfedc42278a78b8f138594c7a"
            ]
          }
        },
        "d881f4720df24f529a6088800fa7c9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3648377571dd4cfabf7bb3157c436ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc2ca4522ea74077ad710b49a6d8a134",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3380a8488bf84f1a8d3c04fcc2df753f"
          }
        },
        "ec16333dfedc42278a78b8f138594c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_817134e660d040e4b4b78f9355ed37c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:03&lt;00:00, 271kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01449101d0d34835a15add052fcebc9f"
          }
        },
        "cc2ca4522ea74077ad710b49a6d8a134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3380a8488bf84f1a8d3c04fcc2df753f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "817134e660d040e4b4b78f9355ed37c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01449101d0d34835a15add052fcebc9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efeffb756b774da2ad7d4a4e0b2017d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f13391c21404670aff27d32441cf045",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72e32ab9b64e4c7f8afb037c2c5a5ea0",
              "IPY_MODEL_1e3480b580534cde911ee608a58a5ade"
            ]
          }
        },
        "1f13391c21404670aff27d32441cf045": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72e32ab9b64e4c7f8afb037c2c5a5ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bcf8e7af0d5b4ce981bdbc5e294ea956",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ab716b2cc954cac84970d313f94fdae"
          }
        },
        "1e3480b580534cde911ee608a58a5ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38f6152650794759a01ac518bfe85bdd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 575kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d852ffc495d4f18a76473b9626a72dd"
          }
        },
        "bcf8e7af0d5b4ce981bdbc5e294ea956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ab716b2cc954cac84970d313f94fdae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38f6152650794759a01ac518bfe85bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d852ffc495d4f18a76473b9626a72dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b38a80ac4e144b2855f906cc5c5e748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f09377d93a94072b3032a45ba0ba8b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e22a570549324ed0923286104c7feda8",
              "IPY_MODEL_0452f4e73c71425a9cc7736b76e3d647"
            ]
          }
        },
        "9f09377d93a94072b3032a45ba0ba8b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e22a570549324ed0923286104c7feda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_865d578eee314750904b8625a4b010b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03ae9d09beb54245bb0aadf343315db3"
          }
        },
        "0452f4e73c71425a9cc7736b76e3d647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f475ce47dfe04c3faa9166317ace1c23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00,  6.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0e495bd2d9b45a3b02c8cf2d015897e"
          }
        },
        "865d578eee314750904b8625a4b010b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03ae9d09beb54245bb0aadf343315db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f475ce47dfe04c3faa9166317ace1c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0e495bd2d9b45a3b02c8cf2d015897e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "252c6570292d40c7a4540eb95233393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6c1ca8d7f3349dab0bdfc21697a5887",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47aa084cee1c49369a8ffad0d83f5dfb",
              "IPY_MODEL_2458b166660b4de683d4a70c54fcab26"
            ]
          }
        },
        "a6c1ca8d7f3349dab0bdfc21697a5887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47aa084cee1c49369a8ffad0d83f5dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26aaba6eade74599ac3ec17dd29cf5bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 557941479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 557941479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89aa2f3d0c20446989fe17d94f4a7544"
          }
        },
        "2458b166660b4de683d4a70c54fcab26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f56df0e428f426c9fa6c4e4427d084a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 558M/558M [00:20&lt;00:00, 27.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6066742583f64a069201b3a56efaf51a"
          }
        },
        "26aaba6eade74599ac3ec17dd29cf5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89aa2f3d0c20446989fe17d94f4a7544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f56df0e428f426c9fa6c4e4427d084a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6066742583f64a069201b3a56efaf51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17b041e2e51844bb8c958432723d2462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74664b3e2250444881dbfc3c9578e501",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c581d046a1a944b5a2c47474741dc08f",
              "IPY_MODEL_7bf9bab4be5940eba262c4738be8ae2b"
            ]
          }
        },
        "74664b3e2250444881dbfc3c9578e501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c581d046a1a944b5a2c47474741dc08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21bfa5545c734d059d88c8916cc849ad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d3747668fd14124b5543532e5178127"
          }
        },
        "7bf9bab4be5940eba262c4738be8ae2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53d933f3b9b7451ead62565731c3e98a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [06:09&lt;00:00, 27.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2340ff10c361423f9cafa070046b4226"
          }
        },
        "21bfa5545c734d059d88c8916cc849ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d3747668fd14124b5543532e5178127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53d933f3b9b7451ead62565731c3e98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2340ff10c361423f9cafa070046b4226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba8df617f2654ce9976219d0cdac6eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e2e42a67e8e24cf6907ea34d977dc71c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_827d1ecca1954065856d5a9a1dfe8d23",
              "IPY_MODEL_320c3c57a0b94b62ba7462fa74305c4c"
            ]
          }
        },
        "e2e42a67e8e24cf6907ea34d977dc71c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "827d1ecca1954065856d5a9a1dfe8d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b0b2d44ee4341cc84a070f3c8351222",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 41489,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 41489,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87c53e0b282a49cd845998e838a2b1ff"
          }
        },
        "320c3c57a0b94b62ba7462fa74305c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45c4727679234070b22009aa6d13633a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 41489/41489 [00:39&lt;00:00, 1050.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2c86ed82a19480ebbde51bae5433f0a"
          }
        },
        "2b0b2d44ee4341cc84a070f3c8351222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87c53e0b282a49cd845998e838a2b1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45c4727679234070b22009aa6d13633a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2c86ed82a19480ebbde51bae5433f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7568d0e21df94b54886b1c85654b9e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42f4cb0557ab411db021ed4226091084",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_696f13f7b4554aa596df13d7e19b10ad",
              "IPY_MODEL_8fd7c354b0e3413581bac06e5b48174d"
            ]
          }
        },
        "42f4cb0557ab411db021ed4226091084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "696f13f7b4554aa596df13d7e19b10ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b750c706eef4d3c9b96bf68d4d10d51",
            "_dom_classes": [],
            "description": "  4%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2594,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 91,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be446e5090334851b2f581a791b3ab9f"
          }
        },
        "8fd7c354b0e3413581bac06e5b48174d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e14181b087445be8c2f26b554d5040d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 91/2594 [00:58&lt;28:23,  1.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff25164be0c143de93f2c955515ada18"
          }
        },
        "0b750c706eef4d3c9b96bf68d4d10d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be446e5090334851b2f581a791b3ab9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e14181b087445be8c2f26b554d5040d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff25164be0c143de93f2c955515ada18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c11876985e84675a7ab4289d8e6c5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4527a396b8164d90bea5f3837000bd25",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_537774ccc16942bd8a30542e89bf7be4",
              "IPY_MODEL_b49647e6b27b4a15bb8f24ee94b86f48"
            ]
          }
        },
        "4527a396b8164d90bea5f3837000bd25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "537774ccc16942bd8a30542e89bf7be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a999c93a12fc4bc7a67737abc162a3ae",
            "_dom_classes": [],
            "description": " 16%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2075,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 328,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86c4fb7e79b347c59adf536a5a36504f"
          }
        },
        "b49647e6b27b4a15bb8f24ee94b86f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eaef0bc70e034fb5b33debadba8fd422",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 328/2075 [04:52&lt;25:42,  1.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a63df29bb1a949d6a87d1c17d7130eee"
          }
        },
        "a999c93a12fc4bc7a67737abc162a3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86c4fb7e79b347c59adf536a5a36504f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaef0bc70e034fb5b33debadba8fd422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a63df29bb1a949d6a87d1c17d7130eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/MS-Thesis-Phase3/blob/master/Models/Beheshti/Beheshti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkQPQqY6s8-v",
        "colab_type": "text"
      },
      "source": [
        "#In the name of God"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SudnGM-6qcaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8c127fc-afb4-434b-8e32-6079f54164f7"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        "  function ClickConnect(){\n",
        "    console.log(\"Working\"); \n",
        "    document.querySelector(\"colab-connect-button\").click() \n",
        "  }\n",
        "  var connect_timer = setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  function ClickConnect(){\n",
              "    console.log(\"Working\"); \n",
              "    document.querySelector(\"colab-connect-button\").click() \n",
              "  }\n",
              "  var connect_timer = setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTGb1dOrs48Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "63ecd15d-1a5a-4450-be30-5cff8a1e1440"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 20 14:07:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyf240b5tD82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "d8956889-54de-4d9c-ee69-d4f9e8da82d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcbfW-tZtpLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "6cd2724d-3c88-4272-a4ce-b6813f24f411"
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 2.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 14.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 18.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 24.3MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eweO40_dtxZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from transformers import AutoTokenizer\n",
        "import random\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X2E9kZ5tJRA",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eddoohNmtKug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = '/content/drive/My Drive/Thesis/phase-3/hkr_train.csv'\n",
        "valid_file =  '/content/drive/My Drive/Thesis/phase-3/hkr_valid.csv'\n",
        "test_seen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_seen.csv'\n",
        "test_unseen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_unseen.csv'\n",
        "last_sentence_file = '/content/drive/My Drive/Thesis/phase-3/last_sentence.csv'\n",
        "squad_file = '/content/drive/My Drive/Thesis/phase-3/squad.csv'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCX3Tv8tqPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "f3999435efa04adb8b5da5c6163c5577",
            "b7aac9c0e8db49b4adca2d4eb060744b",
            "23bfea2555bf49a79462b6d286925cbb",
            "2841a2249f8f4bde90837e509697685b",
            "6ded062aa0b44bc8b838d06540e83580",
            "8d9e65189d054d3cbfea82198d9fef4d",
            "1402043cca4249b7b70640b0125407f5",
            "cd0f4ec917104e778c58d604457e17c3",
            "29ebac02821540dd80d472cdec415500",
            "d881f4720df24f529a6088800fa7c9ab",
            "3648377571dd4cfabf7bb3157c436ae1",
            "ec16333dfedc42278a78b8f138594c7a",
            "cc2ca4522ea74077ad710b49a6d8a134",
            "3380a8488bf84f1a8d3c04fcc2df753f",
            "817134e660d040e4b4b78f9355ed37c5",
            "01449101d0d34835a15add052fcebc9f",
            "efeffb756b774da2ad7d4a4e0b2017d2",
            "1f13391c21404670aff27d32441cf045",
            "72e32ab9b64e4c7f8afb037c2c5a5ea0",
            "1e3480b580534cde911ee608a58a5ade",
            "bcf8e7af0d5b4ce981bdbc5e294ea956",
            "7ab716b2cc954cac84970d313f94fdae",
            "38f6152650794759a01ac518bfe85bdd",
            "3d852ffc495d4f18a76473b9626a72dd"
          ]
        },
        "outputId": "0591ceab-1efc-43ad-a2fd-386397d28d23"
      },
      "source": [
        "enc_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n",
        "dec_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3999435efa04adb8b5da5c6163c5577",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1001.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29ebac02821540dd80d472cdec415500",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efeffb756b774da2ad7d4a4e0b2017d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu21rVUPuIvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"My dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, frac=1, split_rate=1, max_len=512, sort=True, bound=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "        \"\"\"\n",
        "        self.dialogues = pd.read_csv(csv_file)\n",
        "        #self.dialogues.dropna(inplace=True)\n",
        "        \n",
        "        self.dialogues.fillna(\"\", inplace=True)\n",
        "        self.dialogues = self.dialogues[self.dialogues.index % split_rate == 0]\n",
        "\n",
        "        self.dialogues = self.dialogues.sample(frac=frac)\n",
        "\n",
        "        self.dialogues.history = self.dialogues.history.str.replace(\n",
        "            \"[SEP]\", \"</s>\", n=-1, regex=False) ### SPECIAL CHARACHTER FOR TURN\n",
        "        \n",
        "        if bound:\n",
        "          len_prt = int(len(self.dialogues) / 5)\n",
        "          self.dialogues = self.dialogues[ : len_prt]\n",
        "\n",
        "        s = self.dialogues['response'].apply(dec_tokenizer.encode).apply(len).sort_values().index\n",
        "        self.dialogues = self.dialogues.reindex(s)\n",
        "\n",
        "        \n",
        "\n",
        "        #self.dialogues.dropna(inplace=True)\n",
        "\n",
        "        self.max_len = max_len\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    @staticmethod\n",
        "    def truncuate_join_pair_sentence(sentence1, sentence2, max_len=510):\n",
        "\n",
        "        \"\"\"\n",
        "        truncuate sentence one from head and sentence two from tail\n",
        "        Args:\n",
        "            sentence1 (string): first sentence\n",
        "            sentence2 (string): seconde sentence\n",
        "        \"\"\"\n",
        "        temp1 = enc_tokenizer.encode(sentence1,add_special_tokens=False)\n",
        "        temp2 = enc_tokenizer.encode(sentence2,add_special_tokens=False)\n",
        "        ### two above line may cause warning but no problem because we've handle them below\n",
        "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "        seq_1 = temp1\n",
        "        seq_2 = temp2\n",
        "        num_tokens_to_remove = len(temp1) + len(temp2) + 3 - max_len\n",
        "        if num_tokens_to_remove > 0 :\n",
        "            seq_1, seq_2, _ = enc_tokenizer.truncate_sequences(temp1[::-1],temp2, num_tokens_to_remove=num_tokens_to_remove,\n",
        "                                                               truncation_strategy='longest_first')\n",
        "            seq_1.reverse()\n",
        "        result_list = [enc_tokenizer.cls_token_id]+seq_1+[enc_tokenizer.sep_token_id]+seq_2+[enc_tokenizer.sep_token_id]\n",
        "        token_type_ids = [0] * (len(seq_1) + 2) + [1] * (len(seq_2) + 1)\n",
        "\n",
        "        if(len(result_list)>1000):\n",
        "          print(len(result_list))\n",
        "\n",
        "        return result_list, token_type_ids\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        \n",
        "        history = self.dialogues.iloc[idx].history\n",
        "        knowledge = self.dialogues.iloc[idx].knowledge\n",
        "        response = self.dialogues.iloc[idx].response\n",
        "\n",
        "\n",
        "        input_pair, input_pair_segments = MyDataset.truncuate_join_pair_sentence(history, knowledge, self.max_len)\n",
        "                \n",
        "\n",
        "        input_pair = torch.LongTensor(input_pair)\n",
        "\n",
        "        input_pair_segments = torch.LongTensor(input_pair_segments)\n",
        "\n",
        "        response_tensor = torch.LongTensor(dec_tokenizer.encode(response, truncation=True, max_length=128))\n",
        "\n",
        "        sample = {'input_pair': input_pair,\n",
        "                  'input_pair_segments': input_pair_segments,\n",
        "                  'response': response_tensor}\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0jkglqFwFQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c434a698-539e-4757-9c98-6bca4bae015f"
      },
      "source": [
        "train_dataset = MyDataset(train_file, max_len=128, bound=False)\n",
        "valid_dataset = MyDataset(valid_file, max_len=128)\n",
        "test_unseen_dataset = MyDataset(test_unseen_file, max_len=128)\n",
        "test_seen_dataset = MyDataset(test_seen_file, max_len=128)\n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))\n",
        "print(len(test_unseen_dataset))\n",
        "print(len(test_seen_dataset))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "41489\n",
            "4458\n",
            "2075\n",
            "2224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VasXIkuLwHnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9e0ac634-c3b9-47fb-8357-11ffed8dbcf9"
      },
      "source": [
        "print(enc_tokenizer.decode(train_dataset[500]['input_pair']))\n",
        "print(dec_tokenizer.decode(train_dataset[500]['response']))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s>Starbucks</s>Starbucks Corporation is an American coffee company and coffeehouse chain.</s>\n",
            "<s>I really like coffee especially Starbucks.</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Z5ZeAT2oii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "1b38a80ac4e144b2855f906cc5c5e748",
            "9f09377d93a94072b3032a45ba0ba8b0",
            "e22a570549324ed0923286104c7feda8",
            "0452f4e73c71425a9cc7736b76e3d647",
            "865d578eee314750904b8625a4b010b7",
            "03ae9d09beb54245bb0aadf343315db3",
            "f475ce47dfe04c3faa9166317ace1c23",
            "d0e495bd2d9b45a3b02c8cf2d015897e"
          ]
        },
        "outputId": "7caa02e4-2d6a-4d11-97dc-556806619451"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "\n",
        "  len_batch = len(batch)\n",
        "\n",
        "  \n",
        "  max_len_input_pair = max([len(data['input_pair']) for data in batch])\n",
        "\n",
        "  max_len_response = max([len(data['response']) for data in batch])\n",
        "  \n",
        "  padding_ind = 0 ## for bert is 0 DON'T THINK BAD IT IS NOT REFACTORING !!!!!!\n",
        "  result_input_pair = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_input_pair_segments = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_response = torch.zeros(len_batch, max_len_response)\n",
        "\n",
        "  for i, data in enumerate(batch):\n",
        "    p1 = len(data['input_pair'])\n",
        "    result_input_pair[i, :p1] = data['input_pair']\n",
        "\n",
        "    p3 = len(data['input_pair_segments'])\n",
        "    result_input_pair_segments[i, :p3] = data['input_pair_segments']\n",
        "\n",
        "    p4 = len(data['response'])\n",
        "    result_response[i, :p4] = data['response']\n",
        "\n",
        "  return result_input_pair.long(), result_input_pair_segments.long(), result_response.long()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16,\n",
        "                                             shuffle=True, collate_fn=my_collate_fn,\n",
        "                                           num_workers=1)\n",
        "\n",
        "#valid_sampler = torch.utils.data.SequentialSampler(valid_dataset)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn, num_workers=1)\n",
        "\n",
        "i = 0 \n",
        "for batch_idx, batch  in tqdm(enumerate(train_loader)):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  print(pair_batch.shape)\n",
        "  print(segment_batch.shape)\n",
        "  print(response_batch.shape)\n",
        "  print(\"****\")\n",
        "  i += 1 \n",
        "  if(i==2):\n",
        "    break\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(valid_loader))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b38a80ac4e144b2855f906cc5c5e748",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 45])\n",
            "****\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 48])\n",
            "****\n",
            "2594\n",
            "279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXB7YVVgDyPU",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfGvoJMiEicR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizer\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    # self.seq2seq = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    #     'google/bert_uncased_L-2_H-128_A-2', 'google/bert_uncased_L-6_H-128_A-2')\n",
        "    \n",
        "    # for p in self.seq2seq.encoder.embeddings.parameters():\n",
        "    #    p.requires_grad = False\n",
        "    \n",
        "    # for p in self.seq2seq.decoder.bert.embeddings.parameters():\n",
        "    #    p.requires_grad = False\n",
        "\n",
        "    self.seq2seq = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "\n",
        "  def forward(self, encoder_input, segments_tensors, decoder_input, **kwargs):\n",
        "    '''\n",
        "    encoder_input = [batch_size, enc_len]\n",
        "    segments_tensors = [batch_size, enc_len]\n",
        "    decoder_input = [batch_size, dec_len]\n",
        "    '''\n",
        "    #kwargs = {'token_type_ids':segments_tensors}\n",
        "    #kwargs = {}\n",
        "    outputs = self.seq2seq(input_ids=encoder_input,\n",
        "                           decoder_input_ids=decoder_input,\n",
        "                           use_cache=False, **kwargs)[0]\n",
        "    return outputs\n",
        "  \n",
        "  def generate(self, encoder_input, segments_tensors, **kwargs):\n",
        "    ### encoder_input = [len] in int format\n",
        "    ### segment_tensors = [len]\n",
        "    encoder_input = encoder_input.unsqueeze(0)\n",
        "    segments_tensors = segments_tensors.unsqueeze(0)\n",
        "    \n",
        "    model_specific_kwargs = {}\n",
        "    #model_specific_kwargs['token_type_ids'] = {'token_type_ids':segments_tensors}\n",
        "\n",
        "    generated = model.seq2seq.generate(encoder_input, decoder_start_token_id=0,\n",
        "                                       eos_token_id=2, ## <s> = 0 </s> = 2\n",
        "                                       **kwargs, **model_specific_kwargs)\n",
        "\n",
        "    #### generated = [1, len]\n",
        "    return generated"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxsRPOHFGrBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "252c6570292d40c7a4540eb95233393e",
            "a6c1ca8d7f3349dab0bdfc21697a5887",
            "47aa084cee1c49369a8ffad0d83f5dfb",
            "2458b166660b4de683d4a70c54fcab26",
            "26aaba6eade74599ac3ec17dd29cf5bc",
            "89aa2f3d0c20446989fe17d94f4a7544",
            "0f56df0e428f426c9fa6c4e4427d084a",
            "6066742583f64a069201b3a56efaf51a"
          ]
        },
        "outputId": "6cb24db6-3c97-4e33-c432-4f96f48c4604"
      },
      "source": [
        "dev = torch.device('cuda')\n",
        "model = Model().to(dev)\n",
        "\n",
        "# x = torch.LongTensor(8, 40).random_(1,1000).to(dev)\n",
        "# y = torch.LongTensor(8, 10).random_(1,1000).to(dev)\n",
        "# print(model(x,x,y).shape)\n",
        "\n",
        "\n",
        "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(count_parameters(model))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "252c6570292d40c7a4540eb95233393e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557941479.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "139420416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb5uvuCKL0cj",
        "colab_type": "text"
      },
      "source": [
        "#Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxB7zLBDZQXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "decoder_optimizer = torch.optim.Adam(model.seq2seq.model.decoder.parameters(), lr=3e-5)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJplUNA2A-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_cosine_schedule_with_warmup, get_constant_schedule\n",
        "scheduler = get_constant_schedule(optimizer)\n",
        "decoder_scheduler = get_constant_schedule(decoder_optimizer)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ofqAPp12OnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "17b041e2e51844bb8c958432723d2462",
            "74664b3e2250444881dbfc3c9578e501",
            "c581d046a1a944b5a2c47474741dc08f",
            "7bf9bab4be5940eba262c4738be8ae2b",
            "21bfa5545c734d059d88c8916cc849ad",
            "5d3747668fd14124b5543532e5178127",
            "53d933f3b9b7451ead62565731c3e98a",
            "2340ff10c361423f9cafa070046b4226"
          ]
        },
        "outputId": "fcaa773d-b5d5-45ea-997b-b54a1ee95292"
      },
      "source": [
        "lrs = []\n",
        "for i in tqdm(range(10000)):\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "  lrs.append(scheduler.get_last_lr()[0])\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lrs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17b041e2e51844bb8c958432723d2462",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3ea2eb6400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufFe-Q62ZaFW",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfNUyJV1DfaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "ba8df617f2654ce9976219d0cdac6eb0",
            "e2e42a67e8e24cf6907ea34d977dc71c",
            "827d1ecca1954065856d5a9a1dfe8d23",
            "320c3c57a0b94b62ba7462fa74305c4c",
            "2b0b2d44ee4341cc84a070f3c8351222",
            "87c53e0b282a49cd845998e838a2b1ff",
            "45c4727679234070b22009aa6d13633a",
            "e2c86ed82a19480ebbde51bae5433f0a"
          ]
        },
        "outputId": "ac37e047-f7d6-41b1-b75e-bcb1e9b643f3"
      },
      "source": [
        "df = pd.read_csv(train_file)\n",
        "freqs = [1] * dec_tokenizer.vocab_size\n",
        "for response in tqdm(df['response']):\n",
        "  tknzd = dec_tokenizer.encode(response)\n",
        "  for tkn in tknzd:\n",
        "    freqs[tkn] += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba8df617f2654ce9976219d0cdac6eb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=41489.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_YgBP3AFXF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weights(_lambda = 0):\n",
        "  weights = torch.ones(dec_tokenizer.vocab_size)\n",
        "  # for idx, freq in enumerate(freqs):\n",
        "  #   weight = 1 / (freq**_lambda)\n",
        "  #   weights[idx] = weight\n",
        "  return weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-t7PADEZcZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn\n",
        "\n",
        "weight = get_weights().to(dev)\n",
        "\n",
        "def mahdi_loss(model_output, true_trg, **kwargs):\n",
        "  '''\n",
        "  model_output: [batch, len, hidden]\n",
        "  true_trg: [batch, len]\n",
        "  '''\n",
        "  model_output = model_output[:,:-1,:]\n",
        "  true_trg = true_trg[:,1:]\n",
        "\n",
        "  batch_len = model_output.shape[0]\n",
        "  snt_len = model_output.shape[1]\n",
        "  hidden_size = model_output.shape[2]\n",
        "\n",
        "  model_output = model_output.reshape(-1, hidden_size)\n",
        "  true_trg = true_trg.reshape(-1)\n",
        "\n",
        "  loss_mod = nn.CrossEntropyLoss(weight=weight, ignore_index=0)## PAD = 0\n",
        "  loss = loss_mod(model_output, true_trg)\n",
        "\n",
        "\n",
        "\n",
        "  #z = torch.LongTensor(model_output[true_trg!=1045].shape[0]).fill_(1045).to(dev)\n",
        "  #neg_loss = -0.5*F.nll_loss(nn.functional.log_softmax(model_output[true_trg!=1045]), z, reduction='mean')\n",
        "\n",
        "  return loss "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmuTGJMJbR9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "accumulation_steps = 4\n",
        "\n",
        "def train_step(batch_idx, batch, step):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  pair_batch = pair_batch.to(dev)\n",
        "  segment_batch = segment_batch.to(dev)\n",
        "  response_batch = response_batch.to(dev)\n",
        "  model_output = model(pair_batch, segment_batch, response_batch)\n",
        "  loss = mahdi_loss(model_output, response_batch)\n",
        "  loss = loss / accumulation_steps\n",
        "  loss.backward()\n",
        "  if (step+1) % accumulation_steps == 0:\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  del pair_batch\n",
        "  del segment_batch\n",
        "  del response_batch\n",
        "  return loss.item()\n",
        "\n",
        "\n",
        "### UNDER CONSTRUCT\n",
        "def train_decoder_step(batch_idx, batch):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  batch_size = pair_batch.shape[0]\n",
        "  response_batch = response_batch.to(dev)\n",
        "  encoder_outputs = torch.Tensor(batch_size,20,768).fill_(0).to(dev)\n",
        "  kwargs = {'encoder_outputs' : (encoder_outputs, None, None)}\n",
        "  model_output = model(None, None, response_batch, **kwargs)\n",
        "  loss = mahdi_loss(model_output, response_batch)\n",
        "  decoder_optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  torch.nn.utils.clip_grad_norm_(model.seq2seq.model.decoder.parameters(), 2)\n",
        "  decoder_optimizer.step()\n",
        "  decoder_scheduler.step()\n",
        "  del pair_batch\n",
        "  del segment_batch\n",
        "  del response_batch\n",
        "  return loss.item()\n",
        "\n",
        "def valid_step(batch_idx, batch):\n",
        "  with torch.no_grad():\n",
        "    pair_batch, segment_batch, response_batch = batch\n",
        "    pair_batch = pair_batch.to(dev)\n",
        "    segment_batch = segment_batch.to(dev)\n",
        "    response_batch = response_batch.to(dev)\n",
        "    model_output = model(pair_batch, segment_batch, response_batch)\n",
        "    loss = mahdi_loss(model_output, response_batch)\n",
        "    del pair_batch\n",
        "    del segment_batch\n",
        "    del response_batch\n",
        "    return loss.item()\n",
        "\n",
        "def valid_loop(valid_loader):\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "  for batch_idx, batch in tqdm(enumerate(valid_loader),  total=len(valid_loader), leave=False):\n",
        "    total_loss += valid_step(batch_idx, batch)\n",
        "  \n",
        "  print(\"temperature is 1:\")\n",
        "  kwargs = {'num_beams':8,'num_return_sequences':8,'temperature':1,\n",
        "            'no_repeat_ngram_size':3}\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  print(\"most greedy sentence:\")\n",
        "  kwargs = {\n",
        "          'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3,\n",
        "          'top-k':1\n",
        "          }\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  # print(\"temperature is 2:\")\n",
        "  # kwargs = {'num_beams':16,'num_return_sequences':16,'temperature':2}\n",
        "  # valid_inference(**kwargs)\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  return total_loss / len(valid_loader)\n",
        "\n",
        "def valid_inference(idx=600, **kwargs):\n",
        "  hk_pair =  train_dataset[idx]['input_pair'].to(dev)\n",
        "  hk_segment = train_dataset[idx]['input_pair_segments'].to(dev)\n",
        "  response = train_dataset[idx]['response'].to(dev)\n",
        "  generateds = model.generate(hk_pair, hk_segment, **kwargs)\n",
        "  print(\"pair is: \",enc_tokenizer.decode(hk_pair))\n",
        "  print(\"response is: \",dec_tokenizer.decode(response))\n",
        "  for generated in generateds:\n",
        "    print(\"model says: \",dec_tokenizer.decode(generated))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pxjS0PQfKU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_learning = True\n",
        "if new_learning:\n",
        "  # optimizer = NoamOpt(128, 1, 2000,\n",
        "  #           torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "  model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Beheshti\"\n",
        "  step = 0\n",
        "  log_list = []"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZD1hD7rfNFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b619ef5b-b500-4a2a-e393-fb7c19e4531c"
      },
      "source": [
        "## if continue learning:\n",
        "#!wget -q https://github.com/mmsamiei/MS-Thesis-Phase2/raw/master/Models/hashemi_16000steps.model\n",
        "model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Montazeri\"\n",
        "checkpoint = torch.load(model_dir+'/montazeri_15000steps.model')\n",
        "step = checkpoint['log_list'][-1]['step']\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "optimizer._step = step\n",
        "log_list = checkpoint['log_list']\n",
        "new_learning = False\n",
        "print(step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHv6tC4YfZI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "7568d0e21df94b54886b1c85654b9e17",
            "42f4cb0557ab411db021ed4226091084",
            "696f13f7b4554aa596df13d7e19b10ad",
            "8fd7c354b0e3413581bac06e5b48174d",
            "0b750c706eef4d3c9b96bf68d4d10d51",
            "be446e5090334851b2f581a791b3ab9f",
            "2e14181b087445be8c2f26b554d5040d",
            "ff25164be0c143de93f2c955515ada18"
          ]
        },
        "outputId": "6a637520-92a1-4616-dc79-510fa01ae54d"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "MAX_STEP = 80000\n",
        "STEP_SAVE = 2000\n",
        "STEP_CHECK = 8000\n",
        "step_num = step + 1\n",
        "log_list = log_list ### Check if new learning or not\n",
        "print(step_num)\n",
        "while step_num <= MAX_STEP:\n",
        "  model.train()\n",
        "  for batch_idx, batch in tqdm(enumerate(iter(train_loader)), total=len(train_loader), leave=False):\n",
        "    step_loss = train_step(batch_idx, batch, step_num)\n",
        "    #decoder_step_loss = train_decoder_step(batch_idx, batch)\n",
        "    #log = {'step':step_num, 'train_loss':step_loss, 'decoder_loss':decoder_step_loss}\n",
        "    log = {'step':step_num, 'train_loss':step_loss}\n",
        "\n",
        "    if(step_num % STEP_CHECK == 0):\n",
        "      valid_error = valid_loop(valid_loader)\n",
        "      train_losses = [step['train_loss'] for step in log_list[-100:]]\n",
        "      #decoder_train_losses = [step['decoder_loss'] for step in log_list[-100:]]\n",
        "      avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "      #avg_decoder_train_loss = sum(decoder_train_losses) / len(decoder_train_losses)\n",
        "      print(\"train Loss rate: {} at step {}\".format(avg_train_loss, step_num))  \n",
        "      #print(\"decoder train Loss rate: {} at step {}\".format(avg_decoder_train_loss, step_num))\n",
        "      print(\"valid Loss rate: {} at step {}\".format(valid_error, step_num))  \n",
        "      log['valid_loss'] = valid_error\n",
        "\n",
        "    log_list.append(log)\n",
        "\n",
        "    if(step_num % STEP_SAVE == 0):\n",
        "      torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'log_list': log_list,\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, model_dir+'beheshti_{}steps.model'.format(step_num))\n",
        "    step_num += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7568d0e21df94b54886b1c85654b9e17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2594.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow4c6BCePKec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3e5f2813-df9c-4b96-8bd7-9e7ca180627d"
      },
      "source": [
        "kwargs = {'num_beams':4,\n",
        "          'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3,\n",
        "          #'top-k':1\n",
        "          }\n",
        "valid_inference(idx=1200, **kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pair is:  <s>Algeria</s>Algeria ( '; '; ), officially the People's Democratic Republic of Algeria, is a sovereign state in North Africa on the Mediterranean coast.</s>\n",
            "response is:  <s>You ever been to the sovereign state in North Africa on the Mediterreanean? That's where I am from. Algeria </s>\n",
            "model says:  <s><s> country in North Africa on the Mediterranean coast.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlWb7ZY5ClYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d015384e-3d39-4d88-94a2-eaa4b2396084"
      },
      "source": [
        "input_tns = dec_tokenizer.encode(\"who is danial wife?</s> Danial is a student who is studying at ml lab \", return_tensors='pt').squeeze(0).to(dev)\n",
        "kwargs = {'num_beams':8,\n",
        "          'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3,\n",
        "          #'top-k':1\n",
        "          }\n",
        "dec_tokenizer.decode(model.generate(input_tns, input_tns, **kwargs).squeeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'<s><s> is a student who is studying at ml lab'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001YzGTpEiV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49f05560-704e-4348-fc46-7c58e63b55b5"
      },
      "source": [
        "log_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'decoder_loss': 6.256505012512207,\n",
              "  'step': 1,\n",
              "  'train_loss': 5.436079502105713},\n",
              " {'decoder_loss': 5.6536478996276855,\n",
              "  'step': 2,\n",
              "  'train_loss': 4.637739181518555},\n",
              " {'decoder_loss': 5.428417205810547,\n",
              "  'step': 3,\n",
              "  'train_loss': 4.3970818519592285},\n",
              " {'decoder_loss': 5.562341213226318,\n",
              "  'step': 4,\n",
              "  'train_loss': 4.593493461608887},\n",
              " {'decoder_loss': 4.967794418334961,\n",
              "  'step': 5,\n",
              "  'train_loss': 4.253992557525635},\n",
              " {'decoder_loss': 4.760581016540527,\n",
              "  'step': 6,\n",
              "  'train_loss': 3.9162845611572266},\n",
              " {'decoder_loss': 4.915162086486816,\n",
              "  'step': 7,\n",
              "  'train_loss': 4.2906904220581055},\n",
              " {'decoder_loss': 4.85003662109375,\n",
              "  'step': 8,\n",
              "  'train_loss': 3.936544895172119},\n",
              " {'decoder_loss': 4.46215295791626,\n",
              "  'step': 9,\n",
              "  'train_loss': 3.941171884536743},\n",
              " {'decoder_loss': 4.828457355499268,\n",
              "  'step': 10,\n",
              "  'train_loss': 3.760065793991089},\n",
              " {'decoder_loss': 4.553035259246826,\n",
              "  'step': 11,\n",
              "  'train_loss': 3.9074344635009766},\n",
              " {'decoder_loss': 4.83854866027832,\n",
              "  'step': 12,\n",
              "  'train_loss': 3.7646703720092773},\n",
              " {'decoder_loss': 4.949313163757324,\n",
              "  'step': 13,\n",
              "  'train_loss': 4.12359094619751},\n",
              " {'decoder_loss': 4.510192394256592,\n",
              "  'step': 14,\n",
              "  'train_loss': 3.9105560779571533},\n",
              " {'decoder_loss': 4.795533657073975,\n",
              "  'step': 15,\n",
              "  'train_loss': 3.872370958328247},\n",
              " {'decoder_loss': 4.961838245391846,\n",
              "  'step': 16,\n",
              "  'train_loss': 4.056728363037109},\n",
              " {'decoder_loss': 4.770679473876953,\n",
              "  'step': 17,\n",
              "  'train_loss': 3.9887993335723877},\n",
              " {'decoder_loss': 4.782637119293213,\n",
              "  'step': 18,\n",
              "  'train_loss': 3.658003807067871},\n",
              " {'decoder_loss': 4.740941047668457,\n",
              "  'step': 19,\n",
              "  'train_loss': 3.8406238555908203},\n",
              " {'decoder_loss': 4.522959232330322,\n",
              "  'step': 20,\n",
              "  'train_loss': 3.7337567806243896},\n",
              " {'decoder_loss': 4.672895431518555,\n",
              "  'step': 21,\n",
              "  'train_loss': 3.6409223079681396},\n",
              " {'decoder_loss': 4.3611345291137695,\n",
              "  'step': 22,\n",
              "  'train_loss': 3.760563611984253},\n",
              " {'decoder_loss': 4.750197887420654,\n",
              "  'step': 23,\n",
              "  'train_loss': 3.666283130645752},\n",
              " {'decoder_loss': 4.776888370513916,\n",
              "  'step': 24,\n",
              "  'train_loss': 4.028707504272461},\n",
              " {'decoder_loss': 4.552083492279053,\n",
              "  'step': 25,\n",
              "  'train_loss': 3.6120870113372803},\n",
              " {'decoder_loss': 4.340111255645752,\n",
              "  'step': 26,\n",
              "  'train_loss': 3.8385732173919678},\n",
              " {'decoder_loss': 4.795973777770996,\n",
              "  'step': 27,\n",
              "  'train_loss': 4.2256879806518555},\n",
              " {'decoder_loss': 4.371953010559082,\n",
              "  'step': 28,\n",
              "  'train_loss': 3.878095865249634},\n",
              " {'decoder_loss': 4.398616313934326,\n",
              "  'step': 29,\n",
              "  'train_loss': 3.7375247478485107},\n",
              " {'decoder_loss': 4.689492702484131,\n",
              "  'step': 30,\n",
              "  'train_loss': 3.7792258262634277},\n",
              " {'decoder_loss': 4.481766700744629,\n",
              "  'step': 31,\n",
              "  'train_loss': 3.0930652618408203},\n",
              " {'decoder_loss': 4.8938307762146,\n",
              "  'step': 32,\n",
              "  'train_loss': 3.902588129043579},\n",
              " {'decoder_loss': 4.297797679901123,\n",
              "  'step': 33,\n",
              "  'train_loss': 3.3589653968811035},\n",
              " {'decoder_loss': 4.298104286193848,\n",
              "  'step': 34,\n",
              "  'train_loss': 3.680004596710205},\n",
              " {'decoder_loss': 4.596022605895996,\n",
              "  'step': 35,\n",
              "  'train_loss': 3.66481614112854},\n",
              " {'decoder_loss': 4.537723064422607,\n",
              "  'step': 36,\n",
              "  'train_loss': 3.5803613662719727},\n",
              " {'decoder_loss': 4.322371959686279,\n",
              "  'step': 37,\n",
              "  'train_loss': 3.2892205715179443},\n",
              " {'decoder_loss': 4.424259185791016,\n",
              "  'step': 38,\n",
              "  'train_loss': 3.3663668632507324},\n",
              " {'decoder_loss': 4.0156450271606445,\n",
              "  'step': 39,\n",
              "  'train_loss': 3.2779910564422607},\n",
              " {'decoder_loss': 4.3781633377075195,\n",
              "  'step': 40,\n",
              "  'train_loss': 3.4935309886932373},\n",
              " {'decoder_loss': 4.383758544921875,\n",
              "  'step': 41,\n",
              "  'train_loss': 3.3254172801971436},\n",
              " {'decoder_loss': 4.3319993019104,\n",
              "  'step': 42,\n",
              "  'train_loss': 3.2712981700897217},\n",
              " {'decoder_loss': 4.352022171020508,\n",
              "  'step': 43,\n",
              "  'train_loss': 3.2608354091644287},\n",
              " {'decoder_loss': 4.366360187530518,\n",
              "  'step': 44,\n",
              "  'train_loss': 3.6333067417144775},\n",
              " {'decoder_loss': 4.664966106414795,\n",
              "  'step': 45,\n",
              "  'train_loss': 4.0607709884643555},\n",
              " {'decoder_loss': 4.496405124664307,\n",
              "  'step': 46,\n",
              "  'train_loss': 3.7239935398101807},\n",
              " {'decoder_loss': 4.474130153656006,\n",
              "  'step': 47,\n",
              "  'train_loss': 3.3638622760772705},\n",
              " {'decoder_loss': 4.146924018859863,\n",
              "  'step': 48,\n",
              "  'train_loss': 3.6384470462799072},\n",
              " {'decoder_loss': 4.309504508972168,\n",
              "  'step': 49,\n",
              "  'train_loss': 3.1701114177703857},\n",
              " {'decoder_loss': 4.340481281280518,\n",
              "  'step': 50,\n",
              "  'train_loss': 3.186394453048706},\n",
              " {'decoder_loss': 4.342617511749268,\n",
              "  'step': 51,\n",
              "  'train_loss': 3.456035614013672},\n",
              " {'decoder_loss': 4.650259494781494,\n",
              "  'step': 52,\n",
              "  'train_loss': 3.290187120437622},\n",
              " {'decoder_loss': 3.965803623199463,\n",
              "  'step': 53,\n",
              "  'train_loss': 2.9073288440704346},\n",
              " {'decoder_loss': 4.026138782501221,\n",
              "  'step': 54,\n",
              "  'train_loss': 3.280022382736206},\n",
              " {'decoder_loss': 3.961334228515625,\n",
              "  'step': 55,\n",
              "  'train_loss': 3.219662666320801},\n",
              " {'decoder_loss': 4.422320365905762,\n",
              "  'step': 56,\n",
              "  'train_loss': 3.206134080886841},\n",
              " {'decoder_loss': 4.044920921325684,\n",
              "  'step': 57,\n",
              "  'train_loss': 3.416404962539673},\n",
              " {'decoder_loss': 4.276465892791748,\n",
              "  'step': 58,\n",
              "  'train_loss': 3.593662977218628},\n",
              " {'decoder_loss': 4.287737846374512,\n",
              "  'step': 59,\n",
              "  'train_loss': 3.1336846351623535},\n",
              " {'decoder_loss': 4.421957015991211,\n",
              "  'step': 60,\n",
              "  'train_loss': 3.5760486125946045},\n",
              " {'decoder_loss': 4.42981481552124,\n",
              "  'step': 61,\n",
              "  'train_loss': 3.703402519226074},\n",
              " {'decoder_loss': 4.411368370056152,\n",
              "  'step': 62,\n",
              "  'train_loss': 2.872403860092163},\n",
              " {'decoder_loss': 4.521775245666504,\n",
              "  'step': 63,\n",
              "  'train_loss': 3.710766077041626},\n",
              " {'decoder_loss': 4.5368733406066895,\n",
              "  'step': 64,\n",
              "  'train_loss': 3.1087958812713623},\n",
              " {'decoder_loss': 4.555994987487793,\n",
              "  'step': 65,\n",
              "  'train_loss': 3.807316541671753},\n",
              " {'decoder_loss': 4.425563335418701,\n",
              "  'step': 66,\n",
              "  'train_loss': 3.2058236598968506},\n",
              " {'decoder_loss': 4.444594383239746,\n",
              "  'step': 67,\n",
              "  'train_loss': 3.2658095359802246},\n",
              " {'decoder_loss': 4.305461406707764,\n",
              "  'step': 68,\n",
              "  'train_loss': 3.5191032886505127},\n",
              " {'decoder_loss': 4.467517852783203,\n",
              "  'step': 69,\n",
              "  'train_loss': 3.4442484378814697},\n",
              " {'decoder_loss': 4.444998264312744,\n",
              "  'step': 70,\n",
              "  'train_loss': 3.460587978363037},\n",
              " {'decoder_loss': 4.3179497718811035,\n",
              "  'step': 71,\n",
              "  'train_loss': 3.6369545459747314},\n",
              " {'decoder_loss': 4.463009834289551,\n",
              "  'step': 72,\n",
              "  'train_loss': 3.6055235862731934},\n",
              " {'decoder_loss': 4.115528583526611,\n",
              "  'step': 73,\n",
              "  'train_loss': 3.004577398300171},\n",
              " {'decoder_loss': 4.438993453979492,\n",
              "  'step': 74,\n",
              "  'train_loss': 3.0754125118255615},\n",
              " {'decoder_loss': 4.0521416664123535,\n",
              "  'step': 75,\n",
              "  'train_loss': 2.969029664993286},\n",
              " {'decoder_loss': 4.478641986846924,\n",
              "  'step': 76,\n",
              "  'train_loss': 3.218065023422241},\n",
              " {'decoder_loss': 4.632535934448242,\n",
              "  'step': 77,\n",
              "  'train_loss': 3.5438344478607178},\n",
              " {'decoder_loss': 3.942605495452881,\n",
              "  'step': 78,\n",
              "  'train_loss': 2.9282660484313965},\n",
              " {'decoder_loss': 4.34688663482666,\n",
              "  'step': 79,\n",
              "  'train_loss': 3.0388033390045166},\n",
              " {'decoder_loss': 4.037693977355957,\n",
              "  'step': 80,\n",
              "  'train_loss': 3.0572001934051514},\n",
              " {'decoder_loss': 4.238879680633545,\n",
              "  'step': 81,\n",
              "  'train_loss': 3.5155467987060547},\n",
              " {'decoder_loss': 4.061465740203857,\n",
              "  'step': 82,\n",
              "  'train_loss': 2.893805980682373},\n",
              " {'decoder_loss': 4.558087348937988,\n",
              "  'step': 83,\n",
              "  'train_loss': 3.4533581733703613},\n",
              " {'decoder_loss': 4.154393672943115,\n",
              "  'step': 84,\n",
              "  'train_loss': 3.1831254959106445},\n",
              " {'decoder_loss': 4.43717622756958,\n",
              "  'step': 85,\n",
              "  'train_loss': 3.4973042011260986},\n",
              " {'decoder_loss': 3.8314592838287354,\n",
              "  'step': 86,\n",
              "  'train_loss': 3.2808289527893066},\n",
              " {'decoder_loss': 4.453582763671875,\n",
              "  'step': 87,\n",
              "  'train_loss': 3.5199756622314453},\n",
              " {'decoder_loss': 4.533690929412842,\n",
              "  'step': 88,\n",
              "  'train_loss': 3.514561176300049},\n",
              " {'decoder_loss': 4.382701873779297,\n",
              "  'step': 89,\n",
              "  'train_loss': 3.1538755893707275},\n",
              " {'decoder_loss': 4.260868549346924,\n",
              "  'step': 90,\n",
              "  'train_loss': 3.0669491291046143},\n",
              " {'decoder_loss': 4.132564067840576,\n",
              "  'step': 91,\n",
              "  'train_loss': 3.4137122631073},\n",
              " {'decoder_loss': 4.442209243774414,\n",
              "  'step': 92,\n",
              "  'train_loss': 3.2528436183929443},\n",
              " {'decoder_loss': 4.59959077835083,\n",
              "  'step': 93,\n",
              "  'train_loss': 3.401667594909668},\n",
              " {'decoder_loss': 4.075793266296387,\n",
              "  'step': 94,\n",
              "  'train_loss': 3.062782049179077},\n",
              " {'decoder_loss': 4.01455020904541,\n",
              "  'step': 95,\n",
              "  'train_loss': 3.264730930328369},\n",
              " {'decoder_loss': 3.9387786388397217,\n",
              "  'step': 96,\n",
              "  'train_loss': 3.144197702407837},\n",
              " {'decoder_loss': 4.105278491973877,\n",
              "  'step': 97,\n",
              "  'train_loss': 3.075429916381836},\n",
              " {'decoder_loss': 4.580872535705566,\n",
              "  'step': 98,\n",
              "  'train_loss': 3.444469928741455},\n",
              " {'decoder_loss': 4.305210113525391,\n",
              "  'step': 99,\n",
              "  'train_loss': 2.9055774211883545},\n",
              " {'decoder_loss': 4.371609210968018,\n",
              "  'step': 100,\n",
              "  'train_loss': 3.3109254837036133},\n",
              " {'decoder_loss': 4.647287368774414,\n",
              "  'step': 101,\n",
              "  'train_loss': 3.778640031814575},\n",
              " {'decoder_loss': 4.1333699226379395,\n",
              "  'step': 102,\n",
              "  'train_loss': 3.1233320236206055},\n",
              " {'decoder_loss': 4.078310012817383,\n",
              "  'step': 103,\n",
              "  'train_loss': 2.9428012371063232},\n",
              " {'decoder_loss': 4.02249813079834,\n",
              "  'step': 104,\n",
              "  'train_loss': 3.282197952270508},\n",
              " {'decoder_loss': 4.490407466888428,\n",
              "  'step': 105,\n",
              "  'train_loss': 3.421032190322876},\n",
              " {'decoder_loss': 4.249340534210205,\n",
              "  'step': 106,\n",
              "  'train_loss': 3.294433832168579},\n",
              " {'decoder_loss': 4.403398036956787,\n",
              "  'step': 107,\n",
              "  'train_loss': 3.4501423835754395},\n",
              " {'decoder_loss': 4.302622318267822,\n",
              "  'step': 108,\n",
              "  'train_loss': 3.0482699871063232},\n",
              " {'decoder_loss': 3.9301323890686035,\n",
              "  'step': 109,\n",
              "  'train_loss': 2.991528034210205},\n",
              " {'decoder_loss': 4.1654791831970215,\n",
              "  'step': 110,\n",
              "  'train_loss': 3.2072536945343018},\n",
              " {'decoder_loss': 4.066817283630371,\n",
              "  'step': 111,\n",
              "  'train_loss': 2.898679256439209},\n",
              " {'decoder_loss': 4.336197853088379,\n",
              "  'step': 112,\n",
              "  'train_loss': 3.1571784019470215},\n",
              " {'decoder_loss': 4.048557758331299,\n",
              "  'step': 113,\n",
              "  'train_loss': 3.452589511871338},\n",
              " {'decoder_loss': 4.316223621368408,\n",
              "  'step': 114,\n",
              "  'train_loss': 3.1430094242095947},\n",
              " {'decoder_loss': 4.2721476554870605,\n",
              "  'step': 115,\n",
              "  'train_loss': 3.215001344680786},\n",
              " {'decoder_loss': 4.276540756225586,\n",
              "  'step': 116,\n",
              "  'train_loss': 2.9761524200439453},\n",
              " {'decoder_loss': 4.36808967590332,\n",
              "  'step': 117,\n",
              "  'train_loss': 2.985732078552246},\n",
              " {'decoder_loss': 4.196727752685547,\n",
              "  'step': 118,\n",
              "  'train_loss': 3.0823142528533936},\n",
              " {'decoder_loss': 4.184417247772217,\n",
              "  'step': 119,\n",
              "  'train_loss': 2.789055109024048},\n",
              " {'decoder_loss': 4.325475692749023,\n",
              "  'step': 120,\n",
              "  'train_loss': 3.472834587097168},\n",
              " {'decoder_loss': 4.424478054046631,\n",
              "  'step': 121,\n",
              "  'train_loss': 2.863173484802246},\n",
              " {'decoder_loss': 4.252093315124512,\n",
              "  'step': 122,\n",
              "  'train_loss': 2.7458696365356445},\n",
              " {'decoder_loss': 4.594419956207275,\n",
              "  'step': 123,\n",
              "  'train_loss': 3.4193050861358643},\n",
              " {'decoder_loss': 4.161252498626709,\n",
              "  'step': 124,\n",
              "  'train_loss': 2.8850462436676025},\n",
              " {'decoder_loss': 4.149146556854248,\n",
              "  'step': 125,\n",
              "  'train_loss': 3.386160373687744},\n",
              " {'decoder_loss': 4.28227424621582,\n",
              "  'step': 126,\n",
              "  'train_loss': 2.945338010787964},\n",
              " {'decoder_loss': 4.254208087921143,\n",
              "  'step': 127,\n",
              "  'train_loss': 3.5693111419677734},\n",
              " {'decoder_loss': 3.9945006370544434,\n",
              "  'step': 128,\n",
              "  'train_loss': 2.89970326423645},\n",
              " {'decoder_loss': 4.1566996574401855,\n",
              "  'step': 129,\n",
              "  'train_loss': 2.573274850845337},\n",
              " {'decoder_loss': 4.143099308013916,\n",
              "  'step': 130,\n",
              "  'train_loss': 3.1570842266082764},\n",
              " {'decoder_loss': 4.704709053039551,\n",
              "  'step': 131,\n",
              "  'train_loss': 3.419877290725708},\n",
              " {'decoder_loss': 4.0337347984313965,\n",
              "  'step': 132,\n",
              "  'train_loss': 3.0060548782348633},\n",
              " {'decoder_loss': 4.26106071472168,\n",
              "  'step': 133,\n",
              "  'train_loss': 3.2201571464538574},\n",
              " {'decoder_loss': 4.478018760681152,\n",
              "  'step': 134,\n",
              "  'train_loss': 3.5566298961639404},\n",
              " {'decoder_loss': 4.176342487335205,\n",
              "  'step': 135,\n",
              "  'train_loss': 2.9999146461486816},\n",
              " {'decoder_loss': 4.27808141708374,\n",
              "  'step': 136,\n",
              "  'train_loss': 2.7773187160491943},\n",
              " {'decoder_loss': 3.821857213973999,\n",
              "  'step': 137,\n",
              "  'train_loss': 2.7764406204223633},\n",
              " {'decoder_loss': 4.227816104888916,\n",
              "  'step': 138,\n",
              "  'train_loss': 3.239534854888916},\n",
              " {'decoder_loss': 4.231797695159912,\n",
              "  'step': 139,\n",
              "  'train_loss': 2.922801971435547},\n",
              " {'decoder_loss': 4.11179256439209,\n",
              "  'step': 140,\n",
              "  'train_loss': 3.0278873443603516},\n",
              " {'decoder_loss': 4.477397918701172,\n",
              "  'step': 141,\n",
              "  'train_loss': 3.2461180686950684},\n",
              " {'decoder_loss': 4.41241455078125,\n",
              "  'step': 142,\n",
              "  'train_loss': 3.223872661590576},\n",
              " {'decoder_loss': 4.066448211669922,\n",
              "  'step': 143,\n",
              "  'train_loss': 2.9259119033813477},\n",
              " {'decoder_loss': 4.280019760131836,\n",
              "  'step': 144,\n",
              "  'train_loss': 2.7790470123291016},\n",
              " {'decoder_loss': 3.936757802963257,\n",
              "  'step': 145,\n",
              "  'train_loss': 3.2308027744293213},\n",
              " {'decoder_loss': 4.1423563957214355,\n",
              "  'step': 146,\n",
              "  'train_loss': 2.9191808700561523},\n",
              " {'decoder_loss': 4.382500648498535,\n",
              "  'step': 147,\n",
              "  'train_loss': 3.0141615867614746},\n",
              " {'decoder_loss': 3.8912289142608643,\n",
              "  'step': 148,\n",
              "  'train_loss': 3.0877444744110107},\n",
              " {'decoder_loss': 4.2686052322387695,\n",
              "  'step': 149,\n",
              "  'train_loss': 3.232872247695923},\n",
              " {'decoder_loss': 4.333850383758545,\n",
              "  'step': 150,\n",
              "  'train_loss': 3.1949779987335205},\n",
              " {'decoder_loss': 4.2868170738220215,\n",
              "  'step': 151,\n",
              "  'train_loss': 3.0781075954437256},\n",
              " {'decoder_loss': 3.9001922607421875,\n",
              "  'step': 152,\n",
              "  'train_loss': 3.041738510131836},\n",
              " {'decoder_loss': 3.9720489978790283,\n",
              "  'step': 153,\n",
              "  'train_loss': 2.5561985969543457},\n",
              " {'decoder_loss': 4.130784511566162,\n",
              "  'step': 154,\n",
              "  'train_loss': 2.8730382919311523},\n",
              " {'decoder_loss': 4.294782638549805,\n",
              "  'step': 155,\n",
              "  'train_loss': 2.979295492172241},\n",
              " {'decoder_loss': 4.029789447784424,\n",
              "  'step': 156,\n",
              "  'train_loss': 2.8960812091827393},\n",
              " {'decoder_loss': 4.26033878326416,\n",
              "  'step': 157,\n",
              "  'train_loss': 3.3008697032928467},\n",
              " {'decoder_loss': 4.120528221130371,\n",
              "  'step': 158,\n",
              "  'train_loss': 2.765960454940796},\n",
              " {'decoder_loss': 4.147927284240723,\n",
              "  'step': 159,\n",
              "  'train_loss': 3.0386428833007812},\n",
              " {'decoder_loss': 4.34422492980957,\n",
              "  'step': 160,\n",
              "  'train_loss': 3.037651538848877},\n",
              " {'decoder_loss': 4.297746181488037,\n",
              "  'step': 161,\n",
              "  'train_loss': 2.9505977630615234},\n",
              " {'decoder_loss': 4.1587748527526855,\n",
              "  'step': 162,\n",
              "  'train_loss': 3.060549259185791},\n",
              " {'decoder_loss': 4.273472785949707,\n",
              "  'step': 163,\n",
              "  'train_loss': 3.050029754638672},\n",
              " {'decoder_loss': 4.143144130706787,\n",
              "  'step': 164,\n",
              "  'train_loss': 2.9715728759765625},\n",
              " {'decoder_loss': 4.23620080947876,\n",
              "  'step': 165,\n",
              "  'train_loss': 3.1781656742095947},\n",
              " {'decoder_loss': 4.4014058113098145,\n",
              "  'step': 166,\n",
              "  'train_loss': 2.7530770301818848},\n",
              " {'decoder_loss': 4.405462265014648,\n",
              "  'step': 167,\n",
              "  'train_loss': 3.1553900241851807},\n",
              " {'decoder_loss': 3.9281442165374756,\n",
              "  'step': 168,\n",
              "  'train_loss': 3.1859683990478516},\n",
              " {'decoder_loss': 4.228604316711426,\n",
              "  'step': 169,\n",
              "  'train_loss': 3.269233465194702},\n",
              " {'decoder_loss': 4.261775016784668,\n",
              "  'step': 170,\n",
              "  'train_loss': 3.3054709434509277},\n",
              " {'decoder_loss': 4.133208751678467,\n",
              "  'step': 171,\n",
              "  'train_loss': 2.9243173599243164},\n",
              " {'decoder_loss': 4.077495098114014,\n",
              "  'step': 172,\n",
              "  'train_loss': 2.9761905670166016},\n",
              " {'decoder_loss': 4.452796459197998,\n",
              "  'step': 173,\n",
              "  'train_loss': 3.243840217590332},\n",
              " {'decoder_loss': 4.629451751708984,\n",
              "  'step': 174,\n",
              "  'train_loss': 3.3680267333984375},\n",
              " {'decoder_loss': 4.354635715484619,\n",
              "  'step': 175,\n",
              "  'train_loss': 3.2210962772369385},\n",
              " {'decoder_loss': 4.033113956451416,\n",
              "  'step': 176,\n",
              "  'train_loss': 2.8335163593292236},\n",
              " {'decoder_loss': 4.1794753074646,\n",
              "  'step': 177,\n",
              "  'train_loss': 2.9597342014312744},\n",
              " {'decoder_loss': 4.405641555786133,\n",
              "  'step': 178,\n",
              "  'train_loss': 3.5537030696868896},\n",
              " {'decoder_loss': 4.25773811340332,\n",
              "  'step': 179,\n",
              "  'train_loss': 3.3293261528015137},\n",
              " {'decoder_loss': 4.241314888000488,\n",
              "  'step': 180,\n",
              "  'train_loss': 3.3393235206604004},\n",
              " {'decoder_loss': 4.1858344078063965,\n",
              "  'step': 181,\n",
              "  'train_loss': 2.966475248336792},\n",
              " {'decoder_loss': 4.113938331604004,\n",
              "  'step': 182,\n",
              "  'train_loss': 2.9273269176483154},\n",
              " {'decoder_loss': 4.179477214813232,\n",
              "  'step': 183,\n",
              "  'train_loss': 2.8328192234039307},\n",
              " {'decoder_loss': 4.705864429473877,\n",
              "  'step': 184,\n",
              "  'train_loss': 3.172903537750244},\n",
              " {'decoder_loss': 4.375298500061035,\n",
              "  'step': 185,\n",
              "  'train_loss': 3.148301601409912},\n",
              " {'decoder_loss': 4.252488613128662,\n",
              "  'step': 186,\n",
              "  'train_loss': 3.005047559738159},\n",
              " {'decoder_loss': 4.139187812805176,\n",
              "  'step': 187,\n",
              "  'train_loss': 3.01298189163208},\n",
              " {'decoder_loss': 4.114499092102051,\n",
              "  'step': 188,\n",
              "  'train_loss': 2.967874765396118},\n",
              " {'decoder_loss': 4.2172722816467285,\n",
              "  'step': 189,\n",
              "  'train_loss': 3.27225923538208},\n",
              " {'decoder_loss': 3.8700778484344482,\n",
              "  'step': 190,\n",
              "  'train_loss': 2.8658268451690674},\n",
              " {'decoder_loss': 3.9928741455078125,\n",
              "  'step': 191,\n",
              "  'train_loss': 2.830416440963745},\n",
              " {'decoder_loss': 4.31365966796875,\n",
              "  'step': 192,\n",
              "  'train_loss': 2.728095769882202},\n",
              " {'decoder_loss': 4.41619348526001,\n",
              "  'step': 193,\n",
              "  'train_loss': 2.881033420562744},\n",
              " {'decoder_loss': 4.402472972869873,\n",
              "  'step': 194,\n",
              "  'train_loss': 3.3928592205047607},\n",
              " {'decoder_loss': 4.152700424194336,\n",
              "  'step': 195,\n",
              "  'train_loss': 3.0571579933166504},\n",
              " {'decoder_loss': 4.291453838348389,\n",
              "  'step': 196,\n",
              "  'train_loss': 3.353006362915039},\n",
              " {'decoder_loss': 3.887017011642456,\n",
              "  'step': 197,\n",
              "  'train_loss': 3.021261692047119},\n",
              " {'decoder_loss': 4.012614727020264,\n",
              "  'step': 198,\n",
              "  'train_loss': 3.053884267807007},\n",
              " {'decoder_loss': 4.235698223114014,\n",
              "  'step': 199,\n",
              "  'train_loss': 3.236191511154175},\n",
              " {'decoder_loss': 4.227677345275879,\n",
              "  'step': 200,\n",
              "  'train_loss': 3.1233506202697754},\n",
              " {'decoder_loss': 4.209092617034912,\n",
              "  'step': 201,\n",
              "  'train_loss': 3.0285537242889404},\n",
              " {'decoder_loss': 4.031613826751709,\n",
              "  'step': 202,\n",
              "  'train_loss': 2.7945263385772705},\n",
              " {'decoder_loss': 4.1922688484191895,\n",
              "  'step': 203,\n",
              "  'train_loss': 3.4666550159454346},\n",
              " {'decoder_loss': 4.316774845123291,\n",
              "  'step': 204,\n",
              "  'train_loss': 3.409364700317383},\n",
              " {'decoder_loss': 4.127485275268555,\n",
              "  'step': 205,\n",
              "  'train_loss': 2.98045015335083},\n",
              " {'decoder_loss': 4.306412696838379,\n",
              "  'step': 206,\n",
              "  'train_loss': 3.186579942703247},\n",
              " {'decoder_loss': 3.8366763591766357,\n",
              "  'step': 207,\n",
              "  'train_loss': 2.9414594173431396},\n",
              " {'decoder_loss': 4.286646842956543,\n",
              "  'step': 208,\n",
              "  'train_loss': 2.902484178543091},\n",
              " {'decoder_loss': 4.358010292053223,\n",
              "  'step': 209,\n",
              "  'train_loss': 3.380892038345337},\n",
              " {'decoder_loss': 4.2205915451049805,\n",
              "  'step': 210,\n",
              "  'train_loss': 3.078418731689453},\n",
              " {'decoder_loss': 3.9061737060546875,\n",
              "  'step': 211,\n",
              "  'train_loss': 3.04399037361145},\n",
              " {'decoder_loss': 3.7425897121429443,\n",
              "  'step': 212,\n",
              "  'train_loss': 2.7515244483947754},\n",
              " {'decoder_loss': 4.341038703918457,\n",
              "  'step': 213,\n",
              "  'train_loss': 3.0361874103546143},\n",
              " {'decoder_loss': 3.981812000274658,\n",
              "  'step': 214,\n",
              "  'train_loss': 2.9319515228271484},\n",
              " {'decoder_loss': 4.0873799324035645,\n",
              "  'step': 215,\n",
              "  'train_loss': 2.884190797805786},\n",
              " {'decoder_loss': 4.078420639038086,\n",
              "  'step': 216,\n",
              "  'train_loss': 3.2367019653320312},\n",
              " {'decoder_loss': 3.966722249984741,\n",
              "  'step': 217,\n",
              "  'train_loss': 2.891908645629883},\n",
              " {'decoder_loss': 3.707531452178955,\n",
              "  'step': 218,\n",
              "  'train_loss': 2.5485057830810547},\n",
              " {'decoder_loss': 4.356540679931641,\n",
              "  'step': 219,\n",
              "  'train_loss': 3.1860649585723877},\n",
              " {'decoder_loss': 3.928520441055298,\n",
              "  'step': 220,\n",
              "  'train_loss': 2.9588141441345215},\n",
              " {'decoder_loss': 3.8575611114501953,\n",
              "  'step': 221,\n",
              "  'train_loss': 2.8530731201171875},\n",
              " {'decoder_loss': 3.5821101665496826,\n",
              "  'step': 222,\n",
              "  'train_loss': 2.6675186157226562},\n",
              " {'decoder_loss': 3.960972785949707,\n",
              "  'step': 223,\n",
              "  'train_loss': 3.00970721244812},\n",
              " {'decoder_loss': 3.902134656906128,\n",
              "  'step': 224,\n",
              "  'train_loss': 3.1503806114196777},\n",
              " {'decoder_loss': 4.237082481384277,\n",
              "  'step': 225,\n",
              "  'train_loss': 2.987647533416748},\n",
              " {'decoder_loss': 4.4700846672058105,\n",
              "  'step': 226,\n",
              "  'train_loss': 2.8805909156799316},\n",
              " {'decoder_loss': 4.091917037963867,\n",
              "  'step': 227,\n",
              "  'train_loss': 2.9469945430755615},\n",
              " {'decoder_loss': 4.0530524253845215,\n",
              "  'step': 228,\n",
              "  'train_loss': 2.862234592437744},\n",
              " {'decoder_loss': 4.327785015106201,\n",
              "  'step': 229,\n",
              "  'train_loss': 3.2970879077911377},\n",
              " {'decoder_loss': 4.270782470703125,\n",
              "  'step': 230,\n",
              "  'train_loss': 3.222886562347412},\n",
              " {'decoder_loss': 4.385369777679443,\n",
              "  'step': 231,\n",
              "  'train_loss': 3.4861254692077637},\n",
              " {'decoder_loss': 3.9946439266204834,\n",
              "  'step': 232,\n",
              "  'train_loss': 2.797588586807251},\n",
              " {'decoder_loss': 4.236487865447998,\n",
              "  'step': 233,\n",
              "  'train_loss': 2.530754327774048},\n",
              " {'decoder_loss': 3.9180688858032227,\n",
              "  'step': 234,\n",
              "  'train_loss': 2.708866834640503},\n",
              " {'decoder_loss': 4.351637363433838,\n",
              "  'step': 235,\n",
              "  'train_loss': 3.269442558288574},\n",
              " {'decoder_loss': 4.195279121398926,\n",
              "  'step': 236,\n",
              "  'train_loss': 2.8957314491271973},\n",
              " {'decoder_loss': 3.9435994625091553,\n",
              "  'step': 237,\n",
              "  'train_loss': 2.7722277641296387},\n",
              " {'decoder_loss': 4.49564266204834,\n",
              "  'step': 238,\n",
              "  'train_loss': 3.2044360637664795},\n",
              " {'decoder_loss': 4.304246425628662,\n",
              "  'step': 239,\n",
              "  'train_loss': 3.1943671703338623},\n",
              " {'decoder_loss': 4.2084269523620605,\n",
              "  'step': 240,\n",
              "  'train_loss': 3.3504066467285156},\n",
              " {'decoder_loss': 3.6031405925750732,\n",
              "  'step': 241,\n",
              "  'train_loss': 2.7159624099731445},\n",
              " {'decoder_loss': 4.340166091918945,\n",
              "  'step': 242,\n",
              "  'train_loss': 3.0896830558776855},\n",
              " {'decoder_loss': 3.978226661682129,\n",
              "  'step': 243,\n",
              "  'train_loss': 3.314835548400879},\n",
              " {'decoder_loss': 3.9578142166137695,\n",
              "  'step': 244,\n",
              "  'train_loss': 2.279597759246826},\n",
              " {'decoder_loss': 3.955176591873169,\n",
              "  'step': 245,\n",
              "  'train_loss': 3.105780601501465},\n",
              " {'decoder_loss': 3.96720552444458,\n",
              "  'step': 246,\n",
              "  'train_loss': 2.9019711017608643},\n",
              " {'decoder_loss': 3.8308475017547607,\n",
              "  'step': 247,\n",
              "  'train_loss': 2.5625293254852295},\n",
              " {'decoder_loss': 3.9213340282440186,\n",
              "  'step': 248,\n",
              "  'train_loss': 3.165954828262329},\n",
              " {'decoder_loss': 4.3454790115356445,\n",
              "  'step': 249,\n",
              "  'train_loss': 3.3310680389404297},\n",
              " {'decoder_loss': 3.824512243270874,\n",
              "  'step': 250,\n",
              "  'train_loss': 2.8491716384887695},\n",
              " {'decoder_loss': 4.285852432250977,\n",
              "  'step': 251,\n",
              "  'train_loss': 3.351109027862549},\n",
              " {'decoder_loss': 4.176516532897949,\n",
              "  'step': 252,\n",
              "  'train_loss': 3.1091413497924805},\n",
              " {'decoder_loss': 4.10911226272583,\n",
              "  'step': 253,\n",
              "  'train_loss': 2.8704581260681152},\n",
              " {'decoder_loss': 4.044400691986084,\n",
              "  'step': 254,\n",
              "  'train_loss': 3.048642873764038},\n",
              " {'decoder_loss': 3.944746732711792,\n",
              "  'step': 255,\n",
              "  'train_loss': 2.9230716228485107},\n",
              " {'decoder_loss': 3.972811222076416,\n",
              "  'step': 256,\n",
              "  'train_loss': 3.055962562561035},\n",
              " {'decoder_loss': 4.410000801086426,\n",
              "  'step': 257,\n",
              "  'train_loss': 3.3159756660461426},\n",
              " {'decoder_loss': 4.028639316558838,\n",
              "  'step': 258,\n",
              "  'train_loss': 3.131514549255371},\n",
              " {'decoder_loss': 3.9895384311676025,\n",
              "  'step': 259,\n",
              "  'train_loss': 2.97776460647583},\n",
              " {'decoder_loss': 4.176092147827148,\n",
              "  'step': 260,\n",
              "  'train_loss': 2.981856346130371},\n",
              " {'decoder_loss': 3.7950305938720703,\n",
              "  'step': 261,\n",
              "  'train_loss': 3.0209927558898926},\n",
              " {'decoder_loss': 4.218411445617676,\n",
              "  'step': 262,\n",
              "  'train_loss': 2.7990810871124268},\n",
              " {'decoder_loss': 3.7598390579223633,\n",
              "  'step': 263,\n",
              "  'train_loss': 2.551868200302124},\n",
              " {'decoder_loss': 4.67426061630249,\n",
              "  'step': 264,\n",
              "  'train_loss': 3.6022396087646484},\n",
              " {'decoder_loss': 4.701407432556152,\n",
              "  'step': 265,\n",
              "  'train_loss': 3.421628952026367},\n",
              " {'decoder_loss': 3.956589460372925,\n",
              "  'step': 266,\n",
              "  'train_loss': 2.7967772483825684},\n",
              " {'decoder_loss': 4.073622703552246,\n",
              "  'step': 267,\n",
              "  'train_loss': 2.793679714202881},\n",
              " {'decoder_loss': 4.09302282333374,\n",
              "  'step': 268,\n",
              "  'train_loss': 3.319835662841797},\n",
              " {'decoder_loss': 4.512967109680176,\n",
              "  'step': 269,\n",
              "  'train_loss': 2.999701499938965},\n",
              " {'decoder_loss': 4.060941219329834,\n",
              "  'step': 270,\n",
              "  'train_loss': 2.8476157188415527},\n",
              " {'decoder_loss': 4.085556507110596,\n",
              "  'step': 271,\n",
              "  'train_loss': 2.9182307720184326},\n",
              " {'decoder_loss': 3.952162981033325,\n",
              "  'step': 272,\n",
              "  'train_loss': 2.468336343765259},\n",
              " {'decoder_loss': 3.960203170776367,\n",
              "  'step': 273,\n",
              "  'train_loss': 2.9377386569976807},\n",
              " {'decoder_loss': 4.05947732925415,\n",
              "  'step': 274,\n",
              "  'train_loss': 2.590811252593994},\n",
              " {'decoder_loss': 4.023854732513428,\n",
              "  'step': 275,\n",
              "  'train_loss': 2.664588212966919},\n",
              " {'decoder_loss': 3.69754958152771,\n",
              "  'step': 276,\n",
              "  'train_loss': 2.463656187057495},\n",
              " {'decoder_loss': 3.985415458679199,\n",
              "  'step': 277,\n",
              "  'train_loss': 3.0086967945098877},\n",
              " {'decoder_loss': 4.020700931549072,\n",
              "  'step': 278,\n",
              "  'train_loss': 2.8188316822052},\n",
              " {'decoder_loss': 4.268316268920898,\n",
              "  'step': 279,\n",
              "  'train_loss': 3.299003839492798},\n",
              " {'decoder_loss': 3.8298728466033936,\n",
              "  'step': 280,\n",
              "  'train_loss': 2.879777193069458},\n",
              " {'decoder_loss': 3.9265806674957275,\n",
              "  'step': 281,\n",
              "  'train_loss': 3.0728697776794434},\n",
              " {'decoder_loss': 4.061431884765625,\n",
              "  'step': 282,\n",
              "  'train_loss': 2.8365206718444824},\n",
              " {'decoder_loss': 4.472903728485107,\n",
              "  'step': 283,\n",
              "  'train_loss': 3.224684715270996},\n",
              " {'decoder_loss': 3.9356555938720703,\n",
              "  'step': 284,\n",
              "  'train_loss': 2.565425157546997},\n",
              " {'decoder_loss': 4.055601119995117,\n",
              "  'step': 285,\n",
              "  'train_loss': 2.9937899112701416},\n",
              " {'decoder_loss': 4.318641185760498,\n",
              "  'step': 286,\n",
              "  'train_loss': 2.846954822540283},\n",
              " {'decoder_loss': 4.068978309631348,\n",
              "  'step': 287,\n",
              "  'train_loss': 2.989374876022339},\n",
              " {'decoder_loss': 3.853457450866699,\n",
              "  'step': 288,\n",
              "  'train_loss': 3.058154821395874},\n",
              " {'decoder_loss': 4.016862392425537,\n",
              "  'step': 289,\n",
              "  'train_loss': 2.855778932571411},\n",
              " {'decoder_loss': 4.198334693908691,\n",
              "  'step': 290,\n",
              "  'train_loss': 3.265528678894043},\n",
              " {'decoder_loss': 3.8759820461273193,\n",
              "  'step': 291,\n",
              "  'train_loss': 2.706385374069214},\n",
              " {'decoder_loss': 4.099663257598877,\n",
              "  'step': 292,\n",
              "  'train_loss': 2.9402661323547363},\n",
              " {'decoder_loss': 3.8506994247436523,\n",
              "  'step': 293,\n",
              "  'train_loss': 3.1876749992370605},\n",
              " {'decoder_loss': 3.905028820037842,\n",
              "  'step': 294,\n",
              "  'train_loss': 2.768023729324341},\n",
              " {'decoder_loss': 4.297054290771484,\n",
              "  'step': 295,\n",
              "  'train_loss': 2.6865286827087402},\n",
              " {'decoder_loss': 4.141312122344971,\n",
              "  'step': 296,\n",
              "  'train_loss': 3.2195236682891846},\n",
              " {'decoder_loss': 4.0310959815979,\n",
              "  'step': 297,\n",
              "  'train_loss': 2.976093053817749},\n",
              " {'decoder_loss': 4.010438919067383,\n",
              "  'step': 298,\n",
              "  'train_loss': 2.917994737625122},\n",
              " {'decoder_loss': 4.081194877624512,\n",
              "  'step': 299,\n",
              "  'train_loss': 3.245096445083618},\n",
              " {'decoder_loss': 3.8422555923461914,\n",
              "  'step': 300,\n",
              "  'train_loss': 2.723437547683716},\n",
              " {'decoder_loss': 4.132062911987305,\n",
              "  'step': 301,\n",
              "  'train_loss': 2.782233953475952},\n",
              " {'decoder_loss': 4.142673492431641,\n",
              "  'step': 302,\n",
              "  'train_loss': 2.734384536743164},\n",
              " {'decoder_loss': 4.167751789093018,\n",
              "  'step': 303,\n",
              "  'train_loss': 2.9009928703308105},\n",
              " {'decoder_loss': 3.8705554008483887,\n",
              "  'step': 304,\n",
              "  'train_loss': 2.9339168071746826},\n",
              " {'decoder_loss': 4.1280059814453125,\n",
              "  'step': 305,\n",
              "  'train_loss': 3.294053792953491},\n",
              " {'decoder_loss': 3.7593023777008057,\n",
              "  'step': 306,\n",
              "  'train_loss': 2.571587085723877},\n",
              " {'decoder_loss': 4.093074321746826,\n",
              "  'step': 307,\n",
              "  'train_loss': 2.6149673461914062},\n",
              " {'decoder_loss': 4.14940881729126,\n",
              "  'step': 308,\n",
              "  'train_loss': 3.126744508743286},\n",
              " {'decoder_loss': 3.989237070083618,\n",
              "  'step': 309,\n",
              "  'train_loss': 2.760406017303467},\n",
              " {'decoder_loss': 4.423190116882324,\n",
              "  'step': 310,\n",
              "  'train_loss': 3.255152463912964},\n",
              " {'decoder_loss': 4.172206401824951,\n",
              "  'step': 311,\n",
              "  'train_loss': 3.1463472843170166},\n",
              " {'decoder_loss': 4.139737606048584,\n",
              "  'step': 312,\n",
              "  'train_loss': 3.24770450592041},\n",
              " {'decoder_loss': 4.348472595214844,\n",
              "  'step': 313,\n",
              "  'train_loss': 3.1341187953948975},\n",
              " {'decoder_loss': 4.331850528717041,\n",
              "  'step': 314,\n",
              "  'train_loss': 3.2379372119903564},\n",
              " {'decoder_loss': 3.8527157306671143,\n",
              "  'step': 315,\n",
              "  'train_loss': 2.4856762886047363},\n",
              " {'decoder_loss': 4.038485527038574,\n",
              "  'step': 316,\n",
              "  'train_loss': 3.2922534942626953},\n",
              " {'decoder_loss': 4.1815409660339355,\n",
              "  'step': 317,\n",
              "  'train_loss': 2.9032065868377686},\n",
              " {'decoder_loss': 3.9357056617736816,\n",
              "  'step': 318,\n",
              "  'train_loss': 2.518948554992676},\n",
              " {'decoder_loss': 4.4099931716918945,\n",
              "  'step': 319,\n",
              "  'train_loss': 3.062232494354248},\n",
              " {'decoder_loss': 3.758300304412842,\n",
              "  'step': 320,\n",
              "  'train_loss': 2.799311876296997},\n",
              " {'decoder_loss': 3.9959774017333984,\n",
              "  'step': 321,\n",
              "  'train_loss': 3.169663906097412},\n",
              " {'decoder_loss': 4.233682632446289,\n",
              "  'step': 322,\n",
              "  'train_loss': 3.194537878036499},\n",
              " {'decoder_loss': 3.9438302516937256,\n",
              "  'step': 323,\n",
              "  'train_loss': 2.8923373222351074},\n",
              " {'decoder_loss': 4.179691314697266,\n",
              "  'step': 324,\n",
              "  'train_loss': 2.9809515476226807},\n",
              " {'decoder_loss': 4.083210468292236,\n",
              "  'step': 325,\n",
              "  'train_loss': 3.043541431427002},\n",
              " {'decoder_loss': 4.082983493804932,\n",
              "  'step': 326,\n",
              "  'train_loss': 2.7515738010406494},\n",
              " {'decoder_loss': 4.100729465484619,\n",
              "  'step': 327,\n",
              "  'train_loss': 2.891958713531494},\n",
              " {'decoder_loss': 3.682612895965576,\n",
              "  'step': 328,\n",
              "  'train_loss': 2.752310037612915},\n",
              " {'decoder_loss': 4.142539978027344,\n",
              "  'step': 329,\n",
              "  'train_loss': 3.0237627029418945},\n",
              " {'decoder_loss': 3.864851236343384,\n",
              "  'step': 330,\n",
              "  'train_loss': 2.8964664936065674},\n",
              " {'decoder_loss': 4.2574381828308105,\n",
              "  'step': 331,\n",
              "  'train_loss': 3.0397050380706787},\n",
              " {'decoder_loss': 4.172438144683838,\n",
              "  'step': 332,\n",
              "  'train_loss': 3.151421308517456},\n",
              " {'decoder_loss': 4.070080757141113,\n",
              "  'step': 333,\n",
              "  'train_loss': 2.5016560554504395},\n",
              " {'decoder_loss': 3.9879536628723145,\n",
              "  'step': 334,\n",
              "  'train_loss': 3.1004481315612793},\n",
              " {'decoder_loss': 4.002842426300049,\n",
              "  'step': 335,\n",
              "  'train_loss': 2.9221811294555664},\n",
              " {'decoder_loss': 3.558743953704834,\n",
              "  'step': 336,\n",
              "  'train_loss': 2.802070379257202},\n",
              " {'decoder_loss': 4.058781147003174,\n",
              "  'step': 337,\n",
              "  'train_loss': 3.1092400550842285},\n",
              " {'decoder_loss': 4.011800765991211,\n",
              "  'step': 338,\n",
              "  'train_loss': 2.6333446502685547},\n",
              " {'decoder_loss': 3.8393373489379883,\n",
              "  'step': 339,\n",
              "  'train_loss': 2.818599224090576},\n",
              " {'decoder_loss': 4.3551859855651855,\n",
              "  'step': 340,\n",
              "  'train_loss': 2.933603048324585},\n",
              " {'decoder_loss': 4.103588104248047,\n",
              "  'step': 341,\n",
              "  'train_loss': 2.7679789066314697},\n",
              " {'decoder_loss': 4.073355674743652,\n",
              "  'step': 342,\n",
              "  'train_loss': 3.161745071411133},\n",
              " {'decoder_loss': 4.082519054412842,\n",
              "  'step': 343,\n",
              "  'train_loss': 2.899245500564575},\n",
              " {'decoder_loss': 4.379388332366943,\n",
              "  'step': 344,\n",
              "  'train_loss': 3.121753215789795},\n",
              " {'decoder_loss': 4.260717868804932,\n",
              "  'step': 345,\n",
              "  'train_loss': 2.8947792053222656},\n",
              " {'decoder_loss': 4.334198951721191,\n",
              "  'step': 346,\n",
              "  'train_loss': 3.1129133701324463},\n",
              " {'decoder_loss': 4.004152297973633,\n",
              "  'step': 347,\n",
              "  'train_loss': 3.0359158515930176},\n",
              " {'decoder_loss': 4.355292320251465,\n",
              "  'step': 348,\n",
              "  'train_loss': 2.613952398300171},\n",
              " {'decoder_loss': 4.340612411499023,\n",
              "  'step': 349,\n",
              "  'train_loss': 3.5991556644439697},\n",
              " {'decoder_loss': 4.166212558746338,\n",
              "  'step': 350,\n",
              "  'train_loss': 2.886969804763794},\n",
              " {'decoder_loss': 4.329283237457275,\n",
              "  'step': 351,\n",
              "  'train_loss': 3.2575674057006836},\n",
              " {'decoder_loss': 4.069575309753418,\n",
              "  'step': 352,\n",
              "  'train_loss': 3.212792158126831},\n",
              " {'decoder_loss': 4.403819561004639,\n",
              "  'step': 353,\n",
              "  'train_loss': 3.0357229709625244},\n",
              " {'decoder_loss': 3.9703407287597656,\n",
              "  'step': 354,\n",
              "  'train_loss': 2.831009864807129},\n",
              " {'decoder_loss': 4.451112270355225,\n",
              "  'step': 355,\n",
              "  'train_loss': 3.5696403980255127},\n",
              " {'decoder_loss': 4.0565972328186035,\n",
              "  'step': 356,\n",
              "  'train_loss': 2.6361029148101807},\n",
              " {'decoder_loss': 4.007158279418945,\n",
              "  'step': 357,\n",
              "  'train_loss': 3.228219747543335},\n",
              " {'decoder_loss': 3.9652211666107178,\n",
              "  'step': 358,\n",
              "  'train_loss': 2.855409860610962},\n",
              " {'decoder_loss': 3.8436107635498047,\n",
              "  'step': 359,\n",
              "  'train_loss': 2.454845666885376},\n",
              " {'decoder_loss': 4.016040802001953,\n",
              "  'step': 360,\n",
              "  'train_loss': 3.1003544330596924},\n",
              " {'decoder_loss': 3.961226224899292,\n",
              "  'step': 361,\n",
              "  'train_loss': 2.665565013885498},\n",
              " {'decoder_loss': 4.123095512390137,\n",
              "  'step': 362,\n",
              "  'train_loss': 2.940701961517334},\n",
              " {'decoder_loss': 3.9196338653564453,\n",
              "  'step': 363,\n",
              "  'train_loss': 2.821300506591797},\n",
              " {'decoder_loss': 4.246180534362793,\n",
              "  'step': 364,\n",
              "  'train_loss': 3.1099793910980225},\n",
              " {'decoder_loss': 3.9397218227386475,\n",
              "  'step': 365,\n",
              "  'train_loss': 2.9100213050842285},\n",
              " {'decoder_loss': 4.196070671081543,\n",
              "  'step': 366,\n",
              "  'train_loss': 2.7903058528900146},\n",
              " {'decoder_loss': 4.128612518310547,\n",
              "  'step': 367,\n",
              "  'train_loss': 2.496051788330078},\n",
              " {'decoder_loss': 3.899608850479126,\n",
              "  'step': 368,\n",
              "  'train_loss': 2.6326003074645996},\n",
              " {'decoder_loss': 4.03063440322876,\n",
              "  'step': 369,\n",
              "  'train_loss': 3.0395612716674805},\n",
              " {'decoder_loss': 3.97171950340271,\n",
              "  'step': 370,\n",
              "  'train_loss': 3.3419618606567383},\n",
              " {'decoder_loss': 4.067780494689941,\n",
              "  'step': 371,\n",
              "  'train_loss': 2.5658938884735107},\n",
              " {'decoder_loss': 3.777606725692749,\n",
              "  'step': 372,\n",
              "  'train_loss': 2.81469464302063},\n",
              " {'decoder_loss': 4.156208515167236,\n",
              "  'step': 373,\n",
              "  'train_loss': 2.496286392211914},\n",
              " {'decoder_loss': 4.290757656097412,\n",
              "  'step': 374,\n",
              "  'train_loss': 3.4211955070495605},\n",
              " {'decoder_loss': 3.7687106132507324,\n",
              "  'step': 375,\n",
              "  'train_loss': 2.852008104324341},\n",
              " {'decoder_loss': 4.221627235412598,\n",
              "  'step': 376,\n",
              "  'train_loss': 2.9515247344970703},\n",
              " {'decoder_loss': 3.508884906768799,\n",
              "  'step': 377,\n",
              "  'train_loss': 2.57077956199646},\n",
              " {'decoder_loss': 4.130458831787109,\n",
              "  'step': 378,\n",
              "  'train_loss': 3.071040630340576},\n",
              " {'decoder_loss': 4.044956207275391,\n",
              "  'step': 379,\n",
              "  'train_loss': 3.236111640930176},\n",
              " {'decoder_loss': 4.122175216674805,\n",
              "  'step': 380,\n",
              "  'train_loss': 2.781660556793213},\n",
              " {'decoder_loss': 4.027557849884033,\n",
              "  'step': 381,\n",
              "  'train_loss': 2.8668549060821533},\n",
              " {'decoder_loss': 4.278225421905518,\n",
              "  'step': 382,\n",
              "  'train_loss': 2.9314117431640625},\n",
              " {'decoder_loss': 3.987691879272461,\n",
              "  'step': 383,\n",
              "  'train_loss': 2.916132688522339},\n",
              " {'decoder_loss': 3.9459002017974854,\n",
              "  'step': 384,\n",
              "  'train_loss': 2.807048797607422},\n",
              " {'decoder_loss': 4.246133804321289,\n",
              "  'step': 385,\n",
              "  'train_loss': 2.9340553283691406},\n",
              " {'decoder_loss': 4.290125370025635,\n",
              "  'step': 386,\n",
              "  'train_loss': 3.2973361015319824},\n",
              " {'decoder_loss': 3.9644482135772705,\n",
              "  'step': 387,\n",
              "  'train_loss': 2.85758376121521},\n",
              " {'decoder_loss': 3.780345916748047,\n",
              "  'step': 388,\n",
              "  'train_loss': 2.8687658309936523},\n",
              " {'decoder_loss': 3.835636615753174,\n",
              "  'step': 389,\n",
              "  'train_loss': 2.677224636077881},\n",
              " {'decoder_loss': 4.224031925201416,\n",
              "  'step': 390,\n",
              "  'train_loss': 3.0216169357299805},\n",
              " {'decoder_loss': 4.215954780578613,\n",
              "  'step': 391,\n",
              "  'train_loss': 2.9462575912475586},\n",
              " {'decoder_loss': 4.453909873962402,\n",
              "  'step': 392,\n",
              "  'train_loss': 3.01115345954895},\n",
              " {'decoder_loss': 4.0582146644592285,\n",
              "  'step': 393,\n",
              "  'train_loss': 2.844999313354492},\n",
              " {'decoder_loss': 4.193479537963867,\n",
              "  'step': 394,\n",
              "  'train_loss': 3.0673763751983643},\n",
              " {'decoder_loss': 3.9673469066619873,\n",
              "  'step': 395,\n",
              "  'train_loss': 2.959364891052246},\n",
              " {'decoder_loss': 4.183481216430664,\n",
              "  'step': 396,\n",
              "  'train_loss': 2.9645886421203613},\n",
              " {'decoder_loss': 4.009942054748535,\n",
              "  'step': 397,\n",
              "  'train_loss': 3.073549509048462},\n",
              " {'decoder_loss': 3.918766736984253,\n",
              "  'step': 398,\n",
              "  'train_loss': 3.1273467540740967},\n",
              " {'decoder_loss': 4.075650691986084,\n",
              "  'step': 399,\n",
              "  'train_loss': 2.7653274536132812},\n",
              " {'decoder_loss': 3.925374746322632,\n",
              "  'step': 400,\n",
              "  'train_loss': 2.8695623874664307},\n",
              " {'decoder_loss': 3.7049615383148193,\n",
              "  'step': 401,\n",
              "  'train_loss': 2.7688486576080322},\n",
              " {'decoder_loss': 4.1382904052734375,\n",
              "  'step': 402,\n",
              "  'train_loss': 3.2223572731018066},\n",
              " {'decoder_loss': 3.8381412029266357,\n",
              "  'step': 403,\n",
              "  'train_loss': 2.6507391929626465},\n",
              " {'decoder_loss': 3.9187257289886475,\n",
              "  'step': 404,\n",
              "  'train_loss': 2.7509663105010986},\n",
              " {'decoder_loss': 3.911336660385132,\n",
              "  'step': 405,\n",
              "  'train_loss': 2.8107941150665283},\n",
              " {'decoder_loss': 3.930067300796509,\n",
              "  'step': 406,\n",
              "  'train_loss': 2.911810874938965},\n",
              " {'decoder_loss': 4.193448066711426,\n",
              "  'step': 407,\n",
              "  'train_loss': 2.856621265411377},\n",
              " {'decoder_loss': 3.9950761795043945,\n",
              "  'step': 408,\n",
              "  'train_loss': 3.2893810272216797},\n",
              " {'decoder_loss': 4.093944072723389,\n",
              "  'step': 409,\n",
              "  'train_loss': 2.6905462741851807},\n",
              " {'decoder_loss': 4.167457580566406,\n",
              "  'step': 410,\n",
              "  'train_loss': 3.1923370361328125},\n",
              " {'decoder_loss': 4.116408824920654,\n",
              "  'step': 411,\n",
              "  'train_loss': 3.1185946464538574},\n",
              " {'decoder_loss': 4.115623950958252,\n",
              "  'step': 412,\n",
              "  'train_loss': 3.141005754470825},\n",
              " {'decoder_loss': 4.319913387298584,\n",
              "  'step': 413,\n",
              "  'train_loss': 2.977978467941284},\n",
              " {'decoder_loss': 3.839716672897339,\n",
              "  'step': 414,\n",
              "  'train_loss': 2.8203368186950684},\n",
              " {'decoder_loss': 3.893785238265991,\n",
              "  'step': 415,\n",
              "  'train_loss': 2.996328115463257},\n",
              " {'decoder_loss': 3.8962368965148926,\n",
              "  'step': 416,\n",
              "  'train_loss': 2.7908785343170166},\n",
              " {'decoder_loss': 4.166330337524414,\n",
              "  'step': 417,\n",
              "  'train_loss': 2.791414976119995},\n",
              " {'decoder_loss': 3.972480297088623,\n",
              "  'step': 418,\n",
              "  'train_loss': 2.6891324520111084},\n",
              " {'decoder_loss': 3.9258835315704346,\n",
              "  'step': 419,\n",
              "  'train_loss': 3.076108455657959},\n",
              " {'decoder_loss': 4.217876434326172,\n",
              "  'step': 420,\n",
              "  'train_loss': 3.368013858795166},\n",
              " {'decoder_loss': 4.1407060623168945,\n",
              "  'step': 421,\n",
              "  'train_loss': 2.8664238452911377},\n",
              " {'decoder_loss': 4.082234859466553,\n",
              "  'step': 422,\n",
              "  'train_loss': 2.7748489379882812},\n",
              " {'decoder_loss': 3.9909942150115967,\n",
              "  'step': 423,\n",
              "  'train_loss': 3.006195068359375},\n",
              " {'decoder_loss': 3.7385878562927246,\n",
              "  'step': 424,\n",
              "  'train_loss': 2.821016788482666},\n",
              " {'decoder_loss': 4.136026382446289,\n",
              "  'step': 425,\n",
              "  'train_loss': 2.9756126403808594},\n",
              " {'decoder_loss': 3.939671277999878,\n",
              "  'step': 426,\n",
              "  'train_loss': 2.73580265045166},\n",
              " {'decoder_loss': 4.138106822967529,\n",
              "  'step': 427,\n",
              "  'train_loss': 2.967783212661743},\n",
              " {'decoder_loss': 3.7107906341552734,\n",
              "  'step': 428,\n",
              "  'train_loss': 2.876333475112915},\n",
              " {'decoder_loss': 3.8867037296295166,\n",
              "  'step': 429,\n",
              "  'train_loss': 2.6914987564086914},\n",
              " {'decoder_loss': 4.032543182373047,\n",
              "  'step': 430,\n",
              "  'train_loss': 2.9494729042053223},\n",
              " {'decoder_loss': 3.8779373168945312,\n",
              "  'step': 431,\n",
              "  'train_loss': 2.3504416942596436},\n",
              " {'decoder_loss': 4.4484171867370605,\n",
              "  'step': 432,\n",
              "  'train_loss': 3.1441144943237305},\n",
              " {'decoder_loss': 4.426990032196045,\n",
              "  'step': 433,\n",
              "  'train_loss': 3.2321276664733887},\n",
              " {'decoder_loss': 3.6375415325164795,\n",
              "  'step': 434,\n",
              "  'train_loss': 2.321852207183838},\n",
              " {'decoder_loss': 4.119334697723389,\n",
              "  'step': 435,\n",
              "  'train_loss': 2.9624125957489014},\n",
              " {'decoder_loss': 4.134061813354492,\n",
              "  'step': 436,\n",
              "  'train_loss': 2.997314691543579},\n",
              " {'decoder_loss': 4.064202308654785,\n",
              "  'step': 437,\n",
              "  'train_loss': 3.0584771633148193},\n",
              " {'decoder_loss': 4.318699359893799,\n",
              "  'step': 438,\n",
              "  'train_loss': 3.251664400100708},\n",
              " {'decoder_loss': 3.7642128467559814,\n",
              "  'step': 439,\n",
              "  'train_loss': 2.6248555183410645},\n",
              " {'decoder_loss': 3.9931159019470215,\n",
              "  'step': 440,\n",
              "  'train_loss': 2.6784675121307373},\n",
              " {'decoder_loss': 4.081393241882324,\n",
              "  'step': 441,\n",
              "  'train_loss': 3.1827199459075928},\n",
              " {'decoder_loss': 4.482404708862305,\n",
              "  'step': 442,\n",
              "  'train_loss': 3.4274046421051025},\n",
              " {'decoder_loss': 4.068631649017334,\n",
              "  'step': 443,\n",
              "  'train_loss': 2.748774766921997},\n",
              " {'decoder_loss': 4.318976879119873,\n",
              "  'step': 444,\n",
              "  'train_loss': 3.015639066696167},\n",
              " {'decoder_loss': 3.9842095375061035,\n",
              "  'step': 445,\n",
              "  'train_loss': 2.3124921321868896},\n",
              " {'decoder_loss': 3.9197065830230713,\n",
              "  'step': 446,\n",
              "  'train_loss': 2.528468370437622},\n",
              " {'decoder_loss': 4.1073899269104,\n",
              "  'step': 447,\n",
              "  'train_loss': 2.759955644607544},\n",
              " {'decoder_loss': 4.057851791381836,\n",
              "  'step': 448,\n",
              "  'train_loss': 3.017775535583496},\n",
              " {'decoder_loss': 3.8237810134887695,\n",
              "  'step': 449,\n",
              "  'train_loss': 2.7338831424713135},\n",
              " {'decoder_loss': 3.9294021129608154,\n",
              "  'step': 450,\n",
              "  'train_loss': 2.5479719638824463},\n",
              " {'decoder_loss': 3.8932690620422363,\n",
              "  'step': 451,\n",
              "  'train_loss': 3.0035488605499268},\n",
              " {'decoder_loss': 3.8368124961853027,\n",
              "  'step': 452,\n",
              "  'train_loss': 2.749948024749756},\n",
              " {'decoder_loss': 4.319677829742432,\n",
              "  'step': 453,\n",
              "  'train_loss': 2.947051763534546},\n",
              " {'decoder_loss': 3.787296772003174,\n",
              "  'step': 454,\n",
              "  'train_loss': 2.705095052719116},\n",
              " {'decoder_loss': 4.005129337310791,\n",
              "  'step': 455,\n",
              "  'train_loss': 2.8353359699249268},\n",
              " {'decoder_loss': 4.114284038543701,\n",
              "  'step': 456,\n",
              "  'train_loss': 2.8330938816070557},\n",
              " {'decoder_loss': 3.868722915649414,\n",
              "  'step': 457,\n",
              "  'train_loss': 2.8454601764678955},\n",
              " {'decoder_loss': 3.9001283645629883,\n",
              "  'step': 458,\n",
              "  'train_loss': 2.8990800380706787},\n",
              " {'decoder_loss': 4.189449310302734,\n",
              "  'step': 459,\n",
              "  'train_loss': 3.0057215690612793},\n",
              " {'decoder_loss': 3.865346670150757,\n",
              "  'step': 460,\n",
              "  'train_loss': 2.788525104522705},\n",
              " {'decoder_loss': 3.9201395511627197,\n",
              "  'step': 461,\n",
              "  'train_loss': 2.8642382621765137},\n",
              " {'decoder_loss': 3.8695120811462402,\n",
              "  'step': 462,\n",
              "  'train_loss': 2.4930219650268555},\n",
              " {'decoder_loss': 3.975752830505371,\n",
              "  'step': 463,\n",
              "  'train_loss': 2.8232836723327637},\n",
              " {'decoder_loss': 3.828754425048828,\n",
              "  'step': 464,\n",
              "  'train_loss': 2.333615303039551},\n",
              " {'decoder_loss': 3.9198813438415527,\n",
              "  'step': 465,\n",
              "  'train_loss': 3.020937919616699},\n",
              " {'decoder_loss': 3.6314358711242676,\n",
              "  'step': 466,\n",
              "  'train_loss': 2.605088233947754},\n",
              " {'decoder_loss': 3.9468955993652344,\n",
              "  'step': 467,\n",
              "  'train_loss': 2.8535304069519043},\n",
              " {'decoder_loss': 3.84470534324646,\n",
              "  'step': 468,\n",
              "  'train_loss': 2.326979637145996},\n",
              " {'decoder_loss': 4.13462495803833,\n",
              "  'step': 469,\n",
              "  'train_loss': 2.9309465885162354},\n",
              " {'decoder_loss': 3.785922050476074,\n",
              "  'step': 470,\n",
              "  'train_loss': 2.7396841049194336},\n",
              " {'decoder_loss': 4.074984073638916,\n",
              "  'step': 471,\n",
              "  'train_loss': 2.854524612426758},\n",
              " {'decoder_loss': 3.9957199096679688,\n",
              "  'step': 472,\n",
              "  'train_loss': 2.5934345722198486},\n",
              " {'decoder_loss': 3.7601168155670166,\n",
              "  'step': 473,\n",
              "  'train_loss': 2.838395357131958},\n",
              " {'decoder_loss': 4.1658124923706055,\n",
              "  'step': 474,\n",
              "  'train_loss': 3.0323331356048584},\n",
              " {'decoder_loss': 3.8486874103546143,\n",
              "  'step': 475,\n",
              "  'train_loss': 2.9220962524414062},\n",
              " {'decoder_loss': 3.7455389499664307,\n",
              "  'step': 476,\n",
              "  'train_loss': 2.351978063583374},\n",
              " {'decoder_loss': 3.734192132949829,\n",
              "  'step': 477,\n",
              "  'train_loss': 2.776334285736084},\n",
              " {'decoder_loss': 4.463075160980225,\n",
              "  'step': 478,\n",
              "  'train_loss': 3.2497916221618652},\n",
              " {'decoder_loss': 3.861520290374756,\n",
              "  'step': 479,\n",
              "  'train_loss': 2.5530593395233154},\n",
              " {'decoder_loss': 3.8186216354370117,\n",
              "  'step': 480,\n",
              "  'train_loss': 2.92142391204834},\n",
              " {'decoder_loss': 3.916839838027954,\n",
              "  'step': 481,\n",
              "  'train_loss': 2.5836002826690674},\n",
              " {'decoder_loss': 3.8839375972747803,\n",
              "  'step': 482,\n",
              "  'train_loss': 2.7485616207122803},\n",
              " {'decoder_loss': 4.353286266326904,\n",
              "  'step': 483,\n",
              "  'train_loss': 2.943277597427368},\n",
              " {'decoder_loss': 4.1921772956848145,\n",
              "  'step': 484,\n",
              "  'train_loss': 3.0063769817352295},\n",
              " {'decoder_loss': 4.214732646942139,\n",
              "  'step': 485,\n",
              "  'train_loss': 3.044163227081299},\n",
              " {'decoder_loss': 3.940687417984009,\n",
              "  'step': 486,\n",
              "  'train_loss': 3.1055920124053955},\n",
              " {'decoder_loss': 3.6535823345184326,\n",
              "  'step': 487,\n",
              "  'train_loss': 2.9691267013549805},\n",
              " {'decoder_loss': 4.211651802062988,\n",
              "  'step': 488,\n",
              "  'train_loss': 2.9896674156188965},\n",
              " {'decoder_loss': 3.970423936843872,\n",
              "  'step': 489,\n",
              "  'train_loss': 2.9614498615264893},\n",
              " {'decoder_loss': 3.956724166870117,\n",
              "  'step': 490,\n",
              "  'train_loss': 2.658468723297119},\n",
              " {'decoder_loss': 3.6948821544647217,\n",
              "  'step': 491,\n",
              "  'train_loss': 2.6074931621551514},\n",
              " {'decoder_loss': 3.784677505493164,\n",
              "  'step': 492,\n",
              "  'train_loss': 2.8342325687408447},\n",
              " {'decoder_loss': 4.005359649658203,\n",
              "  'step': 493,\n",
              "  'train_loss': 2.8527321815490723},\n",
              " {'decoder_loss': 4.032052516937256,\n",
              "  'step': 494,\n",
              "  'train_loss': 2.821758985519409},\n",
              " {'decoder_loss': 3.9160614013671875,\n",
              "  'step': 495,\n",
              "  'train_loss': 2.3978230953216553},\n",
              " {'decoder_loss': 3.7912943363189697,\n",
              "  'step': 496,\n",
              "  'train_loss': 3.044813871383667},\n",
              " {'decoder_loss': 4.160706043243408,\n",
              "  'step': 497,\n",
              "  'train_loss': 2.9941892623901367},\n",
              " {'decoder_loss': 4.060948371887207,\n",
              "  'step': 498,\n",
              "  'train_loss': 2.995249032974243},\n",
              " {'decoder_loss': 4.093916416168213,\n",
              "  'step': 499,\n",
              "  'train_loss': 2.969594955444336},\n",
              " {'decoder_loss': 3.9327433109283447,\n",
              "  'step': 500,\n",
              "  'train_loss': 2.665285587310791,\n",
              "  'valid_loss': 2.8257901454911862},\n",
              " {'decoder_loss': 3.8854784965515137,\n",
              "  'step': 501,\n",
              "  'train_loss': 2.6911816596984863},\n",
              " {'decoder_loss': 4.249880790710449,\n",
              "  'step': 502,\n",
              "  'train_loss': 2.7552120685577393},\n",
              " {'decoder_loss': 4.2790446281433105,\n",
              "  'step': 503,\n",
              "  'train_loss': 3.1144943237304688},\n",
              " {'decoder_loss': 4.183161735534668,\n",
              "  'step': 504,\n",
              "  'train_loss': 2.713468313217163},\n",
              " {'decoder_loss': 4.437029838562012,\n",
              "  'step': 505,\n",
              "  'train_loss': 3.406010866165161},\n",
              " {'decoder_loss': 4.379916191101074,\n",
              "  'step': 506,\n",
              "  'train_loss': 3.1729929447174072},\n",
              " {'decoder_loss': 4.215329170227051,\n",
              "  'step': 507,\n",
              "  'train_loss': 2.83335280418396},\n",
              " {'decoder_loss': 3.805342674255371,\n",
              "  'step': 508,\n",
              "  'train_loss': 2.520599126815796},\n",
              " {'decoder_loss': 4.013965129852295,\n",
              "  'step': 509,\n",
              "  'train_loss': 2.877342939376831},\n",
              " {'decoder_loss': 3.7193918228149414,\n",
              "  'step': 510,\n",
              "  'train_loss': 2.596487283706665},\n",
              " {'decoder_loss': 4.252140045166016,\n",
              "  'step': 511,\n",
              "  'train_loss': 3.0466601848602295},\n",
              " {'decoder_loss': 4.021883010864258,\n",
              "  'step': 512,\n",
              "  'train_loss': 2.854607343673706},\n",
              " {'decoder_loss': 4.063989162445068,\n",
              "  'step': 513,\n",
              "  'train_loss': 3.041231870651245},\n",
              " {'decoder_loss': 4.1365180015563965,\n",
              "  'step': 514,\n",
              "  'train_loss': 2.886430263519287},\n",
              " {'decoder_loss': 3.838470220565796,\n",
              "  'step': 515,\n",
              "  'train_loss': 2.5918450355529785},\n",
              " {'decoder_loss': 3.9535088539123535,\n",
              "  'step': 516,\n",
              "  'train_loss': 2.7897109985351562},\n",
              " {'decoder_loss': 4.0054240226745605,\n",
              "  'step': 517,\n",
              "  'train_loss': 2.997781753540039},\n",
              " {'decoder_loss': 3.669478416442871,\n",
              "  'step': 518,\n",
              "  'train_loss': 2.589132308959961},\n",
              " {'decoder_loss': 4.032297611236572,\n",
              "  'step': 519,\n",
              "  'train_loss': 2.817739248275757},\n",
              " {'decoder_loss': 4.163212299346924,\n",
              "  'step': 520,\n",
              "  'train_loss': 2.5462400913238525},\n",
              " {'decoder_loss': 4.023849964141846,\n",
              "  'step': 521,\n",
              "  'train_loss': 3.138636350631714},\n",
              " {'decoder_loss': 3.900449275970459,\n",
              "  'step': 522,\n",
              "  'train_loss': 2.9454076290130615},\n",
              " {'decoder_loss': 3.7877883911132812,\n",
              "  'step': 523,\n",
              "  'train_loss': 2.458264112472534},\n",
              " {'decoder_loss': 3.874509572982788,\n",
              "  'step': 524,\n",
              "  'train_loss': 2.8579442501068115},\n",
              " {'decoder_loss': 3.869166135787964,\n",
              "  'step': 525,\n",
              "  'train_loss': 2.5059072971343994},\n",
              " {'decoder_loss': 3.849590539932251,\n",
              "  'step': 526,\n",
              "  'train_loss': 2.5133423805236816},\n",
              " {'decoder_loss': 3.8456220626831055,\n",
              "  'step': 527,\n",
              "  'train_loss': 2.924734592437744},\n",
              " {'decoder_loss': 4.069982051849365,\n",
              "  'step': 528,\n",
              "  'train_loss': 2.771696090698242},\n",
              " {'decoder_loss': 4.00530481338501,\n",
              "  'step': 529,\n",
              "  'train_loss': 2.7779386043548584},\n",
              " {'decoder_loss': 3.966883420944214,\n",
              "  'step': 530,\n",
              "  'train_loss': 2.5607457160949707},\n",
              " {'decoder_loss': 4.216823577880859,\n",
              "  'step': 531,\n",
              "  'train_loss': 2.6958842277526855},\n",
              " {'decoder_loss': 4.314499855041504,\n",
              "  'step': 532,\n",
              "  'train_loss': 2.914458751678467},\n",
              " {'decoder_loss': 4.0498247146606445,\n",
              "  'step': 533,\n",
              "  'train_loss': 2.830268144607544},\n",
              " {'decoder_loss': 4.014098167419434,\n",
              "  'step': 534,\n",
              "  'train_loss': 2.5402982234954834},\n",
              " {'decoder_loss': 4.1554975509643555,\n",
              "  'step': 535,\n",
              "  'train_loss': 2.769577741622925},\n",
              " {'decoder_loss': 4.073632717132568,\n",
              "  'step': 536,\n",
              "  'train_loss': 3.098022222518921},\n",
              " {'decoder_loss': 3.934417724609375,\n",
              "  'step': 537,\n",
              "  'train_loss': 2.4267947673797607},\n",
              " {'decoder_loss': 4.332930564880371,\n",
              "  'step': 538,\n",
              "  'train_loss': 3.2771925926208496},\n",
              " {'decoder_loss': 4.058019161224365,\n",
              "  'step': 539,\n",
              "  'train_loss': 2.9926040172576904},\n",
              " {'decoder_loss': 3.952375888824463,\n",
              "  'step': 540,\n",
              "  'train_loss': 2.8939507007598877},\n",
              " {'decoder_loss': 3.790649175643921,\n",
              "  'step': 541,\n",
              "  'train_loss': 3.037585973739624},\n",
              " {'decoder_loss': 4.186359405517578,\n",
              "  'step': 542,\n",
              "  'train_loss': 2.9660849571228027},\n",
              " {'decoder_loss': 4.217899322509766,\n",
              "  'step': 543,\n",
              "  'train_loss': 3.215677499771118},\n",
              " {'decoder_loss': 4.1366353034973145,\n",
              "  'step': 544,\n",
              "  'train_loss': 2.8516743183135986},\n",
              " {'decoder_loss': 3.973228693008423,\n",
              "  'step': 545,\n",
              "  'train_loss': 2.743666172027588},\n",
              " {'decoder_loss': 4.358132362365723,\n",
              "  'step': 546,\n",
              "  'train_loss': 2.8897719383239746},\n",
              " {'decoder_loss': 3.863499164581299,\n",
              "  'step': 547,\n",
              "  'train_loss': 2.879753828048706},\n",
              " {'decoder_loss': 4.074922561645508,\n",
              "  'step': 548,\n",
              "  'train_loss': 2.803388833999634},\n",
              " {'decoder_loss': 4.007996559143066,\n",
              "  'step': 549,\n",
              "  'train_loss': 3.3144350051879883},\n",
              " {'decoder_loss': 4.05747127532959,\n",
              "  'step': 550,\n",
              "  'train_loss': 2.607625961303711},\n",
              " {'decoder_loss': 4.000553607940674,\n",
              "  'step': 551,\n",
              "  'train_loss': 3.0896799564361572},\n",
              " {'decoder_loss': 3.929997682571411,\n",
              "  'step': 552,\n",
              "  'train_loss': 3.0117745399475098},\n",
              " {'decoder_loss': 4.343929290771484,\n",
              "  'step': 553,\n",
              "  'train_loss': 3.149968385696411},\n",
              " {'decoder_loss': 3.959714889526367,\n",
              "  'step': 554,\n",
              "  'train_loss': 2.9914989471435547},\n",
              " {'decoder_loss': 3.8254642486572266,\n",
              "  'step': 555,\n",
              "  'train_loss': 3.1083030700683594},\n",
              " {'decoder_loss': 4.05465841293335,\n",
              "  'step': 556,\n",
              "  'train_loss': 2.4600839614868164},\n",
              " {'decoder_loss': 4.275276184082031,\n",
              "  'step': 557,\n",
              "  'train_loss': 2.9331977367401123},\n",
              " {'decoder_loss': 4.038704872131348,\n",
              "  'step': 558,\n",
              "  'train_loss': 2.90936541557312},\n",
              " {'decoder_loss': 4.01126766204834,\n",
              "  'step': 559,\n",
              "  'train_loss': 2.8703014850616455},\n",
              " {'decoder_loss': 3.7713639736175537,\n",
              "  'step': 560,\n",
              "  'train_loss': 2.5713417530059814},\n",
              " {'decoder_loss': 4.059140205383301,\n",
              "  'step': 561,\n",
              "  'train_loss': 2.636429786682129},\n",
              " {'decoder_loss': 3.876363754272461,\n",
              "  'step': 562,\n",
              "  'train_loss': 2.556607484817505},\n",
              " {'decoder_loss': 4.047123908996582,\n",
              "  'step': 563,\n",
              "  'train_loss': 3.039949655532837},\n",
              " {'decoder_loss': 3.5271546840667725,\n",
              "  'step': 564,\n",
              "  'train_loss': 2.5842854976654053},\n",
              " {'decoder_loss': 4.227229118347168,\n",
              "  'step': 565,\n",
              "  'train_loss': 3.041147232055664},\n",
              " {'decoder_loss': 3.896277904510498,\n",
              "  'step': 566,\n",
              "  'train_loss': 2.8974030017852783},\n",
              " {'decoder_loss': 3.8472979068756104,\n",
              "  'step': 567,\n",
              "  'train_loss': 2.8583595752716064},\n",
              " {'decoder_loss': 4.086235523223877,\n",
              "  'step': 568,\n",
              "  'train_loss': 2.8192553520202637},\n",
              " {'decoder_loss': 3.7330079078674316,\n",
              "  'step': 569,\n",
              "  'train_loss': 2.57155704498291},\n",
              " {'decoder_loss': 4.0867695808410645,\n",
              "  'step': 570,\n",
              "  'train_loss': 2.6091527938842773},\n",
              " {'decoder_loss': 3.5782206058502197,\n",
              "  'step': 571,\n",
              "  'train_loss': 2.6226580142974854},\n",
              " {'decoder_loss': 4.114109516143799,\n",
              "  'step': 572,\n",
              "  'train_loss': 2.98796010017395},\n",
              " {'decoder_loss': 3.8100335597991943,\n",
              "  'step': 573,\n",
              "  'train_loss': 2.5454719066619873},\n",
              " {'decoder_loss': 4.233234882354736,\n",
              "  'step': 574,\n",
              "  'train_loss': 3.2311394214630127},\n",
              " {'decoder_loss': 4.253875255584717,\n",
              "  'step': 575,\n",
              "  'train_loss': 2.978645086288452},\n",
              " {'decoder_loss': 4.116480827331543,\n",
              "  'step': 576,\n",
              "  'train_loss': 2.905212640762329},\n",
              " {'decoder_loss': 3.667123794555664,\n",
              "  'step': 577,\n",
              "  'train_loss': 2.5584769248962402},\n",
              " {'decoder_loss': 3.941821336746216,\n",
              "  'step': 578,\n",
              "  'train_loss': 2.666806221008301},\n",
              " {'decoder_loss': 4.056541442871094,\n",
              "  'step': 579,\n",
              "  'train_loss': 2.915581226348877},\n",
              " {'decoder_loss': 3.8140063285827637,\n",
              "  'step': 580,\n",
              "  'train_loss': 2.8465735912323},\n",
              " {'decoder_loss': 3.7392706871032715,\n",
              "  'step': 581,\n",
              "  'train_loss': 2.809922218322754},\n",
              " {'decoder_loss': 3.9125142097473145,\n",
              "  'step': 582,\n",
              "  'train_loss': 3.0585885047912598},\n",
              " {'decoder_loss': 4.322198390960693,\n",
              "  'step': 583,\n",
              "  'train_loss': 2.7935080528259277},\n",
              " {'decoder_loss': 3.8499302864074707,\n",
              "  'step': 584,\n",
              "  'train_loss': 2.7998993396759033},\n",
              " {'decoder_loss': 4.225942611694336,\n",
              "  'step': 585,\n",
              "  'train_loss': 2.957642078399658},\n",
              " {'decoder_loss': 3.801787853240967,\n",
              "  'step': 586,\n",
              "  'train_loss': 2.6433608531951904},\n",
              " {'decoder_loss': 3.7681825160980225,\n",
              "  'step': 587,\n",
              "  'train_loss': 2.5739574432373047},\n",
              " {'decoder_loss': 4.29210901260376,\n",
              "  'step': 588,\n",
              "  'train_loss': 3.070128917694092},\n",
              " {'decoder_loss': 3.8899269104003906,\n",
              "  'step': 589,\n",
              "  'train_loss': 2.8557395935058594},\n",
              " {'decoder_loss': 3.76550030708313,\n",
              "  'step': 590,\n",
              "  'train_loss': 2.9222257137298584},\n",
              " {'decoder_loss': 3.839747428894043,\n",
              "  'step': 591,\n",
              "  'train_loss': 2.572169303894043},\n",
              " {'decoder_loss': 4.335397243499756,\n",
              "  'step': 592,\n",
              "  'train_loss': 3.2232513427734375},\n",
              " {'decoder_loss': 3.9719228744506836,\n",
              "  'step': 593,\n",
              "  'train_loss': 2.6435937881469727},\n",
              " {'decoder_loss': 4.000191688537598,\n",
              "  'step': 594,\n",
              "  'train_loss': 2.6341793537139893},\n",
              " {'decoder_loss': 4.244763374328613,\n",
              "  'step': 595,\n",
              "  'train_loss': 3.253079414367676},\n",
              " {'decoder_loss': 4.015101909637451,\n",
              "  'step': 596,\n",
              "  'train_loss': 2.805980682373047},\n",
              " {'decoder_loss': 4.212180137634277,\n",
              "  'step': 597,\n",
              "  'train_loss': 3.2579801082611084},\n",
              " {'decoder_loss': 4.1410651206970215,\n",
              "  'step': 598,\n",
              "  'train_loss': 2.5938150882720947},\n",
              " {'decoder_loss': 4.320493698120117,\n",
              "  'step': 599,\n",
              "  'train_loss': 3.172481060028076},\n",
              " {'decoder_loss': 4.133651256561279,\n",
              "  'step': 600,\n",
              "  'train_loss': 2.920443534851074},\n",
              " {'decoder_loss': 3.9466583728790283,\n",
              "  'step': 601,\n",
              "  'train_loss': 2.6046364307403564},\n",
              " {'decoder_loss': 4.065786838531494,\n",
              "  'step': 602,\n",
              "  'train_loss': 3.0291874408721924},\n",
              " {'decoder_loss': 3.9432480335235596,\n",
              "  'step': 603,\n",
              "  'train_loss': 2.6295526027679443},\n",
              " {'decoder_loss': 4.138298988342285,\n",
              "  'step': 604,\n",
              "  'train_loss': 2.905313730239868},\n",
              " {'decoder_loss': 3.862093925476074,\n",
              "  'step': 605,\n",
              "  'train_loss': 2.6668546199798584},\n",
              " {'decoder_loss': 3.6324713230133057,\n",
              "  'step': 606,\n",
              "  'train_loss': 2.4461376667022705},\n",
              " {'decoder_loss': 4.0582733154296875,\n",
              "  'step': 607,\n",
              "  'train_loss': 2.8438243865966797},\n",
              " {'decoder_loss': 4.1160149574279785,\n",
              "  'step': 608,\n",
              "  'train_loss': 2.703273057937622},\n",
              " {'decoder_loss': 4.130306720733643,\n",
              "  'step': 609,\n",
              "  'train_loss': 2.8831067085266113},\n",
              " {'decoder_loss': 3.796868324279785,\n",
              "  'step': 610,\n",
              "  'train_loss': 2.538482666015625},\n",
              " {'decoder_loss': 4.115458011627197,\n",
              "  'step': 611,\n",
              "  'train_loss': 3.0200119018554688},\n",
              " {'decoder_loss': 3.9485104084014893,\n",
              "  'step': 612,\n",
              "  'train_loss': 2.6622889041900635},\n",
              " {'decoder_loss': 3.9286787509918213,\n",
              "  'step': 613,\n",
              "  'train_loss': 2.816880464553833},\n",
              " {'decoder_loss': 3.85927152633667,\n",
              "  'step': 614,\n",
              "  'train_loss': 2.931483268737793},\n",
              " {'decoder_loss': 4.183497905731201,\n",
              "  'step': 615,\n",
              "  'train_loss': 2.833552122116089},\n",
              " {'decoder_loss': 4.076922416687012,\n",
              "  'step': 616,\n",
              "  'train_loss': 3.05619478225708},\n",
              " {'decoder_loss': 4.084578514099121,\n",
              "  'step': 617,\n",
              "  'train_loss': 2.9282703399658203},\n",
              " {'decoder_loss': 4.11941385269165,\n",
              "  'step': 618,\n",
              "  'train_loss': 3.365095376968384},\n",
              " {'decoder_loss': 3.603550434112549,\n",
              "  'step': 619,\n",
              "  'train_loss': 2.6979243755340576},\n",
              " {'decoder_loss': 3.9351274967193604,\n",
              "  'step': 620,\n",
              "  'train_loss': 2.7997357845306396},\n",
              " {'decoder_loss': 4.028997898101807,\n",
              "  'step': 621,\n",
              "  'train_loss': 2.993542194366455},\n",
              " {'decoder_loss': 4.257194995880127,\n",
              "  'step': 622,\n",
              "  'train_loss': 3.024379253387451},\n",
              " {'decoder_loss': 4.1093950271606445,\n",
              "  'step': 623,\n",
              "  'train_loss': 3.096808433532715},\n",
              " {'decoder_loss': 3.9953746795654297,\n",
              "  'step': 624,\n",
              "  'train_loss': 2.670229434967041},\n",
              " {'decoder_loss': 4.370121955871582,\n",
              "  'step': 625,\n",
              "  'train_loss': 3.5306410789489746},\n",
              " {'decoder_loss': 3.83370304107666,\n",
              "  'step': 626,\n",
              "  'train_loss': 3.0775856971740723},\n",
              " {'decoder_loss': 3.8736701011657715,\n",
              "  'step': 627,\n",
              "  'train_loss': 2.6511166095733643},\n",
              " {'decoder_loss': 4.28211784362793,\n",
              "  'step': 628,\n",
              "  'train_loss': 3.0158960819244385},\n",
              " {'decoder_loss': 3.88254976272583,\n",
              "  'step': 629,\n",
              "  'train_loss': 2.8486838340759277},\n",
              " {'decoder_loss': 3.918501853942871,\n",
              "  'step': 630,\n",
              "  'train_loss': 3.1499762535095215},\n",
              " {'decoder_loss': 3.8635506629943848,\n",
              "  'step': 631,\n",
              "  'train_loss': 2.5751819610595703},\n",
              " {'decoder_loss': 3.9124035835266113,\n",
              "  'step': 632,\n",
              "  'train_loss': 2.782850980758667},\n",
              " {'decoder_loss': 3.9197771549224854,\n",
              "  'step': 633,\n",
              "  'train_loss': 2.566208600997925},\n",
              " {'decoder_loss': 3.8460211753845215,\n",
              "  'step': 634,\n",
              "  'train_loss': 2.785753011703491},\n",
              " {'decoder_loss': 3.9317615032196045,\n",
              "  'step': 635,\n",
              "  'train_loss': 2.8492484092712402},\n",
              " {'decoder_loss': 4.159517288208008,\n",
              "  'step': 636,\n",
              "  'train_loss': 3.208974599838257},\n",
              " {'decoder_loss': 4.089935779571533,\n",
              "  'step': 637,\n",
              "  'train_loss': 3.0430848598480225},\n",
              " {'decoder_loss': 3.925396680831909,\n",
              "  'step': 638,\n",
              "  'train_loss': 2.8169384002685547},\n",
              " {'decoder_loss': 4.175478458404541,\n",
              "  'step': 639,\n",
              "  'train_loss': 3.181511878967285},\n",
              " {'decoder_loss': 4.003679275512695,\n",
              "  'step': 640,\n",
              "  'train_loss': 2.049421548843384},\n",
              " {'decoder_loss': 3.969957113265991,\n",
              "  'step': 641,\n",
              "  'train_loss': 2.5316710472106934},\n",
              " {'decoder_loss': 4.14487886428833,\n",
              "  'step': 642,\n",
              "  'train_loss': 2.5091733932495117},\n",
              " {'decoder_loss': 3.956780195236206,\n",
              "  'step': 643,\n",
              "  'train_loss': 2.535186767578125},\n",
              " {'decoder_loss': 3.9824888706207275,\n",
              "  'step': 644,\n",
              "  'train_loss': 3.025132656097412},\n",
              " {'decoder_loss': 3.706928253173828,\n",
              "  'step': 645,\n",
              "  'train_loss': 2.7174339294433594},\n",
              " {'decoder_loss': 3.7453207969665527,\n",
              "  'step': 646,\n",
              "  'train_loss': 2.621311902999878},\n",
              " {'decoder_loss': 4.21678352355957,\n",
              "  'step': 647,\n",
              "  'train_loss': 3.010378360748291},\n",
              " {'decoder_loss': 4.051718711853027,\n",
              "  'step': 648,\n",
              "  'train_loss': 2.562781810760498},\n",
              " {'decoder_loss': 3.724123954772949,\n",
              "  'step': 649,\n",
              "  'train_loss': 2.677321672439575},\n",
              " {'decoder_loss': 3.5659191608428955,\n",
              "  'step': 650,\n",
              "  'train_loss': 2.446402072906494},\n",
              " {'decoder_loss': 4.050358772277832,\n",
              "  'step': 651,\n",
              "  'train_loss': 3.0789592266082764},\n",
              " {'decoder_loss': 3.9627761840820312,\n",
              "  'step': 652,\n",
              "  'train_loss': 2.8792130947113037},\n",
              " {'decoder_loss': 3.921976327896118,\n",
              "  'step': 653,\n",
              "  'train_loss': 2.936208486557007},\n",
              " {'decoder_loss': 4.150721549987793,\n",
              "  'step': 654,\n",
              "  'train_loss': 2.8559398651123047},\n",
              " {'decoder_loss': 4.031625270843506,\n",
              "  'step': 655,\n",
              "  'train_loss': 3.0936684608459473},\n",
              " {'decoder_loss': 3.8534114360809326,\n",
              "  'step': 656,\n",
              "  'train_loss': 2.8117613792419434},\n",
              " {'decoder_loss': 4.021310806274414,\n",
              "  'step': 657,\n",
              "  'train_loss': 2.7932779788970947},\n",
              " {'decoder_loss': 4.130270004272461,\n",
              "  'step': 658,\n",
              "  'train_loss': 2.9048686027526855},\n",
              " {'decoder_loss': 3.9894156455993652,\n",
              "  'step': 659,\n",
              "  'train_loss': 2.9990665912628174},\n",
              " {'decoder_loss': 4.11293363571167,\n",
              "  'step': 660,\n",
              "  'train_loss': 2.8967373371124268},\n",
              " {'decoder_loss': 3.927029848098755,\n",
              "  'step': 661,\n",
              "  'train_loss': 2.38397216796875},\n",
              " {'decoder_loss': 3.7628490924835205,\n",
              "  'step': 662,\n",
              "  'train_loss': 2.611978530883789},\n",
              " {'decoder_loss': 4.304269790649414,\n",
              "  'step': 663,\n",
              "  'train_loss': 2.884056568145752},\n",
              " {'decoder_loss': 3.859161853790283,\n",
              "  'step': 664,\n",
              "  'train_loss': 2.4171009063720703},\n",
              " {'decoder_loss': 3.741792678833008,\n",
              "  'step': 665,\n",
              "  'train_loss': 2.8291070461273193},\n",
              " {'decoder_loss': 4.235950469970703,\n",
              "  'step': 666,\n",
              "  'train_loss': 3.361527442932129},\n",
              " {'decoder_loss': 4.065389633178711,\n",
              "  'step': 667,\n",
              "  'train_loss': 3.024271011352539},\n",
              " {'decoder_loss': 4.232849597930908,\n",
              "  'step': 668,\n",
              "  'train_loss': 2.7541329860687256},\n",
              " {'decoder_loss': 4.23481559753418,\n",
              "  'step': 669,\n",
              "  'train_loss': 2.968614101409912},\n",
              " {'decoder_loss': 4.085148811340332,\n",
              "  'step': 670,\n",
              "  'train_loss': 2.8260157108306885},\n",
              " {'decoder_loss': 4.083740234375,\n",
              "  'step': 671,\n",
              "  'train_loss': 2.732712984085083},\n",
              " {'decoder_loss': 4.288727760314941,\n",
              "  'step': 672,\n",
              "  'train_loss': 2.5607657432556152},\n",
              " {'decoder_loss': 4.281029224395752,\n",
              "  'step': 673,\n",
              "  'train_loss': 3.0512070655822754},\n",
              " {'decoder_loss': 3.9349329471588135,\n",
              "  'step': 674,\n",
              "  'train_loss': 2.9055850505828857},\n",
              " {'decoder_loss': 4.103794574737549,\n",
              "  'step': 675,\n",
              "  'train_loss': 2.790257692337036},\n",
              " {'decoder_loss': 4.210806846618652,\n",
              "  'step': 676,\n",
              "  'train_loss': 3.1201932430267334},\n",
              " {'decoder_loss': 4.294961452484131,\n",
              "  'step': 677,\n",
              "  'train_loss': 2.6973063945770264},\n",
              " {'decoder_loss': 4.018770694732666,\n",
              "  'step': 678,\n",
              "  'train_loss': 2.780647039413452},\n",
              " {'decoder_loss': 3.7316339015960693,\n",
              "  'step': 679,\n",
              "  'train_loss': 2.676328420639038},\n",
              " {'decoder_loss': 3.971216917037964,\n",
              "  'step': 680,\n",
              "  'train_loss': 2.8498213291168213},\n",
              " {'decoder_loss': 3.7825491428375244,\n",
              "  'step': 681,\n",
              "  'train_loss': 2.78959059715271},\n",
              " {'decoder_loss': 4.245455741882324,\n",
              "  'step': 682,\n",
              "  'train_loss': 2.8666281700134277},\n",
              " {'decoder_loss': 4.103235244750977,\n",
              "  'step': 683,\n",
              "  'train_loss': 3.3199033737182617},\n",
              " {'decoder_loss': 3.76108717918396,\n",
              "  'step': 684,\n",
              "  'train_loss': 2.184211015701294},\n",
              " {'decoder_loss': 3.988588333129883,\n",
              "  'step': 685,\n",
              "  'train_loss': 2.721564292907715},\n",
              " {'decoder_loss': 4.1055989265441895,\n",
              "  'step': 686,\n",
              "  'train_loss': 3.1110575199127197},\n",
              " {'decoder_loss': 3.9510347843170166,\n",
              "  'step': 687,\n",
              "  'train_loss': 3.301222562789917},\n",
              " {'decoder_loss': 3.9914047718048096,\n",
              "  'step': 688,\n",
              "  'train_loss': 2.8103466033935547},\n",
              " {'decoder_loss': 4.183256149291992,\n",
              "  'step': 689,\n",
              "  'train_loss': 3.117845058441162},\n",
              " {'decoder_loss': 4.224051475524902,\n",
              "  'step': 690,\n",
              "  'train_loss': 2.8307693004608154},\n",
              " {'decoder_loss': 4.046093940734863,\n",
              "  'step': 691,\n",
              "  'train_loss': 3.102665662765503},\n",
              " {'decoder_loss': 4.2837629318237305,\n",
              "  'step': 692,\n",
              "  'train_loss': 2.6041274070739746},\n",
              " {'decoder_loss': 3.9206485748291016,\n",
              "  'step': 693,\n",
              "  'train_loss': 2.8617613315582275},\n",
              " {'decoder_loss': 3.839406728744507,\n",
              "  'step': 694,\n",
              "  'train_loss': 2.69075345993042},\n",
              " {'decoder_loss': 3.9209682941436768,\n",
              "  'step': 695,\n",
              "  'train_loss': 2.483733892440796},\n",
              " {'decoder_loss': 4.099237442016602,\n",
              "  'step': 696,\n",
              "  'train_loss': 2.7360928058624268},\n",
              " {'decoder_loss': 3.7436156272888184,\n",
              "  'step': 697,\n",
              "  'train_loss': 2.681417942047119},\n",
              " {'decoder_loss': 4.031423091888428,\n",
              "  'step': 698,\n",
              "  'train_loss': 2.732126474380493},\n",
              " {'decoder_loss': 4.030348777770996,\n",
              "  'step': 699,\n",
              "  'train_loss': 3.0529990196228027},\n",
              " {'decoder_loss': 3.957646608352661,\n",
              "  'step': 700,\n",
              "  'train_loss': 2.9901609420776367},\n",
              " {'decoder_loss': 3.8911774158477783,\n",
              "  'step': 701,\n",
              "  'train_loss': 2.968463182449341},\n",
              " {'decoder_loss': 3.831810712814331,\n",
              "  'step': 702,\n",
              "  'train_loss': 2.6507792472839355},\n",
              " {'decoder_loss': 3.8327300548553467,\n",
              "  'step': 703,\n",
              "  'train_loss': 2.5821588039398193},\n",
              " {'decoder_loss': 4.105072975158691,\n",
              "  'step': 704,\n",
              "  'train_loss': 3.0054571628570557},\n",
              " {'decoder_loss': 3.591526508331299,\n",
              "  'step': 705,\n",
              "  'train_loss': 2.533308982849121},\n",
              " {'decoder_loss': 3.8074347972869873,\n",
              "  'step': 706,\n",
              "  'train_loss': 2.6983866691589355},\n",
              " {'decoder_loss': 4.207211971282959,\n",
              "  'step': 707,\n",
              "  'train_loss': 3.020177125930786},\n",
              " {'decoder_loss': 4.010804653167725,\n",
              "  'step': 708,\n",
              "  'train_loss': 2.5516605377197266},\n",
              " {'decoder_loss': 3.948003053665161,\n",
              "  'step': 709,\n",
              "  'train_loss': 2.6625330448150635},\n",
              " {'decoder_loss': 4.128579616546631,\n",
              "  'step': 710,\n",
              "  'train_loss': 2.5979831218719482},\n",
              " {'decoder_loss': 4.130411148071289,\n",
              "  'step': 711,\n",
              "  'train_loss': 2.9966824054718018},\n",
              " {'decoder_loss': 4.102951526641846,\n",
              "  'step': 712,\n",
              "  'train_loss': 2.9429843425750732},\n",
              " {'decoder_loss': 4.036689758300781,\n",
              "  'step': 713,\n",
              "  'train_loss': 3.1303532123565674},\n",
              " {'decoder_loss': 4.338154315948486,\n",
              "  'step': 714,\n",
              "  'train_loss': 3.0704269409179688},\n",
              " {'decoder_loss': 4.2414231300354,\n",
              "  'step': 715,\n",
              "  'train_loss': 3.1362955570220947},\n",
              " {'decoder_loss': 3.936764717102051,\n",
              "  'step': 716,\n",
              "  'train_loss': 2.9151806831359863},\n",
              " {'decoder_loss': 3.963637113571167,\n",
              "  'step': 717,\n",
              "  'train_loss': 2.386868953704834},\n",
              " {'decoder_loss': 3.945896863937378,\n",
              "  'step': 718,\n",
              "  'train_loss': 2.7562172412872314},\n",
              " {'decoder_loss': 3.924203872680664,\n",
              "  'step': 719,\n",
              "  'train_loss': 2.719943046569824},\n",
              " {'decoder_loss': 4.16887903213501,\n",
              "  'step': 720,\n",
              "  'train_loss': 3.0184295177459717},\n",
              " {'decoder_loss': 3.7925937175750732,\n",
              "  'step': 721,\n",
              "  'train_loss': 3.04325008392334},\n",
              " {'decoder_loss': 3.6127374172210693,\n",
              "  'step': 722,\n",
              "  'train_loss': 2.4234626293182373},\n",
              " {'decoder_loss': 3.9962549209594727,\n",
              "  'step': 723,\n",
              "  'train_loss': 2.8445920944213867},\n",
              " {'decoder_loss': 3.9939823150634766,\n",
              "  'step': 724,\n",
              "  'train_loss': 2.7929749488830566},\n",
              " {'decoder_loss': 3.6891703605651855,\n",
              "  'step': 725,\n",
              "  'train_loss': 2.4449145793914795},\n",
              " {'decoder_loss': 4.123432159423828,\n",
              "  'step': 726,\n",
              "  'train_loss': 2.5527219772338867},\n",
              " {'decoder_loss': 4.024004936218262,\n",
              "  'step': 727,\n",
              "  'train_loss': 2.6318724155426025},\n",
              " {'decoder_loss': 4.190732955932617,\n",
              "  'step': 728,\n",
              "  'train_loss': 2.730687379837036},\n",
              " {'decoder_loss': 4.008950233459473,\n",
              "  'step': 729,\n",
              "  'train_loss': 2.8378829956054688},\n",
              " {'decoder_loss': 3.9384610652923584,\n",
              "  'step': 730,\n",
              "  'train_loss': 2.847743511199951},\n",
              " {'decoder_loss': 3.7523858547210693,\n",
              "  'step': 731,\n",
              "  'train_loss': 2.7482011318206787},\n",
              " {'decoder_loss': 3.970543146133423,\n",
              "  'step': 732,\n",
              "  'train_loss': 2.59126353263855},\n",
              " {'decoder_loss': 4.093922138214111,\n",
              "  'step': 733,\n",
              "  'train_loss': 2.9039571285247803},\n",
              " {'decoder_loss': 4.090019226074219,\n",
              "  'step': 734,\n",
              "  'train_loss': 3.014854907989502},\n",
              " {'decoder_loss': 4.108753204345703,\n",
              "  'step': 735,\n",
              "  'train_loss': 3.1771461963653564},\n",
              " {'decoder_loss': 4.106053829193115,\n",
              "  'step': 736,\n",
              "  'train_loss': 2.802067756652832},\n",
              " {'decoder_loss': 3.746466636657715,\n",
              "  'step': 737,\n",
              "  'train_loss': 2.7307217121124268},\n",
              " {'decoder_loss': 3.6869592666625977,\n",
              "  'step': 738,\n",
              "  'train_loss': 2.455843925476074},\n",
              " {'decoder_loss': 3.7624242305755615,\n",
              "  'step': 739,\n",
              "  'train_loss': 2.7242374420166016},\n",
              " {'decoder_loss': 3.8215527534484863,\n",
              "  'step': 740,\n",
              "  'train_loss': 3.002647638320923},\n",
              " {'decoder_loss': 4.129760265350342,\n",
              "  'step': 741,\n",
              "  'train_loss': 2.9250292778015137},\n",
              " {'decoder_loss': 3.9425079822540283,\n",
              "  'step': 742,\n",
              "  'train_loss': 2.9069504737854004},\n",
              " {'decoder_loss': 3.7676050662994385,\n",
              "  'step': 743,\n",
              "  'train_loss': 2.3771636486053467},\n",
              " {'decoder_loss': 3.917670249938965,\n",
              "  'step': 744,\n",
              "  'train_loss': 2.686678886413574},\n",
              " {'decoder_loss': 4.306328296661377,\n",
              "  'step': 745,\n",
              "  'train_loss': 2.967072010040283},\n",
              " {'decoder_loss': 4.246204853057861,\n",
              "  'step': 746,\n",
              "  'train_loss': 3.1702663898468018},\n",
              " {'decoder_loss': 4.44526481628418,\n",
              "  'step': 747,\n",
              "  'train_loss': 3.2165050506591797},\n",
              " {'decoder_loss': 4.473298072814941,\n",
              "  'step': 748,\n",
              "  'train_loss': 2.9052183628082275},\n",
              " {'decoder_loss': 3.9579994678497314,\n",
              "  'step': 749,\n",
              "  'train_loss': 3.0912699699401855},\n",
              " {'decoder_loss': 4.160921573638916,\n",
              "  'step': 750,\n",
              "  'train_loss': 3.196383237838745},\n",
              " {'decoder_loss': 3.9981226921081543,\n",
              "  'step': 751,\n",
              "  'train_loss': 2.976022720336914},\n",
              " {'decoder_loss': 3.901477813720703,\n",
              "  'step': 752,\n",
              "  'train_loss': 2.9991555213928223},\n",
              " {'decoder_loss': 3.6451709270477295,\n",
              "  'step': 753,\n",
              "  'train_loss': 2.601245641708374},\n",
              " {'decoder_loss': 4.248461723327637,\n",
              "  'step': 754,\n",
              "  'train_loss': 3.106999158859253},\n",
              " {'decoder_loss': 4.003317356109619,\n",
              "  'step': 755,\n",
              "  'train_loss': 3.2284255027770996},\n",
              " {'decoder_loss': 3.8921444416046143,\n",
              "  'step': 756,\n",
              "  'train_loss': 2.6887009143829346},\n",
              " {'decoder_loss': 4.120646953582764,\n",
              "  'step': 757,\n",
              "  'train_loss': 2.935457229614258},\n",
              " {'decoder_loss': 4.230661392211914,\n",
              "  'step': 758,\n",
              "  'train_loss': 3.130756139755249},\n",
              " {'decoder_loss': 3.924684762954712,\n",
              "  'step': 759,\n",
              "  'train_loss': 2.6173794269561768},\n",
              " {'decoder_loss': 4.048747539520264,\n",
              "  'step': 760,\n",
              "  'train_loss': 2.741332769393921},\n",
              " {'decoder_loss': 4.016638278961182,\n",
              "  'step': 761,\n",
              "  'train_loss': 2.730543375015259},\n",
              " {'decoder_loss': 3.9830214977264404,\n",
              "  'step': 762,\n",
              "  'train_loss': 2.9459142684936523},\n",
              " {'decoder_loss': 3.949929714202881,\n",
              "  'step': 763,\n",
              "  'train_loss': 2.755878210067749},\n",
              " {'decoder_loss': 3.8399815559387207,\n",
              "  'step': 764,\n",
              "  'train_loss': 2.6144752502441406},\n",
              " {'decoder_loss': 3.974574089050293,\n",
              "  'step': 765,\n",
              "  'train_loss': 2.8313302993774414},\n",
              " {'decoder_loss': 3.8920984268188477,\n",
              "  'step': 766,\n",
              "  'train_loss': 2.89448881149292},\n",
              " {'decoder_loss': 4.191454887390137,\n",
              "  'step': 767,\n",
              "  'train_loss': 2.6476752758026123},\n",
              " {'decoder_loss': 4.280914783477783,\n",
              "  'step': 768,\n",
              "  'train_loss': 2.505188226699829},\n",
              " {'decoder_loss': 3.8248071670532227,\n",
              "  'step': 769,\n",
              "  'train_loss': 2.202557325363159},\n",
              " {'decoder_loss': 4.113304138183594,\n",
              "  'step': 770,\n",
              "  'train_loss': 3.3001785278320312},\n",
              " {'decoder_loss': 3.8517496585845947,\n",
              "  'step': 771,\n",
              "  'train_loss': 2.7403361797332764},\n",
              " {'decoder_loss': 3.725449323654175,\n",
              "  'step': 772,\n",
              "  'train_loss': 2.7007086277008057},\n",
              " {'decoder_loss': 3.7176716327667236,\n",
              "  'step': 773,\n",
              "  'train_loss': 2.8788537979125977},\n",
              " {'decoder_loss': 3.8780431747436523,\n",
              "  'step': 774,\n",
              "  'train_loss': 2.3683736324310303},\n",
              " {'decoder_loss': 3.8010685443878174,\n",
              "  'step': 775,\n",
              "  'train_loss': 2.797656536102295},\n",
              " {'decoder_loss': 3.7005856037139893,\n",
              "  'step': 776,\n",
              "  'train_loss': 2.739372730255127},\n",
              " {'decoder_loss': 3.8634374141693115,\n",
              "  'step': 777,\n",
              "  'train_loss': 2.4694442749023438},\n",
              " {'decoder_loss': 3.779710054397583,\n",
              "  'step': 778,\n",
              "  'train_loss': 2.872342824935913},\n",
              " {'decoder_loss': 4.261262893676758,\n",
              "  'step': 779,\n",
              "  'train_loss': 3.150585889816284},\n",
              " {'decoder_loss': 3.7543299198150635,\n",
              "  'step': 780,\n",
              "  'train_loss': 2.882181167602539},\n",
              " {'decoder_loss': 3.7465643882751465,\n",
              "  'step': 781,\n",
              "  'train_loss': 2.3192222118377686},\n",
              " {'decoder_loss': 4.106287002563477,\n",
              "  'step': 782,\n",
              "  'train_loss': 3.100890874862671},\n",
              " {'decoder_loss': 4.336194038391113,\n",
              "  'step': 783,\n",
              "  'train_loss': 2.8281214237213135},\n",
              " {'decoder_loss': 3.842217445373535,\n",
              "  'step': 784,\n",
              "  'train_loss': 2.39223051071167},\n",
              " {'decoder_loss': 3.8881733417510986,\n",
              "  'step': 785,\n",
              "  'train_loss': 2.6297481060028076},\n",
              " {'decoder_loss': 4.098844528198242,\n",
              "  'step': 786,\n",
              "  'train_loss': 2.995800495147705},\n",
              " {'decoder_loss': 3.479060649871826,\n",
              "  'step': 787,\n",
              "  'train_loss': 2.6490964889526367},\n",
              " {'decoder_loss': 4.020685195922852,\n",
              "  'step': 788,\n",
              "  'train_loss': 3.088867425918579},\n",
              " {'decoder_loss': 4.044284343719482,\n",
              "  'step': 789,\n",
              "  'train_loss': 2.7581350803375244},\n",
              " {'decoder_loss': 3.8115720748901367,\n",
              "  'step': 790,\n",
              "  'train_loss': 3.0001120567321777},\n",
              " {'decoder_loss': 4.090169429779053,\n",
              "  'step': 791,\n",
              "  'train_loss': 2.7545101642608643},\n",
              " {'decoder_loss': 3.8967878818511963,\n",
              "  'step': 792,\n",
              "  'train_loss': 2.971445083618164},\n",
              " {'decoder_loss': 4.153049945831299,\n",
              "  'step': 793,\n",
              "  'train_loss': 2.4039018154144287},\n",
              " {'decoder_loss': 3.9845364093780518,\n",
              "  'step': 794,\n",
              "  'train_loss': 2.7565205097198486},\n",
              " {'decoder_loss': 3.8978397846221924,\n",
              "  'step': 795,\n",
              "  'train_loss': 2.53696608543396},\n",
              " {'decoder_loss': 4.27109432220459,\n",
              "  'step': 796,\n",
              "  'train_loss': 3.1431236267089844},\n",
              " {'decoder_loss': 4.317498207092285,\n",
              "  'step': 797,\n",
              "  'train_loss': 3.2415125370025635},\n",
              " {'decoder_loss': 3.9135923385620117,\n",
              "  'step': 798,\n",
              "  'train_loss': 2.910306453704834},\n",
              " {'decoder_loss': 4.216901779174805,\n",
              "  'step': 799,\n",
              "  'train_loss': 2.8219518661499023},\n",
              " {'decoder_loss': 3.9003682136535645,\n",
              "  'step': 800,\n",
              "  'train_loss': 3.041958808898926},\n",
              " {'decoder_loss': 3.694972038269043,\n",
              "  'step': 801,\n",
              "  'train_loss': 2.830885410308838},\n",
              " {'decoder_loss': 3.911623001098633,\n",
              "  'step': 802,\n",
              "  'train_loss': 2.6655404567718506},\n",
              " {'decoder_loss': 4.141160488128662,\n",
              "  'step': 803,\n",
              "  'train_loss': 2.984292984008789},\n",
              " {'decoder_loss': 4.015637397766113,\n",
              "  'step': 804,\n",
              "  'train_loss': 2.795698404312134},\n",
              " {'decoder_loss': 4.26133394241333,\n",
              "  'step': 805,\n",
              "  'train_loss': 2.9788239002227783},\n",
              " {'decoder_loss': 3.825711727142334,\n",
              "  'step': 806,\n",
              "  'train_loss': 2.717136859893799},\n",
              " {'decoder_loss': 4.130895614624023,\n",
              "  'step': 807,\n",
              "  'train_loss': 2.706435441970825},\n",
              " {'decoder_loss': 3.877286195755005,\n",
              "  'step': 808,\n",
              "  'train_loss': 2.9793179035186768},\n",
              " {'decoder_loss': 3.5545284748077393,\n",
              "  'step': 809,\n",
              "  'train_loss': 2.442143440246582},\n",
              " {'decoder_loss': 4.200040340423584,\n",
              "  'step': 810,\n",
              "  'train_loss': 3.064279556274414},\n",
              " {'decoder_loss': 3.865614414215088,\n",
              "  'step': 811,\n",
              "  'train_loss': 2.6602976322174072},\n",
              " {'decoder_loss': 3.8900198936462402,\n",
              "  'step': 812,\n",
              "  'train_loss': 2.5604329109191895},\n",
              " {'decoder_loss': 3.745971202850342,\n",
              "  'step': 813,\n",
              "  'train_loss': 3.086819648742676},\n",
              " {'decoder_loss': 3.959475517272949,\n",
              "  'step': 814,\n",
              "  'train_loss': 2.7755842208862305},\n",
              " {'decoder_loss': 4.1426825523376465,\n",
              "  'step': 815,\n",
              "  'train_loss': 2.882179021835327},\n",
              " {'decoder_loss': 4.101704120635986,\n",
              "  'step': 816,\n",
              "  'train_loss': 3.067373037338257},\n",
              " {'decoder_loss': 3.833324909210205,\n",
              "  'step': 817,\n",
              "  'train_loss': 2.738542079925537},\n",
              " {'decoder_loss': 3.705618381500244,\n",
              "  'step': 818,\n",
              "  'train_loss': 2.5534486770629883},\n",
              " {'decoder_loss': 3.8762924671173096,\n",
              "  'step': 819,\n",
              "  'train_loss': 2.7460036277770996},\n",
              " {'decoder_loss': 3.9540181159973145,\n",
              "  'step': 820,\n",
              "  'train_loss': 3.186560869216919},\n",
              " {'decoder_loss': 4.317124366760254,\n",
              "  'step': 821,\n",
              "  'train_loss': 2.8736050128936768},\n",
              " {'decoder_loss': 4.026819705963135,\n",
              "  'step': 822,\n",
              "  'train_loss': 3.060885190963745},\n",
              " {'decoder_loss': 4.228341579437256,\n",
              "  'step': 823,\n",
              "  'train_loss': 2.8483078479766846},\n",
              " {'decoder_loss': 3.8654251098632812,\n",
              "  'step': 824,\n",
              "  'train_loss': 2.8604226112365723},\n",
              " {'decoder_loss': 4.247901916503906,\n",
              "  'step': 825,\n",
              "  'train_loss': 3.0360729694366455},\n",
              " {'decoder_loss': 4.0735087394714355,\n",
              "  'step': 826,\n",
              "  'train_loss': 3.0601236820220947},\n",
              " {'decoder_loss': 3.8769500255584717,\n",
              "  'step': 827,\n",
              "  'train_loss': 2.6326522827148438},\n",
              " {'decoder_loss': 4.074470520019531,\n",
              "  'step': 828,\n",
              "  'train_loss': 2.986259937286377},\n",
              " {'decoder_loss': 3.7957820892333984,\n",
              "  'step': 829,\n",
              "  'train_loss': 2.6332621574401855},\n",
              " {'decoder_loss': 4.033644199371338,\n",
              "  'step': 830,\n",
              "  'train_loss': 2.956973075866699},\n",
              " {'decoder_loss': 4.228052616119385,\n",
              "  'step': 831,\n",
              "  'train_loss': 2.9677677154541016},\n",
              " {'decoder_loss': 4.0938334465026855,\n",
              "  'step': 832,\n",
              "  'train_loss': 3.0710599422454834},\n",
              " {'decoder_loss': 4.034268856048584,\n",
              "  'step': 833,\n",
              "  'train_loss': 2.354477882385254},\n",
              " {'decoder_loss': 3.82955265045166,\n",
              "  'step': 834,\n",
              "  'train_loss': 2.477353572845459},\n",
              " {'decoder_loss': 4.173892498016357,\n",
              "  'step': 835,\n",
              "  'train_loss': 3.0440614223480225},\n",
              " {'decoder_loss': 4.271511077880859,\n",
              "  'step': 836,\n",
              "  'train_loss': 3.065861701965332},\n",
              " {'decoder_loss': 3.905790328979492,\n",
              "  'step': 837,\n",
              "  'train_loss': 3.0839180946350098},\n",
              " {'decoder_loss': 3.6188082695007324,\n",
              "  'step': 838,\n",
              "  'train_loss': 2.8461050987243652},\n",
              " {'decoder_loss': 4.108700275421143,\n",
              "  'step': 839,\n",
              "  'train_loss': 3.0522408485412598},\n",
              " {'decoder_loss': 3.9377777576446533,\n",
              "  'step': 840,\n",
              "  'train_loss': 2.9924521446228027},\n",
              " {'decoder_loss': 3.9927144050598145,\n",
              "  'step': 841,\n",
              "  'train_loss': 2.8029563426971436},\n",
              " {'decoder_loss': 3.9414303302764893,\n",
              "  'step': 842,\n",
              "  'train_loss': 2.652679443359375},\n",
              " {'decoder_loss': 3.829432964324951,\n",
              "  'step': 843,\n",
              "  'train_loss': 2.867997407913208},\n",
              " {'decoder_loss': 3.6255455017089844,\n",
              "  'step': 844,\n",
              "  'train_loss': 2.5869641304016113},\n",
              " {'decoder_loss': 4.35312032699585,\n",
              "  'step': 845,\n",
              "  'train_loss': 2.9101040363311768},\n",
              " {'decoder_loss': 3.913458824157715,\n",
              "  'step': 846,\n",
              "  'train_loss': 2.877470016479492},\n",
              " {'decoder_loss': 3.6233010292053223,\n",
              "  'step': 847,\n",
              "  'train_loss': 2.5653269290924072},\n",
              " {'decoder_loss': 3.870422124862671,\n",
              "  'step': 848,\n",
              "  'train_loss': 2.7997920513153076},\n",
              " {'decoder_loss': 3.912795305252075,\n",
              "  'step': 849,\n",
              "  'train_loss': 2.7573509216308594},\n",
              " {'decoder_loss': 4.126698017120361,\n",
              "  'step': 850,\n",
              "  'train_loss': 2.6295790672302246},\n",
              " {'decoder_loss': 4.0367655754089355,\n",
              "  'step': 851,\n",
              "  'train_loss': 2.477250099182129},\n",
              " {'decoder_loss': 3.6856586933135986,\n",
              "  'step': 852,\n",
              "  'train_loss': 2.567711591720581},\n",
              " {'decoder_loss': 3.891359329223633,\n",
              "  'step': 853,\n",
              "  'train_loss': 2.91579008102417},\n",
              " {'decoder_loss': 3.410923719406128,\n",
              "  'step': 854,\n",
              "  'train_loss': 2.4303998947143555},\n",
              " {'decoder_loss': 3.8389713764190674,\n",
              "  'step': 855,\n",
              "  'train_loss': 2.71364688873291},\n",
              " {'decoder_loss': 4.047244071960449,\n",
              "  'step': 856,\n",
              "  'train_loss': 2.8365371227264404},\n",
              " {'decoder_loss': 4.11514139175415,\n",
              "  'step': 857,\n",
              "  'train_loss': 2.941025495529175},\n",
              " {'decoder_loss': 4.471316814422607,\n",
              "  'step': 858,\n",
              "  'train_loss': 3.3233492374420166},\n",
              " {'decoder_loss': 3.923532724380493,\n",
              "  'step': 859,\n",
              "  'train_loss': 2.9232170581817627},\n",
              " {'decoder_loss': 4.026597499847412,\n",
              "  'step': 860,\n",
              "  'train_loss': 2.794569492340088},\n",
              " {'decoder_loss': 4.10016393661499,\n",
              "  'step': 861,\n",
              "  'train_loss': 3.247154474258423},\n",
              " {'decoder_loss': 3.4152963161468506,\n",
              "  'step': 862,\n",
              "  'train_loss': 2.4423680305480957},\n",
              " {'decoder_loss': 4.0323333740234375,\n",
              "  'step': 863,\n",
              "  'train_loss': 2.691164493560791},\n",
              " {'decoder_loss': 4.180759429931641,\n",
              "  'step': 864,\n",
              "  'train_loss': 2.636025905609131},\n",
              " {'decoder_loss': 4.271745204925537,\n",
              "  'step': 865,\n",
              "  'train_loss': 3.086151599884033},\n",
              " {'decoder_loss': 3.8496851921081543,\n",
              "  'step': 866,\n",
              "  'train_loss': 2.8737287521362305},\n",
              " {'decoder_loss': 4.051746845245361,\n",
              "  'step': 867,\n",
              "  'train_loss': 3.099102020263672},\n",
              " {'decoder_loss': 4.208078384399414,\n",
              "  'step': 868,\n",
              "  'train_loss': 2.4939496517181396},\n",
              " {'decoder_loss': 3.6177573204040527,\n",
              "  'step': 869,\n",
              "  'train_loss': 2.3711116313934326},\n",
              " {'decoder_loss': 3.8244829177856445,\n",
              "  'step': 870,\n",
              "  'train_loss': 2.7682650089263916},\n",
              " {'decoder_loss': 3.9477434158325195,\n",
              "  'step': 871,\n",
              "  'train_loss': 2.6760520935058594},\n",
              " {'decoder_loss': 3.9721949100494385,\n",
              "  'step': 872,\n",
              "  'train_loss': 2.957980155944824},\n",
              " {'decoder_loss': 4.017827987670898,\n",
              "  'step': 873,\n",
              "  'train_loss': 2.8684799671173096},\n",
              " {'decoder_loss': 3.884293794631958,\n",
              "  'step': 874,\n",
              "  'train_loss': 2.8465189933776855},\n",
              " {'decoder_loss': 3.693340301513672,\n",
              "  'step': 875,\n",
              "  'train_loss': 2.7749006748199463},\n",
              " {'decoder_loss': 4.439362525939941,\n",
              "  'step': 876,\n",
              "  'train_loss': 3.241793394088745},\n",
              " {'decoder_loss': 3.768888473510742,\n",
              "  'step': 877,\n",
              "  'train_loss': 2.417451858520508},\n",
              " {'decoder_loss': 4.174666881561279,\n",
              "  'step': 878,\n",
              "  'train_loss': 2.7335379123687744},\n",
              " {'decoder_loss': 4.046064853668213,\n",
              "  'step': 879,\n",
              "  'train_loss': 2.7802138328552246},\n",
              " {'decoder_loss': 4.160842418670654,\n",
              "  'step': 880,\n",
              "  'train_loss': 2.830378770828247},\n",
              " {'decoder_loss': 4.044505596160889,\n",
              "  'step': 881,\n",
              "  'train_loss': 3.014777660369873},\n",
              " {'decoder_loss': 4.178893566131592,\n",
              "  'step': 882,\n",
              "  'train_loss': 2.795426368713379},\n",
              " {'decoder_loss': 3.9403398036956787,\n",
              "  'step': 883,\n",
              "  'train_loss': 3.0402143001556396},\n",
              " {'decoder_loss': 3.8045833110809326,\n",
              "  'step': 884,\n",
              "  'train_loss': 2.6750707626342773},\n",
              " {'decoder_loss': 4.397439002990723,\n",
              "  'step': 885,\n",
              "  'train_loss': 3.151749610900879},\n",
              " {'decoder_loss': 3.9275221824645996,\n",
              "  'step': 886,\n",
              "  'train_loss': 2.592310905456543},\n",
              " {'decoder_loss': 3.7998032569885254,\n",
              "  'step': 887,\n",
              "  'train_loss': 2.9116950035095215},\n",
              " {'decoder_loss': 3.8861215114593506,\n",
              "  'step': 888,\n",
              "  'train_loss': 2.8134992122650146},\n",
              " {'decoder_loss': 3.6716036796569824,\n",
              "  'step': 889,\n",
              "  'train_loss': 2.700408458709717},\n",
              " {'decoder_loss': 3.902432918548584,\n",
              "  'step': 890,\n",
              "  'train_loss': 2.9277045726776123},\n",
              " {'decoder_loss': 3.8443119525909424,\n",
              "  'step': 891,\n",
              "  'train_loss': 2.7967529296875},\n",
              " {'decoder_loss': 4.022195339202881,\n",
              "  'step': 892,\n",
              "  'train_loss': 3.001129627227783},\n",
              " {'decoder_loss': 3.6806130409240723,\n",
              "  'step': 893,\n",
              "  'train_loss': 2.3489627838134766},\n",
              " {'decoder_loss': 3.9770522117614746,\n",
              "  'step': 894,\n",
              "  'train_loss': 2.5664873123168945},\n",
              " {'decoder_loss': 3.8132781982421875,\n",
              "  'step': 895,\n",
              "  'train_loss': 2.5808069705963135},\n",
              " {'decoder_loss': 3.834383487701416,\n",
              "  'step': 896,\n",
              "  'train_loss': 2.5036613941192627},\n",
              " {'decoder_loss': 4.143492221832275,\n",
              "  'step': 897,\n",
              "  'train_loss': 2.9488377571105957},\n",
              " {'decoder_loss': 3.8305439949035645,\n",
              "  'step': 898,\n",
              "  'train_loss': 2.5509166717529297},\n",
              " {'decoder_loss': 3.817408323287964,\n",
              "  'step': 899,\n",
              "  'train_loss': 2.842646360397339},\n",
              " {'decoder_loss': 3.8462798595428467,\n",
              "  'step': 900,\n",
              "  'train_loss': 2.727863311767578},\n",
              " {'decoder_loss': 4.137610912322998,\n",
              "  'step': 901,\n",
              "  'train_loss': 2.978377103805542},\n",
              " {'decoder_loss': 4.153280735015869,\n",
              "  'step': 902,\n",
              "  'train_loss': 2.6501755714416504},\n",
              " {'decoder_loss': 3.965425729751587,\n",
              "  'step': 903,\n",
              "  'train_loss': 2.7462637424468994},\n",
              " {'decoder_loss': 3.8781542778015137,\n",
              "  'step': 904,\n",
              "  'train_loss': 2.852081775665283},\n",
              " {'decoder_loss': 4.011213302612305,\n",
              "  'step': 905,\n",
              "  'train_loss': 2.8811187744140625},\n",
              " {'decoder_loss': 4.02313756942749,\n",
              "  'step': 906,\n",
              "  'train_loss': 2.721803903579712},\n",
              " {'decoder_loss': 3.7024669647216797,\n",
              "  'step': 907,\n",
              "  'train_loss': 2.782534599304199},\n",
              " {'decoder_loss': 4.083062171936035,\n",
              "  'step': 908,\n",
              "  'train_loss': 2.396059989929199},\n",
              " {'decoder_loss': 3.5513381958007812,\n",
              "  'step': 909,\n",
              "  'train_loss': 2.562507152557373},\n",
              " {'decoder_loss': 3.734957456588745,\n",
              "  'step': 910,\n",
              "  'train_loss': 2.201472520828247},\n",
              " {'decoder_loss': 4.128438472747803,\n",
              "  'step': 911,\n",
              "  'train_loss': 3.072697639465332},\n",
              " {'decoder_loss': 3.628514051437378,\n",
              "  'step': 912,\n",
              "  'train_loss': 2.488213539123535},\n",
              " {'decoder_loss': 3.894930124282837,\n",
              "  'step': 913,\n",
              "  'train_loss': 2.723992109298706},\n",
              " {'decoder_loss': 3.767426013946533,\n",
              "  'step': 914,\n",
              "  'train_loss': 2.3868558406829834},\n",
              " {'decoder_loss': 3.8894402980804443,\n",
              "  'step': 915,\n",
              "  'train_loss': 2.974026918411255},\n",
              " {'decoder_loss': 3.921531915664673,\n",
              "  'step': 916,\n",
              "  'train_loss': 2.840823173522949},\n",
              " {'decoder_loss': 3.9107048511505127,\n",
              "  'step': 917,\n",
              "  'train_loss': 2.919743776321411},\n",
              " {'decoder_loss': 4.122259140014648,\n",
              "  'step': 918,\n",
              "  'train_loss': 2.872434139251709},\n",
              " {'decoder_loss': 3.9428460597991943,\n",
              "  'step': 919,\n",
              "  'train_loss': 3.1266915798187256},\n",
              " {'decoder_loss': 4.0428996086120605,\n",
              "  'step': 920,\n",
              "  'train_loss': 2.6292428970336914},\n",
              " {'decoder_loss': 3.4671778678894043,\n",
              "  'step': 921,\n",
              "  'train_loss': 2.459827423095703},\n",
              " {'decoder_loss': 4.034276008605957,\n",
              "  'step': 922,\n",
              "  'train_loss': 2.999267578125},\n",
              " {'decoder_loss': 3.7969796657562256,\n",
              "  'step': 923,\n",
              "  'train_loss': 2.781926393508911},\n",
              " {'decoder_loss': 3.693525791168213,\n",
              "  'step': 924,\n",
              "  'train_loss': 2.6533799171447754},\n",
              " {'decoder_loss': 3.7905659675598145,\n",
              "  'step': 925,\n",
              "  'train_loss': 3.075185537338257},\n",
              " {'decoder_loss': 3.7711288928985596,\n",
              "  'step': 926,\n",
              "  'train_loss': 2.482787847518921},\n",
              " {'decoder_loss': 3.7697503566741943,\n",
              "  'step': 927,\n",
              "  'train_loss': 2.7408316135406494},\n",
              " {'decoder_loss': 3.9411845207214355,\n",
              "  'step': 928,\n",
              "  'train_loss': 3.2629549503326416},\n",
              " {'decoder_loss': 4.275679111480713,\n",
              "  'step': 929,\n",
              "  'train_loss': 3.176974296569824},\n",
              " {'decoder_loss': 3.964670419692993,\n",
              "  'step': 930,\n",
              "  'train_loss': 2.5368270874023438},\n",
              " {'decoder_loss': 3.864227771759033,\n",
              "  'step': 931,\n",
              "  'train_loss': 2.9795827865600586},\n",
              " {'decoder_loss': 3.90781569480896,\n",
              "  'step': 932,\n",
              "  'train_loss': 2.9142329692840576},\n",
              " {'decoder_loss': 3.7187719345092773,\n",
              "  'step': 933,\n",
              "  'train_loss': 2.6578781604766846},\n",
              " {'decoder_loss': 3.786139726638794,\n",
              "  'step': 934,\n",
              "  'train_loss': 2.662572145462036},\n",
              " {'decoder_loss': 3.8770205974578857,\n",
              "  'step': 935,\n",
              "  'train_loss': 2.6729209423065186},\n",
              " {'decoder_loss': 3.6857082843780518,\n",
              "  'step': 936,\n",
              "  'train_loss': 2.55861759185791},\n",
              " {'decoder_loss': 4.039431571960449,\n",
              "  'step': 937,\n",
              "  'train_loss': 2.6823012828826904},\n",
              " {'decoder_loss': 3.909357786178589,\n",
              "  'step': 938,\n",
              "  'train_loss': 2.9972949028015137},\n",
              " {'decoder_loss': 3.906038761138916,\n",
              "  'step': 939,\n",
              "  'train_loss': 2.587461233139038},\n",
              " {'decoder_loss': 3.8850274085998535,\n",
              "  'step': 940,\n",
              "  'train_loss': 2.3772642612457275},\n",
              " {'decoder_loss': 4.116808891296387,\n",
              "  'step': 941,\n",
              "  'train_loss': 2.8598432540893555},\n",
              " {'decoder_loss': 3.998199701309204,\n",
              "  'step': 942,\n",
              "  'train_loss': 2.7063546180725098},\n",
              " {'decoder_loss': 4.331392765045166,\n",
              "  'step': 943,\n",
              "  'train_loss': 3.0240941047668457},\n",
              " {'decoder_loss': 3.7936294078826904,\n",
              "  'step': 944,\n",
              "  'train_loss': 2.5777454376220703},\n",
              " {'decoder_loss': 3.563021183013916,\n",
              "  'step': 945,\n",
              "  'train_loss': 2.376032590866089},\n",
              " {'decoder_loss': 3.866368055343628,\n",
              "  'step': 946,\n",
              "  'train_loss': 2.6238346099853516},\n",
              " {'decoder_loss': 3.862143039703369,\n",
              "  'step': 947,\n",
              "  'train_loss': 2.9895546436309814},\n",
              " {'decoder_loss': 3.98604154586792,\n",
              "  'step': 948,\n",
              "  'train_loss': 2.6424224376678467},\n",
              " {'decoder_loss': 4.101200580596924,\n",
              "  'step': 949,\n",
              "  'train_loss': 2.9154574871063232},\n",
              " {'decoder_loss': 3.892747402191162,\n",
              "  'step': 950,\n",
              "  'train_loss': 2.763688087463379},\n",
              " {'decoder_loss': 3.5441322326660156,\n",
              "  'step': 951,\n",
              "  'train_loss': 2.3454504013061523},\n",
              " {'decoder_loss': 3.756721019744873,\n",
              "  'step': 952,\n",
              "  'train_loss': 2.592280149459839},\n",
              " {'decoder_loss': 3.935272455215454,\n",
              "  'step': 953,\n",
              "  'train_loss': 2.8901302814483643},\n",
              " {'decoder_loss': 3.946145534515381,\n",
              "  'step': 954,\n",
              "  'train_loss': 2.719353199005127},\n",
              " {'decoder_loss': 4.154617786407471,\n",
              "  'step': 955,\n",
              "  'train_loss': 3.2485599517822266},\n",
              " {'decoder_loss': 3.821533203125,\n",
              "  'step': 956,\n",
              "  'train_loss': 2.756204605102539},\n",
              " {'decoder_loss': 4.1915669441223145,\n",
              "  'step': 957,\n",
              "  'train_loss': 2.758136034011841},\n",
              " {'decoder_loss': 4.114044666290283,\n",
              "  'step': 958,\n",
              "  'train_loss': 2.7874436378479004},\n",
              " {'decoder_loss': 3.912541151046753,\n",
              "  'step': 959,\n",
              "  'train_loss': 2.992744207382202},\n",
              " {'decoder_loss': 3.89980411529541,\n",
              "  'step': 960,\n",
              "  'train_loss': 2.8011653423309326},\n",
              " {'decoder_loss': 3.878002882003784,\n",
              "  'step': 961,\n",
              "  'train_loss': 2.7380058765411377},\n",
              " {'decoder_loss': 3.693474769592285,\n",
              "  'step': 962,\n",
              "  'train_loss': 2.9146578311920166},\n",
              " {'decoder_loss': 3.9284229278564453,\n",
              "  'step': 963,\n",
              "  'train_loss': 2.996211051940918},\n",
              " {'decoder_loss': 3.873950719833374,\n",
              "  'step': 964,\n",
              "  'train_loss': 3.046908140182495},\n",
              " {'decoder_loss': 4.1327667236328125,\n",
              "  'step': 965,\n",
              "  'train_loss': 2.849440574645996},\n",
              " {'decoder_loss': 3.843792200088501,\n",
              "  'step': 966,\n",
              "  'train_loss': 3.0021603107452393},\n",
              " {'decoder_loss': 3.8757264614105225,\n",
              "  'step': 967,\n",
              "  'train_loss': 2.752549409866333},\n",
              " {'decoder_loss': 3.850390911102295,\n",
              "  'step': 968,\n",
              "  'train_loss': 2.9702911376953125},\n",
              " {'decoder_loss': 4.130834102630615,\n",
              "  'step': 969,\n",
              "  'train_loss': 3.0947299003601074},\n",
              " {'decoder_loss': 3.7484078407287598,\n",
              "  'step': 970,\n",
              "  'train_loss': 2.402721643447876},\n",
              " {'decoder_loss': 3.6058616638183594,\n",
              "  'step': 971,\n",
              "  'train_loss': 2.8652563095092773},\n",
              " {'decoder_loss': 3.6748459339141846,\n",
              "  'step': 972,\n",
              "  'train_loss': 2.778818368911743},\n",
              " {'decoder_loss': 4.098810195922852,\n",
              "  'step': 973,\n",
              "  'train_loss': 2.606278657913208},\n",
              " {'decoder_loss': 3.9902327060699463,\n",
              "  'step': 974,\n",
              "  'train_loss': 2.887495517730713},\n",
              " {'decoder_loss': 3.7281157970428467,\n",
              "  'step': 975,\n",
              "  'train_loss': 2.6972501277923584},\n",
              " {'decoder_loss': 3.6602981090545654,\n",
              "  'step': 976,\n",
              "  'train_loss': 2.827451229095459},\n",
              " {'decoder_loss': 3.991738796234131,\n",
              "  'step': 977,\n",
              "  'train_loss': 2.829270362854004},\n",
              " {'decoder_loss': 4.089597702026367,\n",
              "  'step': 978,\n",
              "  'train_loss': 2.9306976795196533},\n",
              " {'decoder_loss': 4.025600910186768,\n",
              "  'step': 979,\n",
              "  'train_loss': 3.044114828109741},\n",
              " {'decoder_loss': 4.143979549407959,\n",
              "  'step': 980,\n",
              "  'train_loss': 2.5723016262054443},\n",
              " {'decoder_loss': 4.185117721557617,\n",
              "  'step': 981,\n",
              "  'train_loss': 2.9672982692718506},\n",
              " {'decoder_loss': 3.5591909885406494,\n",
              "  'step': 982,\n",
              "  'train_loss': 2.5076565742492676},\n",
              " {'decoder_loss': 4.377901077270508,\n",
              "  'step': 983,\n",
              "  'train_loss': 2.9188172817230225},\n",
              " {'decoder_loss': 3.6555159091949463,\n",
              "  'step': 984,\n",
              "  'train_loss': 2.7170517444610596},\n",
              " {'decoder_loss': 3.8628768920898438,\n",
              "  'step': 985,\n",
              "  'train_loss': 3.051326274871826},\n",
              " {'decoder_loss': 3.715757131576538,\n",
              "  'step': 986,\n",
              "  'train_loss': 2.279447555541992},\n",
              " {'decoder_loss': 4.006631374359131,\n",
              "  'step': 987,\n",
              "  'train_loss': 3.0933642387390137},\n",
              " {'decoder_loss': 3.5893285274505615,\n",
              "  'step': 988,\n",
              "  'train_loss': 2.5734620094299316},\n",
              " {'decoder_loss': 3.7542507648468018,\n",
              "  'step': 989,\n",
              "  'train_loss': 2.786118984222412},\n",
              " {'decoder_loss': 3.610994338989258,\n",
              "  'step': 990,\n",
              "  'train_loss': 2.8198952674865723},\n",
              " {'decoder_loss': 4.11293363571167,\n",
              "  'step': 991,\n",
              "  'train_loss': 2.6790060997009277},\n",
              " {'decoder_loss': 3.749875783920288,\n",
              "  'step': 992,\n",
              "  'train_loss': 2.585712432861328},\n",
              " {'decoder_loss': 4.151848316192627,\n",
              "  'step': 993,\n",
              "  'train_loss': 3.0353057384490967},\n",
              " {'decoder_loss': 3.6834728717803955,\n",
              "  'step': 994,\n",
              "  'train_loss': 2.4989216327667236},\n",
              " {'decoder_loss': 4.109575271606445,\n",
              "  'step': 995,\n",
              "  'train_loss': 2.9745781421661377},\n",
              " {'decoder_loss': 3.9488627910614014,\n",
              "  'step': 996,\n",
              "  'train_loss': 2.790740728378296},\n",
              " {'decoder_loss': 4.0318284034729,\n",
              "  'step': 997,\n",
              "  'train_loss': 2.662172794342041},\n",
              " {'decoder_loss': 3.843214750289917,\n",
              "  'step': 998,\n",
              "  'train_loss': 2.865980625152588},\n",
              " {'decoder_loss': 3.7908411026000977,\n",
              "  'step': 999,\n",
              "  'train_loss': 2.793501138687134},\n",
              " {'decoder_loss': 3.6742076873779297,\n",
              "  'step': 1000,\n",
              "  'train_loss': 2.6467504501342773,\n",
              "  'valid_loss': 2.685200533986519},\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgO77jkVjDe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "6c11876985e84675a7ab4289d8e6c5b8",
            "4527a396b8164d90bea5f3837000bd25",
            "537774ccc16942bd8a30542e89bf7be4",
            "b49647e6b27b4a15bb8f24ee94b86f48",
            "a999c93a12fc4bc7a67737abc162a3ae",
            "86c4fb7e79b347c59adf536a5a36504f",
            "eaef0bc70e034fb5b33debadba8fd422",
            "a63df29bb1a949d6a87d1c17d7130eee"
          ]
        },
        "outputId": "6408c160-b94e-41dd-caa0-7f878fb806ec"
      },
      "source": [
        "import numpy as np\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "f_scores = []\n",
        "for i in tqdm(range(len(test_unseen_dataset))):\n",
        "  kwargs = {'num_beams':8,\n",
        "            'num_return_sequences':1,'temperature':1, 'max_length':50, 'early_stopping':True,\n",
        "            'no_repeat_ngram_size':3,\n",
        "            #'top-k':1\n",
        "            }\n",
        "  idx = 100\n",
        "  hk_pair =  test_unseen_dataset[idx]['input_pair'].to(dev)\n",
        "  hk_segment = test_unseen_dataset[idx]['input_pair_segments'].to(dev)\n",
        "  response = test_unseen_dataset[idx]['response'].to(dev)\n",
        "  generateds = model.generate(hk_pair, hk_segment, **kwargs)\n",
        "  generateds = generateds.squeeze(0).cpu().numpy()\n",
        "  response = response.squeeze(0).cpu().numpy()\n",
        "  intersections = np.intersect1d(generateds, response)\n",
        "  recall = len(intersections) / len(response)\n",
        "  precision = len(intersections) / len(generateds)\n",
        "  f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "  f_scores.append(f1_score)\n",
        "  if i % 100 == 0:\n",
        "    print(sum(f_scores) / len(f_scores))\n",
        "\n",
        "print( sum(f_scores) / len(f_scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c11876985e84675a7ab4289d8e6c5b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2075.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.17777777777777776\n",
            "0.1809836658716339\n",
            "0.17820830579324579\n",
            "0.18031518706803867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-fad4c337c329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             }\n\u001b[1;32m     11\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mhk_pair\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtest_unseen_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_pair'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mhk_segment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_unseen_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_pair_segments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_unseen_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-be59c3e9f1a6>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0minput_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pair_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncuate_join_pair_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknowledge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-be59c3e9f1a6>\u001b[0m in \u001b[0;36mtruncuate_join_pair_sentence\u001b[0;34m(sentence1, sentence2, max_len)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0msentence2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseconde\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mtemp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m### two above line may cause warning but no problem because we've handle them below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_pretokenized, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             )\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     (\n\u001b[1;32m    357\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                     )\n\u001b[1;32m    360\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     (\n\u001b[1;32m    357\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                     )\n\u001b[1;32m    360\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_gpt2.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             token = \"\".join(\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             )  # Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)\n\u001b[1;32m    239\u001b[0m             \u001b[0mbpe_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpe_token\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbpe_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}