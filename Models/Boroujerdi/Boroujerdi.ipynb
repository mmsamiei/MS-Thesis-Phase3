{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled162.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbdbc475447e4e5589673eda43887ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25691d1e56954516bbc39bcb4ae4b387",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ce501e273334bfe9cefe06564844ce5",
              "IPY_MODEL_145244cc67134247916471bdb715b9ec"
            ]
          }
        },
        "25691d1e56954516bbc39bcb4ae4b387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ce501e273334bfe9cefe06564844ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d8d29e3c27d4de497b356973cc1bd7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_901cc0d820ec4b1e90be27689df19cae"
          }
        },
        "145244cc67134247916471bdb715b9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5c8abbc2c794a5894aaceca907461c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00,  3.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42685277cf1142679565fed24c31047a"
          }
        },
        "6d8d29e3c27d4de497b356973cc1bd7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "901cc0d820ec4b1e90be27689df19cae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5c8abbc2c794a5894aaceca907461c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42685277cf1142679565fed24c31047a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb7b51f554a446f884946f01b83742dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_763b5f0e7fcf48739a16d0c3a28f4636",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f6ef0521f9a442dac9e40ec79a0ceed",
              "IPY_MODEL_8815473026d74d1b82b97f020ea8142f"
            ]
          }
        },
        "763b5f0e7fcf48739a16d0c3a28f4636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f6ef0521f9a442dac9e40ec79a0ceed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a2cca1ca5c0e4cc4a6319f0f01bc5fbc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fbfc8e73930438487555f8306fb8c6d"
          }
        },
        "8815473026d74d1b82b97f020ea8142f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97339db5206b465cba01ff6ed20e0852",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 649/649 [09:31&lt;00:00,  1.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_085a3db7b3d74fb5b492fc038ecd0c8e"
          }
        },
        "a2cca1ca5c0e4cc4a6319f0f01bc5fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fbfc8e73930438487555f8306fb8c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97339db5206b465cba01ff6ed20e0852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "085a3db7b3d74fb5b492fc038ecd0c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a27f172f8c004ff19bbb21c4c14264f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_508173b94ad045438fdcce88155d3143",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44ece84f87f84d9dae0cc0c089d9060b",
              "IPY_MODEL_588b3b123f1a45138ee3f10088685cac"
            ]
          }
        },
        "508173b94ad045438fdcce88155d3143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44ece84f87f84d9dae0cc0c089d9060b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0fa592d601984419ad8b12240b058dd8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 70,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 70,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6fc222c8a9e497b8f93e0a92ed39d93"
          }
        },
        "588b3b123f1a45138ee3f10088685cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44c341b8592743be807915c585be8ccc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 70/70 [07:59&lt;00:00,  6.85s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64491ae79a21456aa460aebed709d472"
          }
        },
        "0fa592d601984419ad8b12240b058dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6fc222c8a9e497b8f93e0a92ed39d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44c341b8592743be807915c585be8ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64491ae79a21456aa460aebed709d472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d264d1fac4324bbcae861bd9e0ec82c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ef6c18d6029d443ca1c9572be3b18b35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a7e152ffc2eb4a2f9bc30f24c2b88dc9",
              "IPY_MODEL_a5951ad483ab4eb28928fdf7b2bf98db"
            ]
          }
        },
        "ef6c18d6029d443ca1c9572be3b18b35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7e152ffc2eb4a2f9bc30f24c2b88dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c55bf903ae4c4fe6a33df97cf6bfcd10",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_751062a8ebba4f36972f0a9da002e615"
          }
        },
        "a5951ad483ab4eb28928fdf7b2bf98db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_304ab6a3c200426194d2f79aad9f5daa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 649/649 [07:09&lt;00:00,  1.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b97f0db686d7423c8fe6ba4f88556748"
          }
        },
        "c55bf903ae4c4fe6a33df97cf6bfcd10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "751062a8ebba4f36972f0a9da002e615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "304ab6a3c200426194d2f79aad9f5daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b97f0db686d7423c8fe6ba4f88556748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16a41579929c47838045354caaec31be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e305d12be75f451f9cb7b478641e4b7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_adfb90b918a34bf79a2c5bbcd8cbd137",
              "IPY_MODEL_6cb8e5dc31fe453782d8871d58f31da4"
            ]
          }
        },
        "e305d12be75f451f9cb7b478641e4b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adfb90b918a34bf79a2c5bbcd8cbd137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9a8e27472e14a6fb9cc3c55c4f7a6d4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 70,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 70,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5f89b74e70741b285c3e6cdfd357342"
          }
        },
        "6cb8e5dc31fe453782d8871d58f31da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25a2fc57685a4ac186d09baefaa7d8ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 70/70 [06:08&lt;00:00,  5.26s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db3f59c14f744880b37dcb2082c069d5"
          }
        },
        "e9a8e27472e14a6fb9cc3c55c4f7a6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5f89b74e70741b285c3e6cdfd357342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25a2fc57685a4ac186d09baefaa7d8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db3f59c14f744880b37dcb2082c069d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmsamiei/MS-Thesis-Phase3/blob/master/Models/Boroujerdi/Boroujerdi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkQPQqY6s8-v",
        "colab_type": "text"
      },
      "source": [
        "#In the name of God"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SudnGM-6qcaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d4b2642-cfa1-448b-8875-81f28dd70a7b"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        "  function ClickConnect(){\n",
        "    console.log(\"Working\"); \n",
        "    document.querySelector(\"colab-connect-button\").click() \n",
        "  }\n",
        "  var connect_timer = setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "  function ClickConnect(){\n",
              "    console.log(\"Working\"); \n",
              "    document.querySelector(\"colab-connect-button\").click() \n",
              "  }\n",
              "  var connect_timer = setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTGb1dOrs48Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "0413ddfe-6475-49eb-b663-480590b7a7f7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 28 20:40:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyf240b5tD82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0ae8307a-892b-4bba-a551-19ad78d7f9e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcbfW-tZtpLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "e05b8a63-6c24-407b-fa36-b8f3e8afeff3"
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 35.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 62.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 53.3MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eweO40_dtxZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from transformers import AutoTokenizer\n",
        "import random\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModel"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X2E9kZ5tJRA",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eddoohNmtKug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = '/content/drive/My Drive/Thesis/phase-3/hkr_train.csv'\n",
        "valid_file =  '/content/drive/My Drive/Thesis/phase-3/hkr_valid.csv'\n",
        "test_seen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_seen.csv'\n",
        "test_unseen_file = '/content/drive/My Drive/Thesis/phase-3/hkr_test_unseen.csv'\n",
        "last_sentence_file = '/content/drive/My Drive/Thesis/phase-3/last_sentence.csv'"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCX3Tv8tqPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_tokenizer = AutoTokenizer.from_pretrained('google/bert_uncased_L-2_H-128_A-2')\n",
        "dec_tokenizer = AutoTokenizer.from_pretrained('google/bert_uncased_L-2_H-128_A-2')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu21rVUPuIvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"My dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, frac=1, split_rate=1, max_len=512, sort=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "        \"\"\"\n",
        "        self.dialogues = pd.read_csv(csv_file)\n",
        "        self.dialogues.fillna(\"\", inplace=True)\n",
        "        \n",
        "        self.dialogues = self.dialogues[self.dialogues.index % split_rate == 0]\n",
        "\n",
        "        self.dialogues = self.dialogues.sample(frac=frac)\n",
        "        \n",
        "        s = self.dialogues['response'].apply(dec_tokenizer.encode).apply(len).sort_values().index\n",
        "        self.dialogues = self.dialogues.reindex(s)\n",
        "\n",
        "        self.dialogues.dropna(inplace=True)\n",
        "\n",
        "        self.max_len = max_len\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    @staticmethod\n",
        "    def truncuate_join_pair_sentence(sentence1, sentence2, max_len=510):\n",
        "\n",
        "        \"\"\"\n",
        "        truncuate sentence one from head and sentence two from tail\n",
        "        Args:\n",
        "            sentence1 (string): first sentence\n",
        "            sentence2 (string): seconde sentence\n",
        "        \"\"\"\n",
        "        temp1 = enc_tokenizer.encode(sentence1,add_special_tokens=False)\n",
        "        temp2 = enc_tokenizer.encode(sentence2,add_special_tokens=False)\n",
        "        ### two above line may cause warning but no problem because we've handle them below\n",
        "        logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "        seq_1 = temp1\n",
        "        seq_2 = temp2\n",
        "        num_tokens_to_remove = len(temp1) + len(temp2) + 3 - max_len\n",
        "        if num_tokens_to_remove > 0 :\n",
        "            seq_1, seq_2, _ = enc_tokenizer.truncate_sequences(temp1[::-1],temp2, num_tokens_to_remove=num_tokens_to_remove)\n",
        "            seq_1.reverse()\n",
        "        result_list = [enc_tokenizer.cls_token_id]+seq_1+[enc_tokenizer.sep_token_id]+seq_2+[enc_tokenizer.sep_token_id]\n",
        "        token_type_ids = [0] * (len(seq_1) + 2) + [1] * (len(seq_2) + 1)\n",
        "        return result_list, token_type_ids\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "        \n",
        "        history = self.dialogues.iloc[idx].history\n",
        "        knowledge = self.dialogues.iloc[idx].knowledge\n",
        "        response = self.dialogues.iloc[idx].response\n",
        "\n",
        "\n",
        "        input_pair, input_pair_segments = MyDataset.truncuate_join_pair_sentence(history, knowledge, self.max_len)\n",
        "                \n",
        "\n",
        "        input_pair = torch.LongTensor(input_pair)\n",
        "\n",
        "        input_pair_segments = torch.LongTensor(input_pair_segments)\n",
        "\n",
        "        response_tensor = torch.LongTensor(dec_tokenizer.encode(response))\n",
        "\n",
        "        sample = {'input_pair': input_pair,\n",
        "                  'input_pair_segments': input_pair_segments,\n",
        "                  'response': response_tensor}\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0jkglqFwFQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fd889904-89fe-4d81-d0f1-8931eb56d27e"
      },
      "source": [
        "train_dataset = MyDataset(train_file, max_len=128)\n",
        "valid_dataset = MyDataset(valid_file, max_len=510)\n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41489\n",
            "4458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VasXIkuLwHnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d69c4b4-60cf-40e8-ae59-c31c547c4752"
      },
      "source": [
        "enc_tokenizer.decode(train_dataset[399]['input_pair'])\n",
        "dec_tokenizer.decode(train_dataset[399]['response'])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] i have a son with autism [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Z5ZeAT2oii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "cbdbc475447e4e5589673eda43887ef6",
            "25691d1e56954516bbc39bcb4ae4b387",
            "8ce501e273334bfe9cefe06564844ce5",
            "145244cc67134247916471bdb715b9ec",
            "6d8d29e3c27d4de497b356973cc1bd7e",
            "901cc0d820ec4b1e90be27689df19cae",
            "d5c8abbc2c794a5894aaceca907461c2",
            "42685277cf1142679565fed24c31047a"
          ]
        },
        "outputId": "14d706b3-45cc-4af8-d20d-b27d0d8b3835"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "\n",
        "  len_batch = len(batch)\n",
        "\n",
        "  \n",
        "  max_len_input_pair = max([len(data['input_pair']) for data in batch])\n",
        "\n",
        "  max_len_response = max([len(data['response']) for data in batch])\n",
        "  \n",
        "  padding_ind = 0 ## for bert is 0 DON'T THINK BAD IT IS NOT REFACTORING !!!!!!\n",
        "  result_input_pair = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_input_pair_segments = torch.zeros(len_batch, max_len_input_pair)\n",
        "  result_response = torch.zeros(len_batch, max_len_response)\n",
        "\n",
        "  for i, data in enumerate(batch):\n",
        "    p1 = len(data['input_pair'])\n",
        "    result_input_pair[i, :p1] = data['input_pair']\n",
        "\n",
        "    p3 = len(data['input_pair_segments'])\n",
        "    result_input_pair_segments[i, :p3] = data['input_pair_segments']\n",
        "\n",
        "    p4 = len(data['response'])\n",
        "    result_response[i, :p4] = data['response']\n",
        "\n",
        "  return result_input_pair.long(), result_input_pair_segments.long(), result_response.long()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn,\n",
        "                                           num_workers=1)\n",
        "\n",
        "#valid_sampler = torch.utils.data.SequentialSampler(valid_dataset)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64,\n",
        "                                             shuffle=False, collate_fn=my_collate_fn, num_workers=1)\n",
        "\n",
        "i = 0 \n",
        "for batch_idx, batch  in tqdm(enumerate(train_loader)):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  print(pair_batch.shape)\n",
        "  print(segment_batch.shape)\n",
        "  print(response_batch.shape)\n",
        "  print(\"****\")\n",
        "  i += 1 \n",
        "  if(i==2):\n",
        "    break\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(valid_loader))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbdbc475447e4e5589673eda43887ef6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64, 6])\n",
            "****\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64, 7])\n",
            "****\n",
            "649\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoQlszJw_hFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "c5ef1ed1-4202-4916-d65d-d7cab8869c62"
      },
      "source": [
        "o = torch.rand(8,5)\n",
        "o"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7971, 0.5570, 0.6176, 0.8620, 0.0346],\n",
              "        [0.2617, 0.9808, 0.7682, 0.6243, 0.2782],\n",
              "        [0.4833, 0.6336, 0.0463, 0.0938, 0.4098],\n",
              "        [0.9999, 0.7067, 0.1404, 0.7106, 0.1492],\n",
              "        [0.0357, 0.5070, 0.1811, 0.8164, 0.6623],\n",
              "        [0.6191, 0.1194, 0.4503, 0.9537, 0.8837],\n",
              "        [0.2407, 0.3513, 0.4584, 0.2995, 0.2904],\n",
              "        [0.1673, 0.0891, 0.2090, 0.0751, 0.6567]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzwNQ5HwD5hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0aec0d8-18f3-43e7-f137-27cc4551bceb"
      },
      "source": [
        "y = torch.LongTensor(8).random_(0,5)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0, 0, 0, 4, 1, 4, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0fr2mAvGYA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "749be628-2f4b-4379-c354-d490ccde15dd"
      },
      "source": [
        "o[y!=2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2617, 0.9808, 0.7682, 0.6243, 0.2782],\n",
              "        [0.4833, 0.6336, 0.0463, 0.0938, 0.4098],\n",
              "        [0.9999, 0.7067, 0.1404, 0.7106, 0.1492],\n",
              "        [0.0357, 0.5070, 0.1811, 0.8164, 0.6623],\n",
              "        [0.6191, 0.1194, 0.4503, 0.9537, 0.8837],\n",
              "        [0.2407, 0.3513, 0.4584, 0.2995, 0.2904]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxXzuZtMINMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cafb2b27-0aaf-4bb8-8d21-a759de573555"
      },
      "source": [
        "z = torch.LongTensor(o[y!=2].shape[0]).fill_(2)\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J49VS8z3Ilz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfWWb-ayBCsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7132afe9-8373-49be-9a7b-225c4c8afa97"
      },
      "source": [
        "-1*F.nll_loss(nn.functional.log_softmax(o[y!=2]), z, reduction='mean')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.7754)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXB7YVVgDyPU",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfGvoJMiEicR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizer\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    self.seq2seq = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "        'google/bert_uncased_L-2_H-128_A-2', 'google/bert_uncased_L-2_H-128_A-2')\n",
        "    \n",
        "    for p in self.seq2seq.encoder.embeddings.parameters():\n",
        "       p.requires_grad = False\n",
        "    \n",
        "    for p in self.seq2seq.decoder.bert.embeddings.parameters():\n",
        "       p.requires_grad = False\n",
        "\n",
        "  def forward(self, encoder_input, segments_tensors, decoder_input):\n",
        "    '''\n",
        "    encoder_input = [batch_size, enc_len]\n",
        "    segments_tensors = [batch_size, enc_len]\n",
        "    decoder_input = [batch_size, dec_len]\n",
        "    '''\n",
        "    kwargs = {'token_type_ids':segments_tensors}\n",
        "    kwargs = {}\n",
        "    outputs = self.seq2seq(input_ids=encoder_input, decoder_input_ids=decoder_input, **kwargs)[0]\n",
        "    return outputs\n",
        "  \n",
        "  def generate(self, encoder_input, segments_tensors, **kwargs):\n",
        "    ### encoder_input = [len] in int format\n",
        "    ### segment_tensors = [len]\n",
        "    encoder_input = encoder_input.unsqueeze(0)\n",
        "    segments_tensors = segments_tensors.unsqueeze(0)\n",
        "\n",
        "\n",
        "    #kwargs['token_type_ids'] = {'token_type_ids':segments_tensors}\n",
        "\n",
        "    generated = model.seq2seq.generate(encoder_input, decoder_start_token_id=101,\n",
        "                                       eos_token_id=102, ## [SEP] = 102\n",
        "                                       **kwargs)\n",
        "\n",
        "    #### generated = [1, len]\n",
        "    return generated"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxsRPOHFGrBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "531ddb29-3f1b-4a27-d1a1-cb634f25883f"
      },
      "source": [
        "dev = torch.device('cuda')\n",
        "model = Model().to(dev)\n",
        "\n",
        "# x = torch.LongTensor(200, 40).random_(1,1000).to(dev)\n",
        "# print(model(x).shape)\n",
        "\n",
        "\n",
        "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(count_parameters(model))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1006010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb5uvuCKL0cj",
        "colab_type": "text"
      },
      "source": [
        "#Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeCzpzbgZN6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        return 5e-5\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxB7zLBDZQXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer2 = NoamOpt(128, 1, 2000,\n",
        "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "optimizer = NoamOpt(128, 1, 1000,\n",
        "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyeZLHUjZSTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "a4afc207-872a-4310-c4c1-72eeb4921f4f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(np.arange(1, 20*649), [optimizer.rate(i) for i in range(1, 20*649)], color='blue')\n",
        "plt.plot(np.arange(1, 20*649), [optimizer2.rate(i) for i in range(1, 20*649)], color='green')\n",
        "plt.legend([\"128:2000\", \"512:8000\", \"256:4000\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f22e6b76c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAhOZdxHJMoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdf200a8-a4e8-44ee-a20e-ded3b791eecd"
      },
      "source": [
        "print(\"Maximum learning rate is:\",max([optimizer.rate(i) for i in range(1, 20*649)]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum learning rate is: 1e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NNbXiU3xqj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e77a1a42-7822-4cfe-d204-e4e897893430"
      },
      "source": [
        "optimizer.rate(20000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EWALhfgJsZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6045909-d55a-48ab-d7cd-bcd4f11277ae"
      },
      "source": [
        "print(\"Peak step is:\",max(enumerate([optimizer.rate(i) for i in range(1, 20*649)]), key=lambda x: x[1])[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peak step is: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufFe-Q62ZaFW",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-t7PADEZcZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn\n",
        "\n",
        "def mahdi_loss(model_output, true_trg, **kwargs):\n",
        "  '''\n",
        "  model_output: [batch, len, hidden]\n",
        "  true_trg: [batch, len]\n",
        "  '''\n",
        "  model_output = model_output[:,:-1,:]\n",
        "  true_trg = true_trg[:,1:]\n",
        "\n",
        "  # cold\n",
        "  #T = 1\n",
        "  #model_output = model_output / T\n",
        "\n",
        "  if 'easy_training' in kwargs:\n",
        "    limit_last_tokens = kwargs['easy_training']\n",
        "    model_output = model_output[:,-limit_last_tokens:,:]\n",
        "    true_trg = true_trg[:,-limit_last_tokens:]\n",
        "\n",
        "  batch_len = model_output.shape[0]\n",
        "  snt_len = model_output.shape[1]\n",
        "  hidden_size = model_output.shape[2]\n",
        "\n",
        "  model_output = model_output.reshape(-1, hidden_size)\n",
        "  true_trg = true_trg.reshape(-1)\n",
        "\n",
        "  loss_mod = nn.CrossEntropyLoss(ignore_index=0)## PAD = 0\n",
        "  loss = loss_mod(model_output, true_trg)\n",
        "\n",
        "\n",
        "\n",
        "  #z = torch.LongTensor(model_output[true_trg!=1045].shape[0]).fill_(1045).to(dev)\n",
        "  #neg_loss = -0.5*F.nll_loss(nn.functional.log_softmax(model_output[true_trg!=1045]), z, reduction='mean')\n",
        "\n",
        "  return loss "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmuTGJMJbR9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_step(batch_idx, batch):\n",
        "  pair_batch, segment_batch, response_batch = batch\n",
        "  pair_batch = pair_batch.to(dev)\n",
        "  segment_batch = segment_batch.to(dev)\n",
        "  response_batch = response_batch.to(dev)\n",
        "  model_output = model(pair_batch, segment_batch, response_batch)\n",
        "  #kwargs = {'easy_training':4}\n",
        "  loss = mahdi_loss(model_output, response_batch)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  del pair_batch\n",
        "  del segment_batch\n",
        "  del response_batch\n",
        "  return loss.item()\n",
        "\n",
        "def valid_step(batch_idx, batch):\n",
        "  with torch.no_grad():\n",
        "    pair_batch, segment_batch, response_batch = batch\n",
        "    pair_batch = pair_batch.to(dev)\n",
        "    segment_batch = segment_batch.to(dev)\n",
        "    response_batch = response_batch.to(dev)\n",
        "    model_output = model(pair_batch, segment_batch, response_batch)\n",
        "    loss = mahdi_loss(model_output, response_batch)\n",
        "    del pair_batch\n",
        "    del segment_batch\n",
        "    del response_batch\n",
        "    return loss.item()\n",
        "\n",
        "def valid_loop(valid_loader):\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "  for batch_idx, batch in tqdm(enumerate(valid_loader),  total=len(valid_loader)):\n",
        "    total_loss += valid_step(batch_idx, batch)  \n",
        "  \n",
        "  print(\"temperature is 1:\")\n",
        "  kwargs = {'num_beams':16,'num_return_sequences':16,'temperature':1}\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  print(\"temperature is 0.33:\")\n",
        "  kwargs = {'num_beams':16,'num_return_sequences':16,'temperature':0.33}\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  print(\"temperature is 2:\")\n",
        "  kwargs = {'num_beams':16,'num_return_sequences':16,'temperature':2}\n",
        "  valid_inference(**kwargs)\n",
        "\n",
        "  model.train()\n",
        "  return total_loss / len(valid_loader)\n",
        "\n",
        "def valid_inference(idx=313, **kwargs):\n",
        "  hk_pair =  train_dataset[idx]['input_pair'].to(dev)\n",
        "  hk_segment = train_dataset[idx]['input_pair_segments'].to(dev)\n",
        "  response = train_dataset[idx]['response'].to(dev)\n",
        "  generateds = model.generate(hk_pair, hk_segment, **kwargs)\n",
        "  print(\"pair is: \",enc_tokenizer.decode(hk_pair))\n",
        "  print(\"response is: \",dec_tokenizer.decode(response))\n",
        "  for generated in generateds:\n",
        "    print(\"model says: \",dec_tokenizer.decode(generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pxjS0PQfKU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_learning = True\n",
        "if new_learning:\n",
        "  # optimizer = NoamOpt(128, 1, 2000,\n",
        "  #           torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "  model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Boroujerdi/\"\n",
        "  step = 0\n",
        "  log_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZD1hD7rfNFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34f22331-29d0-46a8-cf65-897781111187"
      },
      "source": [
        "## if continue learning:\n",
        "#!wget -q https://github.com/mmsamiei/MS-Thesis-Phase2/raw/master/Models/hashemi_16000steps.model\n",
        "model_dir = \"/content/drive/My Drive/Thesis/phase-3/Models/Boroujerdi\"\n",
        "checkpoint = torch.load(model_dir+'/boroujerdi_20000steps.model')\n",
        "step = checkpoint['log_list'][-1]['step']\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "optimizer._step = step\n",
        "log_list = checkpoint['log_list']\n",
        "new_learning = False\n",
        "print(step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHv6tC4YfZI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bb7b51f554a446f884946f01b83742dc",
            "763b5f0e7fcf48739a16d0c3a28f4636",
            "0f6ef0521f9a442dac9e40ec79a0ceed",
            "8815473026d74d1b82b97f020ea8142f",
            "a2cca1ca5c0e4cc4a6319f0f01bc5fbc",
            "8fbfc8e73930438487555f8306fb8c6d",
            "97339db5206b465cba01ff6ed20e0852",
            "085a3db7b3d74fb5b492fc038ecd0c8e",
            "a27f172f8c004ff19bbb21c4c14264f6",
            "508173b94ad045438fdcce88155d3143",
            "44ece84f87f84d9dae0cc0c089d9060b",
            "588b3b123f1a45138ee3f10088685cac",
            "0fa592d601984419ad8b12240b058dd8",
            "e6fc222c8a9e497b8f93e0a92ed39d93",
            "44c341b8592743be807915c585be8ccc",
            "64491ae79a21456aa460aebed709d472",
            "d264d1fac4324bbcae861bd9e0ec82c1",
            "ef6c18d6029d443ca1c9572be3b18b35",
            "a7e152ffc2eb4a2f9bc30f24c2b88dc9",
            "a5951ad483ab4eb28928fdf7b2bf98db",
            "c55bf903ae4c4fe6a33df97cf6bfcd10",
            "751062a8ebba4f36972f0a9da002e615",
            "304ab6a3c200426194d2f79aad9f5daa",
            "b97f0db686d7423c8fe6ba4f88556748",
            "16a41579929c47838045354caaec31be",
            "e305d12be75f451f9cb7b478641e4b7b",
            "adfb90b918a34bf79a2c5bbcd8cbd137",
            "6cb8e5dc31fe453782d8871d58f31da4",
            "e9a8e27472e14a6fb9cc3c55c4f7a6d4",
            "e5f89b74e70741b285c3e6cdfd357342",
            "25a2fc57685a4ac186d09baefaa7d8ef",
            "db3f59c14f744880b37dcb2082c069d5"
          ]
        },
        "outputId": "4f8eb6fc-8bae-421d-8fef-c55e30d7b4bb"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "MAX_STEP = 1000\n",
        "STEP_SAVE = 500\n",
        "STEP_CHECK = 500\n",
        "step_num = step + 1\n",
        "log_list = log_list ### Check if new learning or not\n",
        "print(step_num)\n",
        "while step_num <= MAX_STEP:\n",
        "  model.train()\n",
        "  for batch_idx, batch in tqdm(enumerate(iter(train_loader)), total=len(train_loader)):\n",
        "    step_loss = train_step(batch_idx, batch)\n",
        "    log = {'step':step_num, 'train_loss':step_loss}\n",
        "\n",
        "    if(step_num % STEP_CHECK == 0):\n",
        "      valid_error = valid_loop(valid_loader)\n",
        "      print(\"valid Loss rate: {} at step {}\".format(valid_error, step_num))  \n",
        "      log['valid_loss'] = valid_error\n",
        "\n",
        "    log_list.append(log)\n",
        "\n",
        "    if(step_num % STEP_SAVE == 0):\n",
        "      torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'log_list': log_list,\n",
        "            'optimizer_state_dict': optimizer.optimizer.state_dict()\n",
        "            }, model_dir+'boroujerdi_{}steps.model'.format(step_num))\n",
        "    step_num += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb7b51f554a446f884946f01b83742dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=649.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a27f172f8c004ff19bbb21c4c14264f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=70.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "temperature is 1:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pair is:  [CLS] katie perry [SEP] katy perry is my favorite artist from london to listen to while showering. [SEP] i like some of her songs but i am more of a queen fan. i like to listen to them anywhere! [SEP] freddie mercury was the lead vocalist right? [SEP] yes! i love them! have you been to any katy perry concerts? [SEP] i saw her superbowl halftime performance in august 2014, it was awesome! [SEP] i think i remember that! what are some of your favorite songs of hers? [SEP] no _ passages _ used [SEP]\n",
            "response is:  [CLS] my favorite song is fireworks. [SEP]\n",
            "model says:  [CLS] i'm not sure, but i'm sure i'm sure sure it's\n",
            "model says:  [CLS] i'm not sure. i'm sure. i'm sure sure it's\n",
            "model says:  [CLS] i'm not sure, but i'm sure i'm sure sure that's\n",
            "model says:  [CLS] i'm not sure, but i'm sure. i'm sure sure that is\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm sure sure that\n",
            "model says:  [CLS] i'm not sure, but i'm sure. i'm sure sure it '\n",
            "model says:  [CLS] i'm not sure. i'm sure, but i'm sure sure that is\n",
            "model says:  [CLS] i'm not sure, but i'm not sure. i'm sure sure that\n",
            "model says:  [CLS] i'm not sure, but i'm sure. i'm not sure that is\n",
            "model says:  [CLS] i'm not sure, but i'm sure. i'm sure sure that '\n",
            "model says:  [CLS] i'm not sure. i'm not sure. i'm sure sure that is\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm sure sure it\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm sure sure,\n",
            "model says:  [CLS] i'm not sure, but i'm sure. i'm sure sure, but\n",
            "model says:  [CLS] i'm not sure, but i'm sure. i'm sure sure it is\n",
            "model says:  [CLS] i'm not sure. i'm sure, but i'm sure sure it '\n",
            "temperature is 0.33:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pair is:  [CLS] katie perry [SEP] katy perry is my favorite artist from london to listen to while showering. [SEP] i like some of her songs but i am more of a queen fan. i like to listen to them anywhere! [SEP] freddie mercury was the lead vocalist right? [SEP] yes! i love them! have you been to any katy perry concerts? [SEP] i saw her superbowl halftime performance in august 2014, it was awesome! [SEP] i think i remember that! what are some of your favorite songs of hers? [SEP] no _ passages _ used [SEP]\n",
            "response is:  [CLS] my favorite song is fireworks. [SEP]\n",
            "model says:  [CLS] i love the best of the best of the best of the best of the best of the best\n",
            "model says:  [CLS] i'm not sure that's not not sure. i'm sure sure that is\n",
            "model says:  [CLS] i have a lot of the most of the most of the most of the most of the most\n",
            "model says:  [CLS] i love the most of the most of the most of the most of the most of the most\n",
            "model says:  [CLS] i'm sure that's a lot of the most of the most most of the most\n",
            "model says:  [CLS] i'm not sure that is a lot of the most of the most most of the most\n",
            "model says:  [CLS] i'm sure that is a lot of the most of the most of the most most of\n",
            "model says:  [CLS] i'm not sure that's a lot of the most of the most most of the\n",
            "model says:  [CLS] i have a lot of the most of the most of the most of the most most of the\n",
            "model says:  [CLS] i love the most of the most of the most of the most of the most most of the\n",
            "model says:  [CLS] i'm sure that is a lot of the most of the most of the most of the\n",
            "model says:  [CLS] i have a lot of the most of the most of the most of the most of the world\n",
            "model says:  [CLS] i have a lot of the world, i have a lot of the world, i have been\n",
            "model says:  [CLS] i think it's a lot of the most of the most of the most of the most\n",
            "model says:  [CLS] i have a lot of the most of the most of the most of the world, the world\n",
            "model says:  [CLS] i love the most of the most of the most of the most of the most of the world\n",
            "temperature is 2:\n",
            "pair is:  [CLS] katie perry [SEP] katy perry is my favorite artist from london to listen to while showering. [SEP] i like some of her songs but i am more of a queen fan. i like to listen to them anywhere! [SEP] freddie mercury was the lead vocalist right? [SEP] yes! i love them! have you been to any katy perry concerts? [SEP] i saw her superbowl halftime performance in august 2014, it was awesome! [SEP] i think i remember that! what are some of your favorite songs of hers? [SEP] no _ passages _ used [SEP]\n",
            "response is:  [CLS] my favorite song is fireworks. [SEP]\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure i'm\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure it's\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure i've\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure it'm\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure i'll\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure it'll\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure it'd\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure i'd\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure it've\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure sure i '\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure it're\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure sure it '\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure i're\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure sure i think\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure i'm sure sure that is\n",
            "model says:  [CLS] i'm sure i'm sure i'm sure. i'm sure sure that\n",
            "valid Loss rate: 5.651821763174874 at step 500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d264d1fac4324bbcae861bd9e0ec82c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=649.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16a41579929c47838045354caaec31be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=70.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "temperature is 1:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pair is:  [CLS] katie perry [SEP] katy perry is my favorite artist from london to listen to while showering. [SEP] i like some of her songs but i am more of a queen fan. i like to listen to them anywhere! [SEP] freddie mercury was the lead vocalist right? [SEP] yes! i love them! have you been to any katy perry concerts? [SEP] i saw her superbowl halftime performance in august 2014, it was awesome! [SEP] i think i remember that! what are some of your favorite songs of hers? [SEP] no _ passages _ used [SEP]\n",
            "response is:  [CLS] my favorite song is fireworks. [SEP]\n",
            "model says:  [CLS] i'm not sure, but i'm not sure, but i'm not sure\n",
            "model says:  [CLS] i'm not sure, but i'm not sure. it's a lot of\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm not sure that\n",
            "model says:  [CLS] i'm not sure, but i'm not sure, but i'm sure.\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm sure sure that\n",
            "model says:  [CLS] i'm not sure, but i'm not sure, but i'm sure that\n",
            "model says:  [CLS] i'm not sure, but i'm sure. it's a lot of the\n",
            "model says:  [CLS] i'm not sure, but i'm not sure. it's not not sure\n",
            "model says:  [CLS] i'm not sure, but i'm not sure, but i'm sure,\n",
            "model says:  [CLS] i'm not sure, but i'm sure. it's not not sure that\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm not sure.\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm not sure,\n",
            "model says:  [CLS] i'm not sure, but i'm not sure. it's not sure that\n",
            "model says:  [CLS] i'm not sure, but i'm not sure, but i'm sure sure\n",
            "model says:  [CLS] i'm not sure, but i'm sure, but i'm not sure it\n",
            "model says:  [CLS] i'm not sure, but i'm sure. it's not sure that '\n",
            "temperature is 0.33:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pair is:  [CLS] katie perry [SEP] katy perry is my favorite artist from london to listen to while showering. [SEP] i like some of her songs but i am more of a queen fan. i like to listen to them anywhere! [SEP] freddie mercury was the lead vocalist right? [SEP] yes! i love them! have you been to any katy perry concerts? [SEP] i saw her superbowl halftime performance in august 2014, it was awesome! [SEP] i think i remember that! what are some of your favorite songs of hers? [SEP] no _ passages _ used [SEP]\n",
            "response is:  [CLS] my favorite song is fireworks. [SEP]\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" \" the song \" \" \"\n",
            "model says:  [CLS] i love to be a lot of the best of the best of the best of the best of\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" the song \" \" \" \"\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" the song \" \" the song\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" \" \" the song \" \"\n",
            "model says:  [CLS] i love the first album was released in the first album, but it was released in the album\n",
            "model says:  [CLS] i love the album was released in the first album, but it was released in the album.\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" the song \" \" \" the\n",
            "model says:  [CLS] i love the first album was released in the first album, but it was released by the album\n",
            "model says:  [CLS] i love the album was released in the united states, but it was released in the united states\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" \" the song \" \" the\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" \" \" \" the song \"\n",
            "model says:  [CLS] i love the first album was released in the album, but it was released in the album.\n",
            "model says:  [CLS] i love the song was a song \" \" the song \" \" \" \" \" \" \" \"\n",
            "model says:  [CLS] i love to be a lot of the best of the best of the best of the best film\n",
            "model says:  [CLS] i love the best album was released in the first album, but it was released in the album\n",
            "temperature is 2:\n",
            "pair is:  [CLS] katie perry [SEP] katy perry is my favorite artist from london to listen to while showering. [SEP] i like some of her songs but i am more of a queen fan. i like to listen to them anywhere! [SEP] freddie mercury was the lead vocalist right? [SEP] yes! i love them! have you been to any katy perry concerts? [SEP] i saw her superbowl halftime performance in august 2014, it was awesome! [SEP] i think i remember that! what are some of your favorite songs of hers? [SEP] no _ passages _ used [SEP]\n",
            "response is:  [CLS] my favorite song is fireworks. [SEP]\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure i'm not sure that\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure. i'm not sure\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure. i'm sure that\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure. i'm sure.\n",
            "model says:  [CLS] i'm not sure i'm sure i'm not sure i'm sure that\n",
            "model says:  [CLS] i'm not sure i'm sure i'm not sure i'm not sure\n",
            "model says:  [CLS] i'm not sure i'm sure i'm not sure i'm sure.\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure i'm sure sure that\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure i'm not sure.\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure. i'm sure,\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure. it's not sure\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure i'm not sure it\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure. i'm sure it\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure. i'm sure what\n",
            "model says:  [CLS] i'm not sure i'm sure i'm not sure i'm sure,\n",
            "model says:  [CLS] i'm not sure i'm sure i'm sure i'm not sure,\n",
            "valid Loss rate: 5.320989513397217 at step 1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow4c6BCePKec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "7139fb42-a9cc-4b87-ceb9-c3df99a494db"
      },
      "source": [
        "#'num_beams':16,\n",
        "kwargs = {'num_beams':8,\n",
        "          'num_return_sequences':8,'temperature':0.1, 'max_length':50, 'early_stopping':True,\n",
        "          'no_repeat_ngram_size':3\n",
        "          }\n",
        "valid_inference(idx=10000, **kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 102 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pair is:  [CLS] basketball [SEP] basketball is such a fun and cool limited contact sport [SEP] i love basketball too, it's great to watch and play! [SEP] while most often played as a team sport with five players on each side, three - on - three, two - on - two, and one - on - one competitions are also common. [SEP]\n",
            "response is:  [CLS] its usually five players each side but 1v1 and 2v2 is common [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - or three - up - legged. [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - or three - up - there. [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - tiers. [SEP] [SEP] [SEP] [SEP] [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - up - 2. [SEP] [SEP] [SEP] [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - or three - up - one. [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - up - level. [SEP] [SEP] [SEP] [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - level. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]\n",
            "model says:  [CLS] i'm not sure. i have a lot of games. i've played in the two - tier - level of three - - - teams. [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BR6gnBSDYzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bd84582-1804-4af5-a96e-b997386a1115"
      },
      "source": [
        "a = torch.load('/content/drive/My Drive/Thesis/phase-3/Models/Boroujerdi/boroujerdi_19000steps.model')\n",
        "model.load_state_dict(a['model_state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001YzGTpEiV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4449703-2e1c-4c1e-ffd8-c1e7edc68f43"
      },
      "source": [
        "log_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'step': 1, 'train_loss': 14.16185474395752},\n",
              " {'step': 2, 'train_loss': 10.588570594787598},\n",
              " {'step': 3, 'train_loss': 8.754494667053223},\n",
              " {'step': 4, 'train_loss': 7.626872539520264},\n",
              " {'step': 5, 'train_loss': 7.459188938140869},\n",
              " {'step': 6, 'train_loss': 7.165883541107178},\n",
              " {'step': 7, 'train_loss': 6.705699443817139},\n",
              " {'step': 8, 'train_loss': 6.861814022064209},\n",
              " {'step': 9, 'train_loss': 7.119411945343018},\n",
              " {'step': 10, 'train_loss': 6.74100923538208},\n",
              " {'step': 11, 'train_loss': 6.516302108764648},\n",
              " {'step': 12, 'train_loss': 6.39729642868042},\n",
              " {'step': 13, 'train_loss': 6.507824420928955},\n",
              " {'step': 14, 'train_loss': 6.552713394165039},\n",
              " {'step': 15, 'train_loss': 6.616140842437744},\n",
              " {'step': 16, 'train_loss': 6.452396392822266},\n",
              " {'step': 17, 'train_loss': 6.47140645980835},\n",
              " {'step': 18, 'train_loss': 6.4972028732299805},\n",
              " {'step': 19, 'train_loss': 6.039199352264404},\n",
              " {'step': 20, 'train_loss': 6.292985439300537},\n",
              " {'step': 21, 'train_loss': 6.300108432769775},\n",
              " {'step': 22, 'train_loss': 6.189670562744141},\n",
              " {'step': 23, 'train_loss': 6.246770858764648},\n",
              " {'step': 24, 'train_loss': 6.452057838439941},\n",
              " {'step': 25, 'train_loss': 6.280635356903076},\n",
              " {'step': 26, 'train_loss': 6.273300647735596},\n",
              " {'step': 27, 'train_loss': 6.056609153747559},\n",
              " {'step': 28, 'train_loss': 6.026507377624512},\n",
              " {'step': 29, 'train_loss': 6.062320709228516},\n",
              " {'step': 30, 'train_loss': 5.975796222686768},\n",
              " {'step': 31, 'train_loss': 6.063614368438721},\n",
              " {'step': 32, 'train_loss': 6.074891090393066},\n",
              " {'step': 33, 'train_loss': 5.941574573516846},\n",
              " {'step': 34, 'train_loss': 5.894112586975098},\n",
              " {'step': 35, 'train_loss': 5.716279983520508},\n",
              " {'step': 36, 'train_loss': 5.833044528961182},\n",
              " {'step': 37, 'train_loss': 6.0303449630737305},\n",
              " {'step': 38, 'train_loss': 5.830294609069824},\n",
              " {'step': 39, 'train_loss': 6.028175354003906},\n",
              " {'step': 40, 'train_loss': 5.833225727081299},\n",
              " {'step': 41, 'train_loss': 5.704662799835205},\n",
              " {'step': 42, 'train_loss': 5.571741104125977},\n",
              " {'step': 43, 'train_loss': 5.689540386199951},\n",
              " {'step': 44, 'train_loss': 5.688337326049805},\n",
              " {'step': 45, 'train_loss': 5.639897346496582},\n",
              " {'step': 46, 'train_loss': 5.584630966186523},\n",
              " {'step': 47, 'train_loss': 5.806941509246826},\n",
              " {'step': 48, 'train_loss': 5.767697334289551},\n",
              " {'step': 49, 'train_loss': 5.917086124420166},\n",
              " {'step': 50, 'train_loss': 5.6431355476379395},\n",
              " {'step': 51, 'train_loss': 5.661414623260498},\n",
              " {'step': 52, 'train_loss': 5.869422912597656},\n",
              " {'step': 53, 'train_loss': 5.681264877319336},\n",
              " {'step': 54, 'train_loss': 5.396480083465576},\n",
              " {'step': 55, 'train_loss': 5.6130242347717285},\n",
              " {'step': 56, 'train_loss': 5.7876811027526855},\n",
              " {'step': 57, 'train_loss': 5.636516094207764},\n",
              " {'step': 58, 'train_loss': 5.453927993774414},\n",
              " {'step': 59, 'train_loss': 5.456034183502197},\n",
              " {'step': 60, 'train_loss': 5.442613124847412},\n",
              " {'step': 61, 'train_loss': 5.690744400024414},\n",
              " {'step': 62, 'train_loss': 5.448334217071533},\n",
              " {'step': 63, 'train_loss': 5.471738338470459},\n",
              " {'step': 64, 'train_loss': 5.292912006378174},\n",
              " {'step': 65, 'train_loss': 5.428622245788574},\n",
              " {'step': 66, 'train_loss': 5.616171836853027},\n",
              " {'step': 67, 'train_loss': 5.620097637176514},\n",
              " {'step': 68, 'train_loss': 5.393664836883545},\n",
              " {'step': 69, 'train_loss': 5.50708532333374},\n",
              " {'step': 70, 'train_loss': 5.605390548706055},\n",
              " {'step': 71, 'train_loss': 5.5498738288879395},\n",
              " {'step': 72, 'train_loss': 5.412203311920166},\n",
              " {'step': 73, 'train_loss': 5.582536697387695},\n",
              " {'step': 74, 'train_loss': 5.443815231323242},\n",
              " {'step': 75, 'train_loss': 5.685203552246094},\n",
              " {'step': 76, 'train_loss': 5.477849006652832},\n",
              " {'step': 77, 'train_loss': 5.542849063873291},\n",
              " {'step': 78, 'train_loss': 5.440784931182861},\n",
              " {'step': 79, 'train_loss': 5.087185859680176},\n",
              " {'step': 80, 'train_loss': 5.338245868682861},\n",
              " {'step': 81, 'train_loss': 5.356476306915283},\n",
              " {'step': 82, 'train_loss': 5.22061824798584},\n",
              " {'step': 83, 'train_loss': 5.371486186981201},\n",
              " {'step': 84, 'train_loss': 5.524362564086914},\n",
              " {'step': 85, 'train_loss': 5.548765659332275},\n",
              " {'step': 86, 'train_loss': 5.422755241394043},\n",
              " {'step': 87, 'train_loss': 5.400096416473389},\n",
              " {'step': 88, 'train_loss': 5.31420373916626},\n",
              " {'step': 89, 'train_loss': 5.216891765594482},\n",
              " {'step': 90, 'train_loss': 5.26539945602417},\n",
              " {'step': 91, 'train_loss': 5.467857837677002},\n",
              " {'step': 92, 'train_loss': 5.467442035675049},\n",
              " {'step': 93, 'train_loss': 5.221518516540527},\n",
              " {'step': 94, 'train_loss': 5.332440376281738},\n",
              " {'step': 95, 'train_loss': 5.321277618408203},\n",
              " {'step': 96, 'train_loss': 5.029416561126709},\n",
              " {'step': 97, 'train_loss': 5.127167224884033},\n",
              " {'step': 98, 'train_loss': 5.405561923980713},\n",
              " {'step': 99, 'train_loss': 5.287512302398682},\n",
              " {'step': 100,\n",
              "  'train_loss': 5.290463447570801,\n",
              "  'valid_loss': 5.823209537778582},\n",
              " {'step': 101, 'train_loss': 5.238887310028076},\n",
              " {'step': 102, 'train_loss': 5.2714009284973145},\n",
              " {'step': 103, 'train_loss': 5.212008953094482},\n",
              " {'step': 104, 'train_loss': 5.323022365570068},\n",
              " {'step': 105, 'train_loss': 5.193583965301514},\n",
              " {'step': 106, 'train_loss': 5.4864277839660645},\n",
              " {'step': 107, 'train_loss': 5.376293659210205},\n",
              " {'step': 108, 'train_loss': 5.0853681564331055},\n",
              " {'step': 109, 'train_loss': 5.334158897399902},\n",
              " {'step': 110, 'train_loss': 5.293378829956055},\n",
              " {'step': 111, 'train_loss': 5.36976432800293},\n",
              " {'step': 112, 'train_loss': 5.273850440979004},\n",
              " {'step': 113, 'train_loss': 5.235997200012207},\n",
              " {'step': 114, 'train_loss': 5.153770923614502},\n",
              " {'step': 115, 'train_loss': 5.2209649085998535},\n",
              " {'step': 116, 'train_loss': 5.247550964355469},\n",
              " {'step': 117, 'train_loss': 5.221922874450684},\n",
              " {'step': 118, 'train_loss': 4.9924235343933105},\n",
              " {'step': 119, 'train_loss': 5.212976455688477},\n",
              " {'step': 120, 'train_loss': 5.02761173248291},\n",
              " {'step': 121, 'train_loss': 5.12086296081543},\n",
              " {'step': 122, 'train_loss': 5.04570198059082},\n",
              " {'step': 123, 'train_loss': 4.8148579597473145},\n",
              " {'step': 124, 'train_loss': 4.896971702575684},\n",
              " {'step': 125, 'train_loss': 5.224151134490967},\n",
              " {'step': 126, 'train_loss': 5.175400733947754},\n",
              " {'step': 127, 'train_loss': 5.05117130279541},\n",
              " {'step': 128, 'train_loss': 5.091390609741211},\n",
              " {'step': 129, 'train_loss': 4.925715446472168},\n",
              " {'step': 130, 'train_loss': 5.087489604949951},\n",
              " {'step': 131, 'train_loss': 5.2539777755737305},\n",
              " {'step': 132, 'train_loss': 5.175881862640381},\n",
              " {'step': 133, 'train_loss': 5.140183925628662},\n",
              " {'step': 134, 'train_loss': 5.064090728759766},\n",
              " {'step': 135, 'train_loss': 5.028682708740234},\n",
              " {'step': 136, 'train_loss': 5.051665782928467},\n",
              " {'step': 137, 'train_loss': 5.214972019195557},\n",
              " {'step': 138, 'train_loss': 5.138067245483398},\n",
              " {'step': 139, 'train_loss': 5.205108642578125},\n",
              " {'step': 140, 'train_loss': 5.162613868713379},\n",
              " {'step': 141, 'train_loss': 5.01164436340332},\n",
              " {'step': 142, 'train_loss': 5.17160177230835},\n",
              " {'step': 143, 'train_loss': 5.042717933654785},\n",
              " {'step': 144, 'train_loss': 5.089645862579346},\n",
              " {'step': 145, 'train_loss': 4.944887161254883},\n",
              " {'step': 146, 'train_loss': 4.9781575202941895},\n",
              " {'step': 147, 'train_loss': 5.105286598205566},\n",
              " {'step': 148, 'train_loss': 4.964589595794678},\n",
              " {'step': 149, 'train_loss': 4.905205249786377},\n",
              " {'step': 150, 'train_loss': 5.1424784660339355},\n",
              " {'step': 151, 'train_loss': 5.141632556915283},\n",
              " {'step': 152, 'train_loss': 4.958339691162109},\n",
              " {'step': 153, 'train_loss': 4.853609561920166},\n",
              " {'step': 154, 'train_loss': 4.959444046020508},\n",
              " {'step': 155, 'train_loss': 4.936411380767822},\n",
              " {'step': 156, 'train_loss': 4.818442344665527},\n",
              " {'step': 157, 'train_loss': 5.241236209869385},\n",
              " {'step': 158, 'train_loss': 4.962329864501953},\n",
              " {'step': 159, 'train_loss': 5.026848316192627},\n",
              " {'step': 160, 'train_loss': 5.144440650939941},\n",
              " {'step': 161, 'train_loss': 5.078807830810547},\n",
              " {'step': 162, 'train_loss': 4.859644889831543},\n",
              " {'step': 163, 'train_loss': 5.066935062408447},\n",
              " {'step': 164, 'train_loss': 4.912227630615234},\n",
              " {'step': 165, 'train_loss': 5.003934383392334},\n",
              " {'step': 166, 'train_loss': 4.848867893218994},\n",
              " {'step': 167, 'train_loss': 4.987781047821045},\n",
              " {'step': 168, 'train_loss': 4.9935736656188965},\n",
              " {'step': 169, 'train_loss': 5.022176742553711},\n",
              " {'step': 170, 'train_loss': 4.874063491821289},\n",
              " {'step': 171, 'train_loss': 4.933993816375732},\n",
              " {'step': 172, 'train_loss': 5.039504051208496},\n",
              " {'step': 173, 'train_loss': 4.98220682144165},\n",
              " {'step': 174, 'train_loss': 4.854319095611572},\n",
              " {'step': 175, 'train_loss': 4.914142608642578},\n",
              " {'step': 176, 'train_loss': 4.790295600891113},\n",
              " {'step': 177, 'train_loss': 4.903184413909912},\n",
              " {'step': 178, 'train_loss': 4.875351428985596},\n",
              " {'step': 179, 'train_loss': 4.936644554138184},\n",
              " {'step': 180, 'train_loss': 4.965722560882568},\n",
              " {'step': 181, 'train_loss': 4.976412773132324},\n",
              " {'step': 182, 'train_loss': 4.751563549041748},\n",
              " {'step': 183, 'train_loss': 4.765707492828369},\n",
              " {'step': 184, 'train_loss': 4.995580673217773},\n",
              " {'step': 185, 'train_loss': 5.074025630950928},\n",
              " {'step': 186, 'train_loss': 4.972367763519287},\n",
              " {'step': 187, 'train_loss': 4.965402126312256},\n",
              " {'step': 188, 'train_loss': 5.014772415161133},\n",
              " {'step': 189, 'train_loss': 4.929333209991455},\n",
              " {'step': 190, 'train_loss': 4.932816028594971},\n",
              " {'step': 191, 'train_loss': 4.781198501586914},\n",
              " {'step': 192, 'train_loss': 4.934109210968018},\n",
              " {'step': 193, 'train_loss': 5.0265045166015625},\n",
              " {'step': 194, 'train_loss': 5.195173740386963},\n",
              " {'step': 195, 'train_loss': 4.8092360496521},\n",
              " {'step': 196, 'train_loss': 4.660788536071777},\n",
              " {'step': 197, 'train_loss': 4.813323020935059},\n",
              " {'step': 198, 'train_loss': 4.9514570236206055},\n",
              " {'step': 199, 'train_loss': 4.915849685668945},\n",
              " {'step': 200,\n",
              "  'train_loss': 5.026140213012695,\n",
              "  'valid_loss': 5.54295426096235},\n",
              " {'step': 201, 'train_loss': 4.932308197021484},\n",
              " {'step': 202, 'train_loss': 4.918108940124512},\n",
              " {'step': 203, 'train_loss': 4.829000473022461},\n",
              " {'step': 204, 'train_loss': 4.817355632781982},\n",
              " {'step': 205, 'train_loss': 4.866188049316406},\n",
              " {'step': 206, 'train_loss': 4.907449722290039},\n",
              " {'step': 207, 'train_loss': 4.80361795425415},\n",
              " {'step': 208, 'train_loss': 4.919430732727051},\n",
              " {'step': 209, 'train_loss': 4.81761360168457},\n",
              " {'step': 210, 'train_loss': 4.859610080718994},\n",
              " {'step': 211, 'train_loss': 4.875446796417236},\n",
              " {'step': 212, 'train_loss': 5.0287017822265625},\n",
              " {'step': 213, 'train_loss': 4.964881896972656},\n",
              " {'step': 214, 'train_loss': 4.9688568115234375},\n",
              " {'step': 215, 'train_loss': 4.816984176635742},\n",
              " {'step': 216, 'train_loss': 4.863687515258789},\n",
              " {'step': 217, 'train_loss': 4.777610778808594},\n",
              " {'step': 218, 'train_loss': 4.986746311187744},\n",
              " {'step': 219, 'train_loss': 4.845912933349609},\n",
              " {'step': 220, 'train_loss': 4.90897798538208},\n",
              " {'step': 221, 'train_loss': 4.796669006347656},\n",
              " {'step': 222, 'train_loss': 5.014331817626953},\n",
              " {'step': 223, 'train_loss': 4.895674705505371},\n",
              " {'step': 224, 'train_loss': 4.723274230957031},\n",
              " {'step': 225, 'train_loss': 4.893627643585205},\n",
              " {'step': 226, 'train_loss': 4.817057132720947},\n",
              " {'step': 227, 'train_loss': 4.849503993988037},\n",
              " {'step': 228, 'train_loss': 4.976110935211182},\n",
              " {'step': 229, 'train_loss': 4.800048351287842},\n",
              " {'step': 230, 'train_loss': 4.795438289642334},\n",
              " {'step': 231, 'train_loss': 4.9782209396362305},\n",
              " {'step': 232, 'train_loss': 4.831854343414307},\n",
              " {'step': 233, 'train_loss': 4.820845127105713},\n",
              " {'step': 234, 'train_loss': 4.777595520019531},\n",
              " {'step': 235, 'train_loss': 4.660221099853516},\n",
              " {'step': 236, 'train_loss': 4.528057098388672},\n",
              " {'step': 237, 'train_loss': 4.685755729675293},\n",
              " {'step': 238, 'train_loss': 4.779863357543945},\n",
              " {'step': 239, 'train_loss': 4.8113203048706055},\n",
              " {'step': 240, 'train_loss': 4.75559663772583},\n",
              " {'step': 241, 'train_loss': 4.9275126457214355},\n",
              " {'step': 242, 'train_loss': 4.928629398345947},\n",
              " {'step': 243, 'train_loss': 4.857390403747559},\n",
              " {'step': 244, 'train_loss': 4.843259334564209},\n",
              " {'step': 245, 'train_loss': 4.868549346923828},\n",
              " {'step': 246, 'train_loss': 5.059941291809082},\n",
              " {'step': 247, 'train_loss': 4.804190158843994},\n",
              " {'step': 248, 'train_loss': 4.7601165771484375},\n",
              " {'step': 249, 'train_loss': 4.896338939666748},\n",
              " {'step': 250, 'train_loss': 4.722661018371582},\n",
              " {'step': 251, 'train_loss': 4.96254825592041},\n",
              " {'step': 252, 'train_loss': 4.694850444793701},\n",
              " {'step': 253, 'train_loss': 4.8591628074646},\n",
              " {'step': 254, 'train_loss': 4.889159202575684},\n",
              " {'step': 255, 'train_loss': 4.760134696960449},\n",
              " {'step': 256, 'train_loss': 4.747522354125977},\n",
              " {'step': 257, 'train_loss': 4.929926872253418},\n",
              " {'step': 258, 'train_loss': 4.8690948486328125},\n",
              " {'step': 259, 'train_loss': 4.858828067779541},\n",
              " {'step': 260, 'train_loss': 4.7294721603393555},\n",
              " {'step': 261, 'train_loss': 4.787950038909912},\n",
              " {'step': 262, 'train_loss': 4.842779636383057},\n",
              " {'step': 263, 'train_loss': 4.808744430541992},\n",
              " {'step': 264, 'train_loss': 4.739518642425537},\n",
              " {'step': 265, 'train_loss': 4.833774089813232},\n",
              " {'step': 266, 'train_loss': 4.875141620635986},\n",
              " {'step': 267, 'train_loss': 4.914432525634766},\n",
              " {'step': 268, 'train_loss': 4.673774242401123},\n",
              " {'step': 269, 'train_loss': 4.784067153930664},\n",
              " {'step': 270, 'train_loss': 4.822796821594238},\n",
              " {'step': 271, 'train_loss': 4.6964111328125},\n",
              " {'step': 272, 'train_loss': 4.671392917633057},\n",
              " {'step': 273, 'train_loss': 4.795265197753906},\n",
              " {'step': 274, 'train_loss': 4.87824010848999},\n",
              " {'step': 275, 'train_loss': 5.004493236541748},\n",
              " {'step': 276, 'train_loss': 4.942490100860596},\n",
              " {'step': 277, 'train_loss': 4.821893215179443},\n",
              " {'step': 278, 'train_loss': 4.8194074630737305},\n",
              " {'step': 279, 'train_loss': 4.701443672180176},\n",
              " {'step': 280, 'train_loss': 4.704490661621094},\n",
              " {'step': 281, 'train_loss': 4.619851589202881},\n",
              " {'step': 282, 'train_loss': 4.598305702209473},\n",
              " {'step': 283, 'train_loss': 4.731791019439697},\n",
              " {'step': 284, 'train_loss': 4.95516300201416},\n",
              " {'step': 285, 'train_loss': 4.704682350158691},\n",
              " {'step': 286, 'train_loss': 4.67237663269043},\n",
              " {'step': 287, 'train_loss': 4.758463382720947},\n",
              " {'step': 288, 'train_loss': 4.7759928703308105},\n",
              " {'step': 289, 'train_loss': 4.697208404541016},\n",
              " {'step': 290, 'train_loss': 4.796821594238281},\n",
              " {'step': 291, 'train_loss': 4.762394428253174},\n",
              " {'step': 292, 'train_loss': 4.700649261474609},\n",
              " {'step': 293, 'train_loss': 4.694566249847412},\n",
              " {'step': 294, 'train_loss': 4.826957702636719},\n",
              " {'step': 295, 'train_loss': 4.593539714813232},\n",
              " {'step': 296, 'train_loss': 4.543375492095947},\n",
              " {'step': 297, 'train_loss': 4.61456298828125},\n",
              " {'step': 298, 'train_loss': 4.617681980133057},\n",
              " {'step': 299, 'train_loss': 4.830827236175537},\n",
              " {'step': 300,\n",
              "  'train_loss': 4.6938581466674805,\n",
              "  'valid_loss': 5.445670938491821},\n",
              " {'step': 301, 'train_loss': 4.844503402709961},\n",
              " {'step': 302, 'train_loss': 4.8401570320129395},\n",
              " {'step': 303, 'train_loss': 4.835399627685547},\n",
              " {'step': 304, 'train_loss': 4.814539432525635},\n",
              " {'step': 305, 'train_loss': 4.7751784324646},\n",
              " {'step': 306, 'train_loss': 4.893603801727295},\n",
              " {'step': 307, 'train_loss': 4.6666178703308105},\n",
              " {'step': 308, 'train_loss': 4.8155083656311035},\n",
              " {'step': 309, 'train_loss': 4.678257465362549},\n",
              " {'step': 310, 'train_loss': 4.709998607635498},\n",
              " {'step': 311, 'train_loss': 4.72310209274292},\n",
              " {'step': 312, 'train_loss': 4.833346843719482},\n",
              " {'step': 313, 'train_loss': 4.725427150726318},\n",
              " {'step': 314, 'train_loss': 4.6124749183654785},\n",
              " {'step': 315, 'train_loss': 4.763779163360596},\n",
              " {'step': 316, 'train_loss': 4.743270397186279},\n",
              " {'step': 317, 'train_loss': 4.588045120239258},\n",
              " {'step': 318, 'train_loss': 4.776163578033447},\n",
              " {'step': 319, 'train_loss': 4.7578935623168945},\n",
              " {'step': 320, 'train_loss': 4.740284442901611},\n",
              " {'step': 321, 'train_loss': 4.875303745269775},\n",
              " {'step': 322, 'train_loss': 4.781793594360352},\n",
              " {'step': 323, 'train_loss': 4.756076335906982},\n",
              " {'step': 324, 'train_loss': 4.640713691711426},\n",
              " {'step': 325, 'train_loss': 4.730323314666748},\n",
              " {'step': 326, 'train_loss': 4.779529571533203},\n",
              " {'step': 327, 'train_loss': 4.7625837326049805},\n",
              " {'step': 328, 'train_loss': 4.666973114013672},\n",
              " {'step': 329, 'train_loss': 4.727555751800537},\n",
              " {'step': 330, 'train_loss': 4.610171794891357},\n",
              " {'step': 331, 'train_loss': 4.745595932006836},\n",
              " {'step': 332, 'train_loss': 4.661873817443848},\n",
              " {'step': 333, 'train_loss': 4.904203414916992},\n",
              " {'step': 334, 'train_loss': 4.791934967041016},\n",
              " {'step': 335, 'train_loss': 4.835606575012207},\n",
              " {'step': 336, 'train_loss': 4.667689323425293},\n",
              " {'step': 337, 'train_loss': 4.656595230102539},\n",
              " {'step': 338, 'train_loss': 4.758028984069824},\n",
              " {'step': 339, 'train_loss': 4.83323860168457},\n",
              " {'step': 340, 'train_loss': 4.627089023590088},\n",
              " {'step': 341, 'train_loss': 4.733526229858398},\n",
              " {'step': 342, 'train_loss': 4.6215620040893555},\n",
              " {'step': 343, 'train_loss': 4.678311347961426},\n",
              " {'step': 344, 'train_loss': 4.756782531738281},\n",
              " {'step': 345, 'train_loss': 4.910965919494629},\n",
              " {'step': 346, 'train_loss': 4.663033485412598},\n",
              " {'step': 347, 'train_loss': 4.709228038787842},\n",
              " {'step': 348, 'train_loss': 4.798034191131592},\n",
              " {'step': 349, 'train_loss': 4.600996971130371},\n",
              " {'step': 350, 'train_loss': 4.628338813781738},\n",
              " {'step': 351, 'train_loss': 4.607990741729736},\n",
              " {'step': 352, 'train_loss': 4.672189712524414},\n",
              " {'step': 353, 'train_loss': 4.723597526550293},\n",
              " {'step': 354, 'train_loss': 4.804142475128174},\n",
              " {'step': 355, 'train_loss': 4.6813836097717285},\n",
              " {'step': 356, 'train_loss': 4.750008583068848},\n",
              " {'step': 357, 'train_loss': 4.729371547698975},\n",
              " {'step': 358, 'train_loss': 4.645566940307617},\n",
              " {'step': 359, 'train_loss': 4.731334686279297},\n",
              " {'step': 360, 'train_loss': 4.661136150360107},\n",
              " {'step': 361, 'train_loss': 4.674532890319824},\n",
              " {'step': 362, 'train_loss': 4.879196643829346},\n",
              " {'step': 363, 'train_loss': 4.634122371673584},\n",
              " {'step': 364, 'train_loss': 4.6652512550354},\n",
              " {'step': 365, 'train_loss': 4.932816982269287},\n",
              " {'step': 366, 'train_loss': 4.87034273147583},\n",
              " {'step': 367, 'train_loss': 4.662930965423584},\n",
              " {'step': 368, 'train_loss': 4.828505516052246},\n",
              " {'step': 369, 'train_loss': 4.670597553253174},\n",
              " {'step': 370, 'train_loss': 4.877627849578857},\n",
              " {'step': 371, 'train_loss': 4.792471408843994},\n",
              " {'step': 372, 'train_loss': 4.819291591644287},\n",
              " {'step': 373, 'train_loss': 4.760438919067383},\n",
              " {'step': 374, 'train_loss': 4.681023120880127},\n",
              " {'step': 375, 'train_loss': 4.764410018920898},\n",
              " {'step': 376, 'train_loss': 4.77895975112915},\n",
              " {'step': 377, 'train_loss': 4.850160121917725},\n",
              " {'step': 378, 'train_loss': 4.759493350982666},\n",
              " {'step': 379, 'train_loss': 4.639034271240234},\n",
              " {'step': 380, 'train_loss': 4.617595672607422},\n",
              " {'step': 381, 'train_loss': 4.633214473724365},\n",
              " {'step': 382, 'train_loss': 4.73839807510376},\n",
              " {'step': 383, 'train_loss': 4.716282367706299},\n",
              " {'step': 384, 'train_loss': 4.610538005828857},\n",
              " {'step': 385, 'train_loss': 4.623270511627197},\n",
              " {'step': 386, 'train_loss': 4.828407287597656},\n",
              " {'step': 387, 'train_loss': 4.797022819519043},\n",
              " {'step': 388, 'train_loss': 4.744808673858643},\n",
              " {'step': 389, 'train_loss': 4.501043319702148},\n",
              " {'step': 390, 'train_loss': 4.644697666168213},\n",
              " {'step': 391, 'train_loss': 4.620615482330322},\n",
              " {'step': 392, 'train_loss': 4.7034406661987305},\n",
              " {'step': 393, 'train_loss': 4.737051486968994},\n",
              " {'step': 394, 'train_loss': 4.779163837432861},\n",
              " {'step': 395, 'train_loss': 4.723454475402832},\n",
              " {'step': 396, 'train_loss': 4.63914680480957},\n",
              " {'step': 397, 'train_loss': 4.774782657623291},\n",
              " {'step': 398, 'train_loss': 4.786055088043213},\n",
              " {'step': 399, 'train_loss': 4.567605495452881},\n",
              " {'step': 400,\n",
              "  'train_loss': 4.6826653480529785,\n",
              "  'valid_loss': 5.346644060952323},\n",
              " {'step': 401, 'train_loss': 4.675041675567627},\n",
              " {'step': 402, 'train_loss': 4.673377513885498},\n",
              " {'step': 403, 'train_loss': 4.552521228790283},\n",
              " {'step': 404, 'train_loss': 4.606475830078125},\n",
              " {'step': 405, 'train_loss': 4.730044364929199},\n",
              " {'step': 406, 'train_loss': 4.654655933380127},\n",
              " {'step': 407, 'train_loss': 4.762310981750488},\n",
              " {'step': 408, 'train_loss': 4.566617012023926},\n",
              " {'step': 409, 'train_loss': 4.638118743896484},\n",
              " {'step': 410, 'train_loss': 4.743715763092041},\n",
              " {'step': 411, 'train_loss': 4.710366249084473},\n",
              " {'step': 412, 'train_loss': 4.77088737487793},\n",
              " {'step': 413, 'train_loss': 4.699418544769287},\n",
              " {'step': 414, 'train_loss': 4.7448506355285645},\n",
              " {'step': 415, 'train_loss': 4.707182884216309},\n",
              " {'step': 416, 'train_loss': 4.767192363739014},\n",
              " {'step': 417, 'train_loss': 4.77849006652832},\n",
              " {'step': 418, 'train_loss': 4.839099884033203},\n",
              " {'step': 419, 'train_loss': 4.701307773590088},\n",
              " {'step': 420, 'train_loss': 4.609561443328857},\n",
              " {'step': 421, 'train_loss': 4.629398822784424},\n",
              " {'step': 422, 'train_loss': 4.607202529907227},\n",
              " {'step': 423, 'train_loss': 4.78108024597168},\n",
              " {'step': 424, 'train_loss': 4.777617931365967},\n",
              " {'step': 425, 'train_loss': 4.722369194030762},\n",
              " {'step': 426, 'train_loss': 4.618376731872559},\n",
              " {'step': 427, 'train_loss': 4.800785541534424},\n",
              " {'step': 428, 'train_loss': 4.6971235275268555},\n",
              " {'step': 429, 'train_loss': 4.618885040283203},\n",
              " {'step': 430, 'train_loss': 4.743460655212402},\n",
              " {'step': 431, 'train_loss': 4.729734897613525},\n",
              " {'step': 432, 'train_loss': 4.6285624504089355},\n",
              " {'step': 433, 'train_loss': 4.685783863067627},\n",
              " {'step': 434, 'train_loss': 4.557346820831299},\n",
              " {'step': 435, 'train_loss': 4.887965202331543},\n",
              " {'step': 436, 'train_loss': 4.740845680236816},\n",
              " {'step': 437, 'train_loss': 4.690654754638672},\n",
              " {'step': 438, 'train_loss': 4.763461112976074},\n",
              " {'step': 439, 'train_loss': 4.6026105880737305},\n",
              " {'step': 440, 'train_loss': 4.816668510437012},\n",
              " {'step': 441, 'train_loss': 4.683244705200195},\n",
              " {'step': 442, 'train_loss': 4.73674201965332},\n",
              " {'step': 443, 'train_loss': 4.699542999267578},\n",
              " {'step': 444, 'train_loss': 4.735312461853027},\n",
              " {'step': 445, 'train_loss': 4.85668420791626},\n",
              " {'step': 446, 'train_loss': 4.636843204498291},\n",
              " {'step': 447, 'train_loss': 4.676257610321045},\n",
              " {'step': 448, 'train_loss': 4.723430156707764},\n",
              " {'step': 449, 'train_loss': 4.532830238342285},\n",
              " {'step': 450, 'train_loss': 4.618477821350098},\n",
              " {'step': 451, 'train_loss': 4.772864818572998},\n",
              " {'step': 452, 'train_loss': 4.573425769805908},\n",
              " {'step': 453, 'train_loss': 4.697084903717041},\n",
              " {'step': 454, 'train_loss': 4.692176818847656},\n",
              " {'step': 455, 'train_loss': 4.77533483505249},\n",
              " {'step': 456, 'train_loss': 4.544423580169678},\n",
              " {'step': 457, 'train_loss': 4.783784866333008},\n",
              " {'step': 458, 'train_loss': 4.724153995513916},\n",
              " {'step': 459, 'train_loss': 4.743695259094238},\n",
              " {'step': 460, 'train_loss': 4.765627384185791},\n",
              " {'step': 461, 'train_loss': 4.806800365447998},\n",
              " {'step': 462, 'train_loss': 4.9186601638793945},\n",
              " {'step': 463, 'train_loss': 4.693702697753906},\n",
              " {'step': 464, 'train_loss': 4.69635009765625},\n",
              " {'step': 465, 'train_loss': 4.7332611083984375},\n",
              " {'step': 466, 'train_loss': 4.677013874053955},\n",
              " {'step': 467, 'train_loss': 4.767759799957275},\n",
              " {'step': 468, 'train_loss': 4.970199108123779},\n",
              " {'step': 469, 'train_loss': 4.514068126678467},\n",
              " {'step': 470, 'train_loss': 4.69742488861084},\n",
              " {'step': 471, 'train_loss': 4.633244514465332},\n",
              " {'step': 472, 'train_loss': 4.631295680999756},\n",
              " {'step': 473, 'train_loss': 4.787206172943115},\n",
              " {'step': 474, 'train_loss': 4.724809169769287},\n",
              " {'step': 475, 'train_loss': 4.551987171173096},\n",
              " {'step': 476, 'train_loss': 4.729552268981934},\n",
              " {'step': 477, 'train_loss': 4.723694324493408},\n",
              " {'step': 478, 'train_loss': 4.9178361892700195},\n",
              " {'step': 479, 'train_loss': 4.810097694396973},\n",
              " {'step': 480, 'train_loss': 4.777570724487305},\n",
              " {'step': 481, 'train_loss': 4.60344934463501},\n",
              " {'step': 482, 'train_loss': 4.664989948272705},\n",
              " {'step': 483, 'train_loss': 4.656327247619629},\n",
              " {'step': 484, 'train_loss': 4.694092273712158},\n",
              " {'step': 485, 'train_loss': 4.655835151672363},\n",
              " {'step': 486, 'train_loss': 4.828627109527588},\n",
              " {'step': 487, 'train_loss': 4.658268451690674},\n",
              " {'step': 488, 'train_loss': 4.660094738006592},\n",
              " {'step': 489, 'train_loss': 4.562456130981445},\n",
              " {'step': 490, 'train_loss': 4.590194225311279},\n",
              " {'step': 491, 'train_loss': 4.624749660491943},\n",
              " {'step': 492, 'train_loss': 4.6636962890625},\n",
              " {'step': 493, 'train_loss': 4.637856960296631},\n",
              " {'step': 494, 'train_loss': 4.659600734710693},\n",
              " {'step': 495, 'train_loss': 4.724188804626465},\n",
              " {'step': 496, 'train_loss': 4.669137954711914},\n",
              " {'step': 497, 'train_loss': 4.66870641708374},\n",
              " {'step': 498, 'train_loss': 4.809542655944824},\n",
              " {'step': 499, 'train_loss': 4.607548713684082},\n",
              " {'step': 500,\n",
              "  'train_loss': 4.636635780334473,\n",
              "  'valid_loss': 5.275369800840106},\n",
              " {'step': 501, 'train_loss': 4.52524995803833},\n",
              " {'step': 502, 'train_loss': 4.737273216247559},\n",
              " {'step': 503, 'train_loss': 4.775355815887451},\n",
              " {'step': 504, 'train_loss': 4.8534440994262695},\n",
              " {'step': 505, 'train_loss': 4.763758182525635},\n",
              " {'step': 506, 'train_loss': 4.7248125076293945},\n",
              " {'step': 507, 'train_loss': 4.811273097991943},\n",
              " {'step': 508, 'train_loss': 4.729446887969971},\n",
              " {'step': 509, 'train_loss': 4.712453365325928},\n",
              " {'step': 510, 'train_loss': 4.755614280700684},\n",
              " {'step': 511, 'train_loss': 4.683717250823975},\n",
              " {'step': 512, 'train_loss': 4.692434787750244},\n",
              " {'step': 513, 'train_loss': 4.75631856918335},\n",
              " {'step': 514, 'train_loss': 4.684567928314209},\n",
              " {'step': 515, 'train_loss': 4.561679840087891},\n",
              " {'step': 516, 'train_loss': 4.88765287399292},\n",
              " {'step': 517, 'train_loss': 4.708027362823486},\n",
              " {'step': 518, 'train_loss': 4.745851039886475},\n",
              " {'step': 519, 'train_loss': 4.874701023101807},\n",
              " {'step': 520, 'train_loss': 4.913914680480957},\n",
              " {'step': 521, 'train_loss': 4.7921366691589355},\n",
              " {'step': 522, 'train_loss': 4.801284313201904},\n",
              " {'step': 523, 'train_loss': 4.7007155418396},\n",
              " {'step': 524, 'train_loss': 4.766933441162109},\n",
              " {'step': 525, 'train_loss': 4.820535182952881},\n",
              " {'step': 526, 'train_loss': 4.588505744934082},\n",
              " {'step': 527, 'train_loss': 4.689375400543213},\n",
              " {'step': 528, 'train_loss': 4.5768327713012695},\n",
              " {'step': 529, 'train_loss': 4.575439453125},\n",
              " {'step': 530, 'train_loss': 4.754021167755127},\n",
              " {'step': 531, 'train_loss': 4.823306560516357},\n",
              " {'step': 532, 'train_loss': 4.711146831512451},\n",
              " {'step': 533, 'train_loss': 4.746954917907715},\n",
              " {'step': 534, 'train_loss': 4.791675567626953},\n",
              " {'step': 535, 'train_loss': 4.699037075042725},\n",
              " {'step': 536, 'train_loss': 4.974743366241455},\n",
              " {'step': 537, 'train_loss': 4.6901631355285645},\n",
              " {'step': 538, 'train_loss': 4.581165313720703},\n",
              " {'step': 539, 'train_loss': 4.633076190948486},\n",
              " {'step': 540, 'train_loss': 4.651427268981934},\n",
              " {'step': 541, 'train_loss': 4.799322128295898},\n",
              " {'step': 542, 'train_loss': 4.665083408355713},\n",
              " {'step': 543, 'train_loss': 4.790781497955322},\n",
              " {'step': 544, 'train_loss': 4.832665920257568},\n",
              " {'step': 545, 'train_loss': 4.812819480895996},\n",
              " {'step': 546, 'train_loss': 4.63370943069458},\n",
              " {'step': 547, 'train_loss': 4.7549614906311035},\n",
              " {'step': 548, 'train_loss': 4.888620853424072},\n",
              " {'step': 549, 'train_loss': 4.775920391082764},\n",
              " {'step': 550, 'train_loss': 4.640279293060303},\n",
              " {'step': 551, 'train_loss': 4.687062740325928},\n",
              " {'step': 552, 'train_loss': 4.746585369110107},\n",
              " {'step': 553, 'train_loss': 4.63829231262207},\n",
              " {'step': 554, 'train_loss': 4.798140048980713},\n",
              " {'step': 555, 'train_loss': 4.670523166656494},\n",
              " {'step': 556, 'train_loss': 4.645259380340576},\n",
              " {'step': 557, 'train_loss': 4.872668743133545},\n",
              " {'step': 558, 'train_loss': 4.681727409362793},\n",
              " {'step': 559, 'train_loss': 4.782008647918701},\n",
              " {'step': 560, 'train_loss': 4.636221408843994},\n",
              " {'step': 561, 'train_loss': 4.775344371795654},\n",
              " {'step': 562, 'train_loss': 4.7664475440979},\n",
              " {'step': 563, 'train_loss': 4.753025531768799},\n",
              " {'step': 564, 'train_loss': 4.747917175292969},\n",
              " {'step': 565, 'train_loss': 4.708774566650391},\n",
              " {'step': 566, 'train_loss': 4.633457660675049},\n",
              " {'step': 567, 'train_loss': 4.66802453994751},\n",
              " {'step': 568, 'train_loss': 4.698133945465088},\n",
              " {'step': 569, 'train_loss': 4.73972749710083},\n",
              " {'step': 570, 'train_loss': 4.783381938934326},\n",
              " {'step': 571, 'train_loss': 4.695085048675537},\n",
              " {'step': 572, 'train_loss': 4.799773216247559},\n",
              " {'step': 573, 'train_loss': 4.707979679107666},\n",
              " {'step': 574, 'train_loss': 4.702939510345459},\n",
              " {'step': 575, 'train_loss': 4.735695838928223},\n",
              " {'step': 576, 'train_loss': 4.734930038452148},\n",
              " {'step': 577, 'train_loss': 4.649556636810303},\n",
              " {'step': 578, 'train_loss': 4.8852152824401855},\n",
              " {'step': 579, 'train_loss': 4.727743625640869},\n",
              " {'step': 580, 'train_loss': 4.747348308563232},\n",
              " {'step': 581, 'train_loss': 4.632375717163086},\n",
              " {'step': 582, 'train_loss': 4.591567039489746},\n",
              " {'step': 583, 'train_loss': 4.756657123565674},\n",
              " {'step': 584, 'train_loss': 4.710386276245117},\n",
              " {'step': 585, 'train_loss': 4.7458343505859375},\n",
              " {'step': 586, 'train_loss': 4.693596363067627},\n",
              " {'step': 587, 'train_loss': 4.782123565673828},\n",
              " {'step': 588, 'train_loss': 4.728944301605225},\n",
              " {'step': 589, 'train_loss': 4.767319202423096},\n",
              " {'step': 590, 'train_loss': 4.7579665184021},\n",
              " {'step': 591, 'train_loss': 4.652619361877441},\n",
              " {'step': 592, 'train_loss': 4.816257953643799},\n",
              " {'step': 593, 'train_loss': 4.6470770835876465},\n",
              " {'step': 594, 'train_loss': 4.93497896194458},\n",
              " {'step': 595, 'train_loss': 4.620888710021973},\n",
              " {'step': 596, 'train_loss': 4.869086742401123},\n",
              " {'step': 597, 'train_loss': 4.726615905761719},\n",
              " {'step': 598, 'train_loss': 4.882898330688477},\n",
              " {'step': 599, 'train_loss': 4.753476142883301},\n",
              " {'step': 600,\n",
              "  'train_loss': 4.749767780303955,\n",
              "  'valid_loss': 5.293262243270874},\n",
              " {'step': 601, 'train_loss': 4.835971355438232},\n",
              " {'step': 602, 'train_loss': 4.827794075012207},\n",
              " {'step': 603, 'train_loss': 4.913280487060547},\n",
              " {'step': 604, 'train_loss': 4.7321553230285645},\n",
              " {'step': 605, 'train_loss': 4.804868698120117},\n",
              " {'step': 606, 'train_loss': 4.86391019821167},\n",
              " {'step': 607, 'train_loss': 4.60609245300293},\n",
              " {'step': 608, 'train_loss': 4.795348167419434},\n",
              " {'step': 609, 'train_loss': 4.834147930145264},\n",
              " {'step': 610, 'train_loss': 4.80106258392334},\n",
              " {'step': 611, 'train_loss': 4.893710136413574},\n",
              " {'step': 612, 'train_loss': 4.779280662536621},\n",
              " {'step': 613, 'train_loss': 4.785711288452148},\n",
              " {'step': 614, 'train_loss': 4.698680400848389},\n",
              " {'step': 615, 'train_loss': 4.810117244720459},\n",
              " {'step': 616, 'train_loss': 4.642062187194824},\n",
              " {'step': 617, 'train_loss': 4.83765983581543},\n",
              " {'step': 618, 'train_loss': 4.827215671539307},\n",
              " {'step': 619, 'train_loss': 4.839496612548828},\n",
              " {'step': 620, 'train_loss': 4.8108744621276855},\n",
              " {'step': 621, 'train_loss': 4.915859699249268},\n",
              " {'step': 622, 'train_loss': 4.881525039672852},\n",
              " {'step': 623, 'train_loss': 4.7330427169799805},\n",
              " {'step': 624, 'train_loss': 4.744163513183594},\n",
              " {'step': 625, 'train_loss': 4.860647201538086},\n",
              " {'step': 626, 'train_loss': 4.84774112701416},\n",
              " {'step': 627, 'train_loss': 4.867400646209717},\n",
              " {'step': 628, 'train_loss': 4.956194877624512},\n",
              " {'step': 629, 'train_loss': 4.847441673278809},\n",
              " {'step': 630, 'train_loss': 4.820918560028076},\n",
              " {'step': 631, 'train_loss': 4.6578264236450195},\n",
              " {'step': 632, 'train_loss': 4.798579216003418},\n",
              " {'step': 633, 'train_loss': 4.738925457000732},\n",
              " {'step': 634, 'train_loss': 4.897169589996338},\n",
              " {'step': 635, 'train_loss': 4.8653564453125},\n",
              " {'step': 636, 'train_loss': 4.974111080169678},\n",
              " {'step': 637, 'train_loss': 4.985699653625488},\n",
              " {'step': 638, 'train_loss': 4.814745903015137},\n",
              " {'step': 639, 'train_loss': 4.8235859870910645},\n",
              " {'step': 640, 'train_loss': 4.8500285148620605},\n",
              " {'step': 641, 'train_loss': 4.945553302764893},\n",
              " {'step': 642, 'train_loss': 4.889034271240234},\n",
              " {'step': 643, 'train_loss': 4.834896087646484},\n",
              " {'step': 644, 'train_loss': 4.986661434173584},\n",
              " {'step': 645, 'train_loss': 4.990405559539795},\n",
              " {'step': 646, 'train_loss': 5.175078868865967},\n",
              " {'step': 647, 'train_loss': 5.1001362800598145},\n",
              " {'step': 648, 'train_loss': 5.2336249351501465},\n",
              " {'step': 649, 'train_loss': 5.14789342880249},\n",
              " {'step': 650, 'train_loss': 9.109679222106934},\n",
              " {'step': 651, 'train_loss': 7.004627227783203},\n",
              " {'step': 652, 'train_loss': 5.84831428527832},\n",
              " {'step': 653, 'train_loss': 4.887032985687256},\n",
              " {'step': 654, 'train_loss': 4.397239685058594},\n",
              " {'step': 655, 'train_loss': 5.090844631195068},\n",
              " {'step': 656, 'train_loss': 4.93619966506958},\n",
              " {'step': 657, 'train_loss': 4.705620765686035},\n",
              " {'step': 658, 'train_loss': 4.981796741485596},\n",
              " {'step': 659, 'train_loss': 4.723294258117676},\n",
              " {'step': 660, 'train_loss': 4.614151954650879},\n",
              " {'step': 661, 'train_loss': 4.352842330932617},\n",
              " {'step': 662, 'train_loss': 4.525052547454834},\n",
              " {'step': 663, 'train_loss': 4.619803428649902},\n",
              " {'step': 664, 'train_loss': 4.788598537445068},\n",
              " {'step': 665, 'train_loss': 4.444990158081055},\n",
              " {'step': 666, 'train_loss': 4.529276371002197},\n",
              " {'step': 667, 'train_loss': 4.626638412475586},\n",
              " {'step': 668, 'train_loss': 4.334490776062012},\n",
              " {'step': 669, 'train_loss': 4.6343560218811035},\n",
              " {'step': 670, 'train_loss': 4.433805465698242},\n",
              " {'step': 671, 'train_loss': 4.498913288116455},\n",
              " {'step': 672, 'train_loss': 4.587981224060059},\n",
              " {'step': 673, 'train_loss': 4.668491363525391},\n",
              " {'step': 674, 'train_loss': 4.577359676361084},\n",
              " {'step': 675, 'train_loss': 4.510356426239014},\n",
              " {'step': 676, 'train_loss': 4.4756669998168945},\n",
              " {'step': 677, 'train_loss': 4.285432815551758},\n",
              " {'step': 678, 'train_loss': 4.373899459838867},\n",
              " {'step': 679, 'train_loss': 4.371013164520264},\n",
              " {'step': 680, 'train_loss': 4.463187217712402},\n",
              " {'step': 681, 'train_loss': 4.528497219085693},\n",
              " {'step': 682, 'train_loss': 4.391573905944824},\n",
              " {'step': 683, 'train_loss': 4.39181661605835},\n",
              " {'step': 684, 'train_loss': 4.298435688018799},\n",
              " {'step': 685, 'train_loss': 4.488317966461182},\n",
              " {'step': 686, 'train_loss': 4.546215534210205},\n",
              " {'step': 687, 'train_loss': 4.377556324005127},\n",
              " {'step': 688, 'train_loss': 4.766483306884766},\n",
              " {'step': 689, 'train_loss': 4.543011665344238},\n",
              " {'step': 690, 'train_loss': 4.271510124206543},\n",
              " {'step': 691, 'train_loss': 4.209789752960205},\n",
              " {'step': 692, 'train_loss': 4.364612579345703},\n",
              " {'step': 693, 'train_loss': 4.350624084472656},\n",
              " {'step': 694, 'train_loss': 4.225891590118408},\n",
              " {'step': 695, 'train_loss': 4.340835094451904},\n",
              " {'step': 696, 'train_loss': 4.404979228973389},\n",
              " {'step': 697, 'train_loss': 4.592503547668457},\n",
              " {'step': 698, 'train_loss': 4.656270503997803},\n",
              " {'step': 699, 'train_loss': 4.532431125640869},\n",
              " {'step': 700,\n",
              "  'train_loss': 4.434880256652832,\n",
              "  'valid_loss': 4.826259810583932},\n",
              " {'step': 701, 'train_loss': 4.623404502868652},\n",
              " {'step': 702, 'train_loss': 4.579867839813232},\n",
              " {'step': 703, 'train_loss': 4.1964945793151855},\n",
              " {'step': 704, 'train_loss': 4.292031764984131},\n",
              " {'step': 705, 'train_loss': 4.572146415710449},\n",
              " {'step': 706, 'train_loss': 4.564513206481934},\n",
              " {'step': 707, 'train_loss': 4.266706466674805},\n",
              " {'step': 708, 'train_loss': 4.331949710845947},\n",
              " {'step': 709, 'train_loss': 4.270078182220459},\n",
              " {'step': 710, 'train_loss': 4.5193562507629395},\n",
              " {'step': 711, 'train_loss': 4.3424506187438965},\n",
              " {'step': 712, 'train_loss': 4.260861396789551},\n",
              " {'step': 713, 'train_loss': 4.256899356842041},\n",
              " {'step': 714, 'train_loss': 4.439578056335449},\n",
              " {'step': 715, 'train_loss': 4.573756694793701},\n",
              " {'step': 716, 'train_loss': 4.494505882263184},\n",
              " {'step': 717, 'train_loss': 4.320614337921143},\n",
              " {'step': 718, 'train_loss': 4.442336082458496},\n",
              " {'step': 719, 'train_loss': 4.599659442901611},\n",
              " {'step': 720, 'train_loss': 4.533692359924316},\n",
              " {'step': 721, 'train_loss': 4.3355255126953125},\n",
              " {'step': 722, 'train_loss': 4.407537460327148},\n",
              " {'step': 723, 'train_loss': 4.417603015899658},\n",
              " {'step': 724, 'train_loss': 4.680809020996094},\n",
              " {'step': 725, 'train_loss': 4.45203161239624},\n",
              " {'step': 726, 'train_loss': 4.526670455932617},\n",
              " {'step': 727, 'train_loss': 4.474836349487305},\n",
              " {'step': 728, 'train_loss': 4.009507656097412},\n",
              " {'step': 729, 'train_loss': 4.4461140632629395},\n",
              " {'step': 730, 'train_loss': 4.382490634918213},\n",
              " {'step': 731, 'train_loss': 4.332301616668701},\n",
              " {'step': 732, 'train_loss': 4.416817665100098},\n",
              " {'step': 733, 'train_loss': 4.6189775466918945},\n",
              " {'step': 734, 'train_loss': 4.516356945037842},\n",
              " {'step': 735, 'train_loss': 4.4319376945495605},\n",
              " {'step': 736, 'train_loss': 4.516080379486084},\n",
              " {'step': 737, 'train_loss': 4.428802967071533},\n",
              " {'step': 738, 'train_loss': 4.346526145935059},\n",
              " {'step': 739, 'train_loss': 4.391401767730713},\n",
              " {'step': 740, 'train_loss': 4.450401782989502},\n",
              " {'step': 741, 'train_loss': 4.5067315101623535},\n",
              " {'step': 742, 'train_loss': 4.314320087432861},\n",
              " {'step': 743, 'train_loss': 4.505476951599121},\n",
              " {'step': 744, 'train_loss': 4.434414386749268},\n",
              " {'step': 745, 'train_loss': 4.150450229644775},\n",
              " {'step': 746, 'train_loss': 4.3159074783325195},\n",
              " {'step': 747, 'train_loss': 4.459837913513184},\n",
              " {'step': 748, 'train_loss': 4.426249027252197},\n",
              " {'step': 749, 'train_loss': 4.482034206390381},\n",
              " {'step': 750, 'train_loss': 4.392688274383545},\n",
              " {'step': 751, 'train_loss': 4.453463077545166},\n",
              " {'step': 752, 'train_loss': 4.262679576873779},\n",
              " {'step': 753, 'train_loss': 4.572542667388916},\n",
              " {'step': 754, 'train_loss': 4.412543773651123},\n",
              " {'step': 755, 'train_loss': 4.653314113616943},\n",
              " {'step': 756, 'train_loss': 4.535012722015381},\n",
              " {'step': 757, 'train_loss': 4.246656894683838},\n",
              " {'step': 758, 'train_loss': 4.482542037963867},\n",
              " {'step': 759, 'train_loss': 4.4788994789123535},\n",
              " {'step': 760, 'train_loss': 4.5109968185424805},\n",
              " {'step': 761, 'train_loss': 4.3874969482421875},\n",
              " {'step': 762, 'train_loss': 4.447875499725342},\n",
              " {'step': 763, 'train_loss': 4.343556880950928},\n",
              " {'step': 764, 'train_loss': 4.399359703063965},\n",
              " {'step': 765, 'train_loss': 4.352089881896973},\n",
              " {'step': 766, 'train_loss': 4.392806053161621},\n",
              " {'step': 767, 'train_loss': 4.2448859214782715},\n",
              " {'step': 768, 'train_loss': 4.42279052734375},\n",
              " {'step': 769, 'train_loss': 4.307247638702393},\n",
              " {'step': 770, 'train_loss': 4.470232009887695},\n",
              " {'step': 771, 'train_loss': 4.235327243804932},\n",
              " {'step': 772, 'train_loss': 4.096709728240967},\n",
              " {'step': 773, 'train_loss': 4.106789588928223},\n",
              " {'step': 774, 'train_loss': 4.4796671867370605},\n",
              " {'step': 775, 'train_loss': 4.438159465789795},\n",
              " {'step': 776, 'train_loss': 4.368139743804932},\n",
              " {'step': 777, 'train_loss': 4.262160301208496},\n",
              " {'step': 778, 'train_loss': 4.22482442855835},\n",
              " {'step': 779, 'train_loss': 4.356376647949219},\n",
              " {'step': 780, 'train_loss': 4.5780768394470215},\n",
              " {'step': 781, 'train_loss': 4.504478454589844},\n",
              " {'step': 782, 'train_loss': 4.420700550079346},\n",
              " {'step': 783, 'train_loss': 4.3714280128479},\n",
              " {'step': 784, 'train_loss': 4.38604736328125},\n",
              " {'step': 785, 'train_loss': 4.332695484161377},\n",
              " {'step': 786, 'train_loss': 4.510317325592041},\n",
              " {'step': 787, 'train_loss': 4.487914085388184},\n",
              " {'step': 788, 'train_loss': 4.527728080749512},\n",
              " {'step': 789, 'train_loss': 4.524243354797363},\n",
              " {'step': 790, 'train_loss': 4.313713550567627},\n",
              " {'step': 791, 'train_loss': 4.475809097290039},\n",
              " {'step': 792, 'train_loss': 4.376941680908203},\n",
              " {'step': 793, 'train_loss': 4.299545764923096},\n",
              " {'step': 794, 'train_loss': 4.294064044952393},\n",
              " {'step': 795, 'train_loss': 4.217931747436523},\n",
              " {'step': 796, 'train_loss': 4.50429105758667},\n",
              " {'step': 797, 'train_loss': 4.262434482574463},\n",
              " {'step': 798, 'train_loss': 4.194103240966797},\n",
              " {'step': 799, 'train_loss': 4.512797832489014},\n",
              " {'step': 800,\n",
              "  'train_loss': 4.468797206878662,\n",
              "  'valid_loss': 5.106768996374948},\n",
              " {'step': 801, 'train_loss': 4.300169467926025},\n",
              " {'step': 802, 'train_loss': 4.2628655433654785},\n",
              " {'step': 803, 'train_loss': 4.268305778503418},\n",
              " {'step': 804, 'train_loss': 4.2831268310546875},\n",
              " {'step': 805, 'train_loss': 4.19259786605835},\n",
              " {'step': 806, 'train_loss': 4.5943193435668945},\n",
              " {'step': 807, 'train_loss': 4.362175941467285},\n",
              " {'step': 808, 'train_loss': 4.345180511474609},\n",
              " {'step': 809, 'train_loss': 4.629295825958252},\n",
              " {'step': 810, 'train_loss': 4.466188907623291},\n",
              " {'step': 811, 'train_loss': 4.216412544250488},\n",
              " {'step': 812, 'train_loss': 4.446636199951172},\n",
              " {'step': 813, 'train_loss': 4.268394470214844},\n",
              " {'step': 814, 'train_loss': 4.430345058441162},\n",
              " {'step': 815, 'train_loss': 4.201312065124512},\n",
              " {'step': 816, 'train_loss': 4.4182844161987305},\n",
              " {'step': 817, 'train_loss': 4.363307476043701},\n",
              " {'step': 818, 'train_loss': 4.528223514556885},\n",
              " {'step': 819, 'train_loss': 4.424612045288086},\n",
              " {'step': 820, 'train_loss': 4.3464035987854},\n",
              " {'step': 821, 'train_loss': 4.39862060546875},\n",
              " {'step': 822, 'train_loss': 4.323718547821045},\n",
              " {'step': 823, 'train_loss': 4.295719146728516},\n",
              " {'step': 824, 'train_loss': 4.230048656463623},\n",
              " {'step': 825, 'train_loss': 4.181216716766357},\n",
              " {'step': 826, 'train_loss': 4.22067403793335},\n",
              " {'step': 827, 'train_loss': 4.239110946655273},\n",
              " {'step': 828, 'train_loss': 4.446796417236328},\n",
              " {'step': 829, 'train_loss': 4.380545139312744},\n",
              " {'step': 830, 'train_loss': 4.363830089569092},\n",
              " {'step': 831, 'train_loss': 4.10322380065918},\n",
              " {'step': 832, 'train_loss': 4.134634494781494},\n",
              " {'step': 833, 'train_loss': 4.359652042388916},\n",
              " {'step': 834, 'train_loss': 4.520097732543945},\n",
              " {'step': 835, 'train_loss': 4.423554420471191},\n",
              " {'step': 836, 'train_loss': 4.384646415710449},\n",
              " {'step': 837, 'train_loss': 4.4849534034729},\n",
              " {'step': 838, 'train_loss': 4.301294326782227},\n",
              " {'step': 839, 'train_loss': 4.43770694732666},\n",
              " {'step': 840, 'train_loss': 4.2197418212890625},\n",
              " {'step': 841, 'train_loss': 4.322351932525635},\n",
              " {'step': 842, 'train_loss': 4.43754768371582},\n",
              " {'step': 843, 'train_loss': 4.690217018127441},\n",
              " {'step': 844, 'train_loss': 4.27587890625},\n",
              " {'step': 845, 'train_loss': 4.084646224975586},\n",
              " {'step': 846, 'train_loss': 4.245536804199219},\n",
              " {'step': 847, 'train_loss': 4.500897407531738},\n",
              " {'step': 848, 'train_loss': 4.308292865753174},\n",
              " {'step': 849, 'train_loss': 4.567070007324219},\n",
              " {'step': 850, 'train_loss': 4.391465663909912},\n",
              " {'step': 851, 'train_loss': 4.36925745010376},\n",
              " {'step': 852, 'train_loss': 4.266512870788574},\n",
              " {'step': 853, 'train_loss': 4.269679546356201},\n",
              " {'step': 854, 'train_loss': 4.365640640258789},\n",
              " {'step': 855, 'train_loss': 4.417253017425537},\n",
              " {'step': 856, 'train_loss': 4.285833358764648},\n",
              " {'step': 857, 'train_loss': 4.367757320404053},\n",
              " {'step': 858, 'train_loss': 4.302289962768555},\n",
              " {'step': 859, 'train_loss': 4.372890949249268},\n",
              " {'step': 860, 'train_loss': 4.383955955505371},\n",
              " {'step': 861, 'train_loss': 4.514763832092285},\n",
              " {'step': 862, 'train_loss': 4.472640514373779},\n",
              " {'step': 863, 'train_loss': 4.440080165863037},\n",
              " {'step': 864, 'train_loss': 4.4010515213012695},\n",
              " {'step': 865, 'train_loss': 4.367393970489502},\n",
              " {'step': 866, 'train_loss': 4.307084560394287},\n",
              " {'step': 867, 'train_loss': 4.468810081481934},\n",
              " {'step': 868, 'train_loss': 4.3804931640625},\n",
              " {'step': 869, 'train_loss': 4.408309459686279},\n",
              " {'step': 870, 'train_loss': 4.21518087387085},\n",
              " {'step': 871, 'train_loss': 4.538379669189453},\n",
              " {'step': 872, 'train_loss': 4.454352855682373},\n",
              " {'step': 873, 'train_loss': 4.313803195953369},\n",
              " {'step': 874, 'train_loss': 4.4067912101745605},\n",
              " {'step': 875, 'train_loss': 4.339052677154541},\n",
              " {'step': 876, 'train_loss': 4.388404369354248},\n",
              " {'step': 877, 'train_loss': 4.524081230163574},\n",
              " {'step': 878, 'train_loss': 4.329559803009033},\n",
              " {'step': 879, 'train_loss': 4.293783664703369},\n",
              " {'step': 880, 'train_loss': 4.496062278747559},\n",
              " {'step': 881, 'train_loss': 4.3510613441467285},\n",
              " {'step': 882, 'train_loss': 4.266261100769043},\n",
              " {'step': 883, 'train_loss': 4.302517414093018},\n",
              " {'step': 884, 'train_loss': 4.2572808265686035},\n",
              " {'step': 885, 'train_loss': 4.101836681365967},\n",
              " {'step': 886, 'train_loss': 4.217494964599609},\n",
              " {'step': 887, 'train_loss': 4.329551696777344},\n",
              " {'step': 888, 'train_loss': 4.329798698425293},\n",
              " {'step': 889, 'train_loss': 4.346057891845703},\n",
              " {'step': 890, 'train_loss': 4.512980937957764},\n",
              " {'step': 891, 'train_loss': 4.466795921325684},\n",
              " {'step': 892, 'train_loss': 4.348085880279541},\n",
              " {'step': 893, 'train_loss': 4.414681434631348},\n",
              " {'step': 894, 'train_loss': 4.402318000793457},\n",
              " {'step': 895, 'train_loss': 4.645906925201416},\n",
              " {'step': 896, 'train_loss': 4.347723484039307},\n",
              " {'step': 897, 'train_loss': 4.343084812164307},\n",
              " {'step': 898, 'train_loss': 4.420262336730957},\n",
              " {'step': 899, 'train_loss': 4.305126190185547},\n",
              " {'step': 900,\n",
              "  'train_loss': 4.568698406219482,\n",
              "  'valid_loss': 4.9592933859143935},\n",
              " {'step': 901, 'train_loss': 4.190789222717285},\n",
              " {'step': 902, 'train_loss': 4.409821033477783},\n",
              " {'step': 903, 'train_loss': 4.40513801574707},\n",
              " {'step': 904, 'train_loss': 4.3235650062561035},\n",
              " {'step': 905, 'train_loss': 4.282802581787109},\n",
              " {'step': 906, 'train_loss': 4.522090435028076},\n",
              " {'step': 907, 'train_loss': 4.474932670593262},\n",
              " {'step': 908, 'train_loss': 4.444377422332764},\n",
              " {'step': 909, 'train_loss': 4.347197532653809},\n",
              " {'step': 910, 'train_loss': 4.3920793533325195},\n",
              " {'step': 911, 'train_loss': 4.445748329162598},\n",
              " {'step': 912, 'train_loss': 4.385473728179932},\n",
              " {'step': 913, 'train_loss': 4.318730354309082},\n",
              " {'step': 914, 'train_loss': 4.432267665863037},\n",
              " {'step': 915, 'train_loss': 4.490477561950684},\n",
              " {'step': 916, 'train_loss': 4.43775749206543},\n",
              " {'step': 917, 'train_loss': 4.245631694793701},\n",
              " {'step': 918, 'train_loss': 4.3666582107543945},\n",
              " {'step': 919, 'train_loss': 4.435795783996582},\n",
              " {'step': 920, 'train_loss': 4.232016086578369},\n",
              " {'step': 921, 'train_loss': 4.3002424240112305},\n",
              " {'step': 922, 'train_loss': 4.4201459884643555},\n",
              " {'step': 923, 'train_loss': 4.419990539550781},\n",
              " {'step': 924, 'train_loss': 4.502818584442139},\n",
              " {'step': 925, 'train_loss': 4.481664657592773},\n",
              " {'step': 926, 'train_loss': 4.408269882202148},\n",
              " {'step': 927, 'train_loss': 4.366469383239746},\n",
              " {'step': 928, 'train_loss': 4.2590436935424805},\n",
              " {'step': 929, 'train_loss': 4.305606842041016},\n",
              " {'step': 930, 'train_loss': 4.242644309997559},\n",
              " {'step': 931, 'train_loss': 4.14793586730957},\n",
              " {'step': 932, 'train_loss': 4.27426815032959},\n",
              " {'step': 933, 'train_loss': 4.539551734924316},\n",
              " {'step': 934, 'train_loss': 4.329168796539307},\n",
              " {'step': 935, 'train_loss': 4.290035247802734},\n",
              " {'step': 936, 'train_loss': 4.310324192047119},\n",
              " {'step': 937, 'train_loss': 4.426572799682617},\n",
              " {'step': 938, 'train_loss': 4.236004829406738},\n",
              " {'step': 939, 'train_loss': 4.384681224822998},\n",
              " {'step': 940, 'train_loss': 4.323431968688965},\n",
              " {'step': 941, 'train_loss': 4.311143398284912},\n",
              " {'step': 942, 'train_loss': 4.3495659828186035},\n",
              " {'step': 943, 'train_loss': 4.449721813201904},\n",
              " {'step': 944, 'train_loss': 4.218267917633057},\n",
              " {'step': 945, 'train_loss': 4.173862934112549},\n",
              " {'step': 946, 'train_loss': 4.251789093017578},\n",
              " {'step': 947, 'train_loss': 4.232183456420898},\n",
              " {'step': 948, 'train_loss': 4.427674293518066},\n",
              " {'step': 949, 'train_loss': 4.241252422332764},\n",
              " {'step': 950, 'train_loss': 4.370894432067871},\n",
              " {'step': 951, 'train_loss': 4.503661632537842},\n",
              " {'step': 952, 'train_loss': 4.520747661590576},\n",
              " {'step': 953, 'train_loss': 4.464183330535889},\n",
              " {'step': 954, 'train_loss': 4.320326805114746},\n",
              " {'step': 955, 'train_loss': 4.507665634155273},\n",
              " {'step': 956, 'train_loss': 4.325619220733643},\n",
              " {'step': 957, 'train_loss': 4.421635627746582},\n",
              " {'step': 958, 'train_loss': 4.206228733062744},\n",
              " {'step': 959, 'train_loss': 4.279170513153076},\n",
              " {'step': 960, 'train_loss': 4.320297718048096},\n",
              " {'step': 961, 'train_loss': 4.431244373321533},\n",
              " {'step': 962, 'train_loss': 4.393827438354492},\n",
              " {'step': 963, 'train_loss': 4.209045886993408},\n",
              " {'step': 964, 'train_loss': 4.3530659675598145},\n",
              " {'step': 965, 'train_loss': 4.420654296875},\n",
              " {'step': 966, 'train_loss': 4.2473297119140625},\n",
              " {'step': 967, 'train_loss': 4.412833213806152},\n",
              " {'step': 968, 'train_loss': 4.388889312744141},\n",
              " {'step': 969, 'train_loss': 4.3958001136779785},\n",
              " {'step': 970, 'train_loss': 4.430582046508789},\n",
              " {'step': 971, 'train_loss': 4.3596649169921875},\n",
              " {'step': 972, 'train_loss': 4.407469272613525},\n",
              " {'step': 973, 'train_loss': 4.28360652923584},\n",
              " {'step': 974, 'train_loss': 4.298564434051514},\n",
              " {'step': 975, 'train_loss': 4.465524673461914},\n",
              " {'step': 976, 'train_loss': 4.465251445770264},\n",
              " {'step': 977, 'train_loss': 4.3864827156066895},\n",
              " {'step': 978, 'train_loss': 4.350946426391602},\n",
              " {'step': 979, 'train_loss': 4.290414333343506},\n",
              " {'step': 980, 'train_loss': 4.3616228103637695},\n",
              " {'step': 981, 'train_loss': 4.264698505401611},\n",
              " {'step': 982, 'train_loss': 4.600488662719727},\n",
              " {'step': 983, 'train_loss': 4.448400497436523},\n",
              " {'step': 984, 'train_loss': 4.434776782989502},\n",
              " {'step': 985, 'train_loss': 4.259401321411133},\n",
              " {'step': 986, 'train_loss': 4.403656482696533},\n",
              " {'step': 987, 'train_loss': 4.3763532638549805},\n",
              " {'step': 988, 'train_loss': 4.477755546569824},\n",
              " {'step': 989, 'train_loss': 4.260756015777588},\n",
              " {'step': 990, 'train_loss': 4.395512580871582},\n",
              " {'step': 991, 'train_loss': 4.296439170837402},\n",
              " {'step': 992, 'train_loss': 4.393542289733887},\n",
              " {'step': 993, 'train_loss': 4.442497730255127},\n",
              " {'step': 994, 'train_loss': 4.592298984527588},\n",
              " {'step': 995, 'train_loss': 4.294090747833252},\n",
              " {'step': 996, 'train_loss': 4.3901872634887695},\n",
              " {'step': 997, 'train_loss': 4.449321746826172},\n",
              " {'step': 998, 'train_loss': 4.244108200073242},\n",
              " {'step': 999, 'train_loss': 4.285708904266357},\n",
              " {'step': 1000,\n",
              "  'train_loss': 4.281221866607666,\n",
              "  'valid_loss': 4.974805423191616},\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgO77jkVjDe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aea12818-1d59-4999-e18b-1b600d180c3c"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss(input, target)\n",
        "print(output)\n",
        "output.backward()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.5508, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}